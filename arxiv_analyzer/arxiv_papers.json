[{"abstract": "We develop models and extract relevant features for automatic text\nsummarization and investigate the performance of different models on the DUC\n2001 dataset. Two different models were developed, one being a ridge regressor\nand the other one was a multi-layer perceptron. The hyperparameters were varied\nand their performance were noted. We segregated the summarization task into 2\nmain steps, the first being sentence ranking and the second step being sentence\nselection. In the first step, given a document, we sort the sentences based on\ntheir Importance, and in the second step, in order to obtain non-redundant\nsentences, we weed out the sentences that are have high similarity with the\npreviously selected sentences.", "authors": ["Karthik Bangalore Mani"], "category": "cs.CL", "comment": "4 pages,10 figures", "img": "/static/thumbs/1612.08333v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1612.08333v3", "num_discussion": 0, "originally_published_time": "12/26/2016", "pid": "1612.08333v3", "published_time": "6/14/2017", "rawpid": "1612.08333", "tags": ["cs.CL"], "title": "Text Summarization using MLP and Ridge Regression"}, {"abstract": "Current Chinese social media text summarization models are based on an\nencoder-decoder framework. Although its generated summaries are similar to\nsource texts literally, they have low semantic relevance. In this work, our\ngoal is to improve semantic relevance between source texts and summaries for\nChinese social media summarization. We introduce a Semantic Relevance Based\nneural model to encourage high semantic similarity between texts and summaries.\nIn our model, the source text is represented by a gated attention encoder,\nwhile the summary representation is produced by a decoder. Besides, the\nsimilarity score between the representations is maximized during training. Our\nexperiments show that the proposed model outperforms baseline systems on a\nsocial media corpus.", "authors": ["Shuming Ma", "Xu Sun", "Jingjing Xu", "Houfeng Wang", "Wenjie Li", "Qi Su"], "category": "cs.CL", "comment": "Accepted by ACL", "img": "/static/thumbs/1706.02459v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1706.02459v1", "num_discussion": 0, "originally_published_time": "6/8/2017", "pid": "1706.02459v1", "published_time": "6/8/2017", "rawpid": "1706.02459", "tags": ["cs.CL"], "title": "Improving Semantic Relevance for Sequence-to-Sequence Learning of\n  Chinese Social Media Text Summarization"}, {"abstract": "Summarization of large texts is still an open problem in language processing.\nIn this work we develop a full fledged pipeline to generate summaries of news\narticles using the Abstract Meaning Representation(AMR). We first generate the\nAMR graphs of stories then extract summary graphs from the story graphs and\nfinally generate sentences from the summary graph. For extracting summary AMRs\nfrom the story AMRs we use a two step process. First, we find important\nsentences from the text and then extract the summary AMRs from those selected\nsentences. We outperform the previous methods using AMR for summarization by\nmore that 3 ROGUE-1 points. On the CNN-Dailymail corpus we achieve results\ncompetitive with the strong lead-3 baseline till summary graph extraction step.", "authors": ["Shibhansh Dohare", "Harish Karnick"], "category": "cs.CL", "comment": "10 pages, 4 figures", "img": "/static/thumbs/1706.01678v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1706.01678v1", "num_discussion": 0, "originally_published_time": "6/6/2017", "pid": "1706.01678v1", "published_time": "6/6/2017", "rawpid": "1706.01678", "tags": ["cs.CL"], "title": "Text Summarization using Abstract Meaning Representation"}, {"abstract": "Automatic text summarization tools help users in biomedical domain to acquire\ntheir intended information from various textual resources more efficiently.\nSome of the biomedical text summarization systems put the basis of their\nsentence selection approach on the frequency of concepts extracted from the\ninput text. However, it seems that exploring other measures rather than the\nfrequency for identifying the valuable content of the input document, and\nconsidering the correlations existing between concepts may be more useful for\nthis type of summarization. In this paper, we describe a Bayesian summarizer\nfor biomedical text documents. The Bayesian summarizer initially maps the input\ntext to the Unified Medical Language System (UMLS) concepts, then it selects\nthe important ones to be used as classification features. We introduce\ndifferent feature selection approaches to identify the most important concepts\nof the text and to select the most informative content according to the\ndistribution of these concepts. We show that with the use of an appropriate\nfeature selection approach, the Bayesian biomedical summarizer can improve the\nperformance of summarization. We perform extensive evaluations on a corpus of\nscientific papers in biomedical domain. The results show that the Bayesian\nsummarizer outperforms the biomedical summarizers that rely on the frequency of\nconcepts, the domain-independent and baseline methods based on the\nRecall-Oriented Understudy for Gisting Evaluation (ROUGE) metrics. Moreover,\nthe results suggest that using the meaningfulness measure and considering the\ncorrelations of concepts in the feature selection step lead to a significant\nincrease in the performance of summarization.", "authors": ["Milad Moradi", "Nasser Ghadiri"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1605.02948v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1605.02948v3", "num_discussion": 0, "originally_published_time": "5/10/2016", "pid": "1605.02948v3", "published_time": "5/30/2017", "rawpid": "1605.02948", "tags": ["cs.CL", "cs.IR", "I.2.7; J.3"], "title": "Different approaches for identifying important concepts in probabilistic\n  biomedical text summarization"}, {"abstract": "Many Natural Language Processing and Computational Linguistics applications\ninvolves the generation of new texts based on some existing texts, such as\nsummarization, text simplification and machine translation. However, there has\nbeen a serious problem haunting these applications for decades, that is, how to\nautomatically and accurately assess quality of these applications. In this\npaper, we will present some preliminary results on one especially useful and\nchallenging problem in NLP system evaluation: how to pinpoint content\ndifferences of two text passages (especially for large pas-sages such as\narticles and books). Our idea is intuitive and very different from existing\napproaches. We treat one text passage as a small knowledge base, and ask it a\nlarge number of questions to exhaustively identify all content points in it. By\ncomparing the correctly answered questions from two text passages, we will be\nable to compare their content precisely. The experiment using 2007 DUC\nsummarization corpus clearly shows promising results.", "authors": ["Ping Chen", "Fei Wu", "Tong Wang"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1704.06259v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.06259v1", "num_discussion": 0, "originally_published_time": "4/21/2017", "pid": "1704.06259v1", "published_time": "4/21/2017", "rawpid": "1704.06259", "tags": ["cs.CL", "cs.AI"], "title": "A Semantic QA-Based Approach for Text Summarization Evaluation"}, {"abstract": "In recent times, data is growing rapidly in every domain such as news, social\nmedia, banking, education, etc. Due to the excessiveness of data, there is a\nneed of automatic summarizer which will be capable to summarize the data\nespecially textual data in original document without losing any critical\npurposes. Text summarization is emerged as an important research area in recent\npast. In this regard, review of existing work on text summarization process is\nuseful for carrying out further research. In this paper, recent literature on\nautomatic keyword extraction and text summarization are presented since text\nsummarization process is highly depend on keyword extraction. This literature\nincludes the discussion about different methodology used for keyword extraction\nand text summarization. It also discusses about different databases used for\ntext summarization in several domains along with evaluation matrices. Finally,\nit discusses briefly about issues and research challenges faced by researchers\nalong with future direction.", "authors": ["Santosh Kumar Bharti", "Korra Sathya Babu"], "category": "cs.CL", "comment": "12 pages, 4 figures", "img": "/static/thumbs/1704.03242v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.03242v1", "num_discussion": 0, "originally_published_time": "4/11/2017", "pid": "1704.03242v1", "published_time": "4/11/2017", "rawpid": "1704.03242", "tags": ["cs.CL"], "title": "Automatic Keyword Extraction for Text Summarization: A Survey"}, {"abstract": "In this work, we present the results of a systematic study to investigate the\n(commercial) benefits of automatic text summarization systems in a real world\nscenario. More specifically, we define a use case in the context of media\nmonitoring and media response analysis and claim that even using a simple\nquery-based extractive approach can dramatically save the processing time of\nthe employees without significantly reducing the quality of their work.", "authors": ["Pashutan Modaresi", "Philipp Gross", "Siavash Sefidrodi", "Mirja Eckhof", "Stefan Conrad"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1701.00728v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1701.00728v1", "num_discussion": 0, "originally_published_time": "1/3/2017", "pid": "1701.00728v1", "published_time": "1/3/2017", "rawpid": "1701.00728", "tags": ["cs.CL"], "title": "On (Commercial) Benefits of Automatic Text Summarization Systems in the\n  News Domain: A Case of Media Monitoring and Media Response Analysis"}, {"abstract": "Developed so far, multi-document summarization has reached its bottleneck due\nto the lack of sufficient training data and diverse categories of documents.\nText classification just makes up for these deficiencies. In this paper, we\npropose a novel summarization system called TCSum, which leverages plentiful\ntext classification data to improve the performance of multi-document\nsummarization. TCSum projects documents onto distributed representations which\nact as a bridge between text classification and summarization. It also utilizes\nthe classification results to produce summaries of different styles. Extensive\nexperiments on DUC generic multi-document summarization datasets show that,\nTCSum can achieve the state-of-the-art performance without using any\nhand-crafted features and has the capability to catch the variations of summary\nstyles with respect to different text categories.", "authors": ["Ziqiang Cao", "Wenjie Li", "Sujian Li", "Furu Wei"], "category": "cs.CL", "comment": "7 pages, 3 figures, AAAI-17", "img": "/static/thumbs/1611.09238v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1611.09238v1", "num_discussion": 0, "originally_published_time": "11/28/2016", "pid": "1611.09238v1", "published_time": "11/28/2016", "rawpid": "1611.09238", "tags": ["cs.CL", "cs.IR"], "title": "Improving Multi-Document Summarization via Text Classification"}, {"abstract": "In this work, we model abstractive text summarization using Attentional\nEncoder-Decoder Recurrent Neural Networks, and show that they achieve\nstate-of-the-art performance on two different corpora. We propose several novel\nmodels that address critical problems in summarization that are not adequately\nmodeled by the basic architecture, such as modeling key-words, capturing the\nhierarchy of sentence-to-word structure, and emitting words that are rare or\nunseen at training time. Our work shows that many of our proposed models\ncontribute to further improvement in performance. We also propose a new dataset\nconsisting of multi-sentence summaries, and establish performance benchmarks\nfor further research.", "authors": ["Ramesh Nallapati", "Bowen Zhou", "Cicero Nogueira dos santos", "Caglar Gulcehre", "Bing Xiang"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1602.06023v5.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1602.06023v5", "num_discussion": 0, "originally_published_time": "2/19/2016", "pid": "1602.06023v5", "published_time": "8/26/2016", "rawpid": "1602.06023", "tags": ["cs.CL"], "title": "Abstractive Text Summarization Using Sequence-to-Sequence RNNs and\n  Beyond"}, {"abstract": "Automatic text summarization is widely regarded as the highly difficult\nproblem, partially because of the lack of large text summarization data set.\nDue to the great challenge of constructing the large scale summaries for full\ntext, in this paper, we introduce a large corpus of Chinese short text\nsummarization dataset constructed from the Chinese microblogging website Sina\nWeibo, which is released to the public\n{http://icrc.hitsz.edu.cn/Article/show/139.html}. This corpus consists of over\n2 million real Chinese short texts with short summaries given by the author of\neach text. We also manually tagged the relevance of 10,666 short summaries with\ntheir corresponding short texts. Based on the corpus, we introduce recurrent\nneural network for the summary generation and achieve promising results, which\nnot only shows the usefulness of the proposed corpus for short text\nsummarization research, but also provides a baseline for further research on\nthis topic.", "authors": ["Baotian Hu", "Qingcai Chen", "Fangze Zhu"], "category": "cs.CL", "comment": "Recently, we received feedbacks from Yuya Taguchi from NAIST in Japan\n  and Qian Chen from USTC of C...", "img": "/static/thumbs/1506.05865v4.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1506.05865v4", "num_discussion": 0, "originally_published_time": "6/19/2015", "pid": "1506.05865v4", "published_time": "2/19/2016", "rawpid": "1506.05865", "tags": ["cs.CL", "cs.IR", "cs.LG"], "title": "LCSTS: A Large Scale Chinese Short Text Summarization Dataset"}, {"abstract": "For a graph formed by vertices and weighted edges, a generalized minimum\ndominating set (MDS) is a vertex set of smallest cardinality such that the\nsummed weight of edges from each outside vertex to vertices in this set is\nequal to or larger than certain threshold value. This generalized MDS problem\nreduces to the conventional MDS problem in the limiting case of all the edge\nweights being equal to the threshold value. We treat the generalized MDS\nproblem in the present paper by a replica-symmetric spin glass theory and\nderive a set of belief-propagation equations. As a practical application we\nconsider the problem of extracting a set of sentences that best summarize a\ngiven input text document. We carry out a preliminary test of the statistical\nphysics-inspired method to this automatic text summarization problem.", "authors": ["Yi-Zhi Xu", "Hai-Jun Zhou"], "category": "cs.IR", "comment": "11 pages, including 4 figures and 2 tables. To be published in\n  Journal of Physics: Conference Seri...", "img": "/static/thumbs/1602.04930v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1602.04930v1", "num_discussion": 0, "originally_published_time": "2/16/2016", "pid": "1602.04930v1", "published_time": "2/16/2016", "rawpid": "1602.04930", "tags": ["cs.IR", "cond-mat.stat-mech", "cs.CL", "physics.soc-ph"], "title": "Generalized minimum dominating set and application in automatic text\n  summarization"}, {"abstract": "So far and trying to reach human capabilities, research in automatic\nsummarization has been based on hypothesis that are both enabling and limiting.\nSome of these limitations are: how to take into account and reflect (in the\ngenerated summary) the implicit information conveyed in the text, the author\nintention, the reader intention, the context influence, the general world\nknowledge. Thus, if we want machines to mimic human abilities, then they will\nneed access to this same large variety of knowledge. The implicit is affecting\nthe orientation and the argumentation of the text and consequently its summary.\nMost of Text Summarizers (TS) are processing as compressing the initial data\nand they necessarily suffer from information loss. TS are focusing on features\nof the text only, not on what the author intended or why the reader is reading\nthe text. In this paper, we address this problem and we present a system\nfocusing on acquiring knowledge that is implicit. We principally spotlight the\nimplicit information conveyed by the argumentative connectives such as: but,\neven, yet and their effect on the summary.", "authors": ["Henda Chorfi Ouertani"], "category": "cs.CL", "comment": "4 pages, 2 figures, journal IJACSA; (IJACSA) International Journal of\n  Advanced Computer Science an...", "img": "/static/thumbs/1312.3258v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1312.3258v1", "num_discussion": 0, "originally_published_time": "12/11/2013", "pid": "1312.3258v1", "published_time": "12/11/2013", "rawpid": "1312.3258", "tags": ["cs.CL"], "title": "Implicit Sensitive Text Summarization based on Data Conveyed by\n  Connectives"}, {"abstract": "Arabic Documents Clustering is an important task for obtaining good results\nwith the traditional Information Retrieval (IR) systems especially with the\nrapid growth of the number of online documents present in Arabic language.\nDocuments clustering aim to automatically group similar documents in one\ncluster using different similarity/distance measures. This task is often\naffected by the documents length, useful information on the documents is often\naccompanied by a large amount of noise, and therefore it is necessary to\neliminate this noise while keeping useful information to boost the performance\nof Documents clustering. In this paper, we propose to evaluate the impact of\ntext summarization using the Latent Semantic Analysis Model on Arabic Documents\nClustering in order to solve problems cited above, using five\nsimilarity/distance measures: Euclidean Distance, Cosine Similarity, Jaccard\nCoefficient, Pearson Correlation Coefficient and Averaged Kullback-Leibler\nDivergence, for two times: without and with stemming. Our experimental results\nindicate that our proposed approach effectively solves the problems of noisy\ninformation and documents length, and thus significantly improve the clustering\nperformance.", "authors": ["Hanane Froud", "Abdelmonaime Lachkar", "Said Alaoui Ouatik"], "category": "cs.IR", "comment": "", "img": "/static/thumbs/1302.1612v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1302.1612v1", "num_discussion": 0, "originally_published_time": "2/6/2013", "pid": "1302.1612v1", "published_time": "2/6/2013", "rawpid": "1302.1612", "tags": ["cs.IR", "cs.CL"], "title": "Arabic text summarization based on latent semantic analysis to enhance\n  arabic documents clustering"}, {"abstract": "In Automatic Text Summarization, preprocessing is an important phase to\nreduce the space of textual representation. Classically, stemming and\nlemmatization have been widely used for normalizing words. However, even using\nnormalization on large texts, the curse of dimensionality can disturb the\nperformance of summarizers. This paper describes a new method for normalization\nof words to further reduce the space of representation. We propose to reduce\neach word to its initial letters, as a form of Ultra-stemming. The results show\nthat Ultra-stemming not only preserve the content of summaries produced by this\nrepresentation, but often the performances of the systems can be dramatically\nimproved. Summaries on trilingual corpora were evaluated automatically with\nFresa. Results confirm an increase in the performance, regardless of summarizer\nsystem used.", "authors": ["Juan-Manuel Torres-Moreno"], "category": "cs.IR", "comment": "22 pages, 12 figures, 9 tables", "img": "/static/thumbs/1209.3126v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1209.3126v1", "num_discussion": 0, "originally_published_time": "9/14/2012", "pid": "1209.3126v1", "published_time": "9/14/2012", "rawpid": "1209.3126", "tags": ["cs.IR", "cs.CL"], "title": "Beyond Stemming and Lemmatization: Ultra-stemming to Improve Automatic\n  Text Summarization"}, {"abstract": "The technology of automatic document summarization is maturing and may\nprovide a solution to the information overload problem. Nowadays, document\nsummarization plays an important role in information retrieval. With a large\nvolume of documents, presenting the user with a summary of each document\ngreatly facilitates the task of finding the desired documents. Document\nsummarization is a process of automatically creating a compressed version of a\ngiven document that provides useful information to users, and multi-document\nsummarization is to produce a summary delivering the majority of information\ncontent from a set of documents about an explicit or implicit main topic. The\nlexical cohesion structure of the text can be exploited to determine the\nimportance of a sentence/phrase. Lexical chains are useful tools to analyze the\nlexical cohesion structure in a text .In this paper we consider the effect of\nthe use of lexical cohesion features in Summarization, And presenting a\nalgorithm base on the knowledge base. Ours algorithm at first find the correct\nsense of any word, Then constructs the lexical chains, remove Lexical chains\nthat less score than other, detects topics roughly from lexical chains,\nsegments the text with respect to the topics and selects the most important\nsentences. The experimental results on an open benchmark datasets from DUC01\nand DUC02 show that our proposed approach can improve the performance compared\nto sate-of-the-art summarization approaches.", "authors": ["Mohsen Pourvali", "Mohammad Saniee Abadeh"], "category": "cs.IR", "comment": "", "img": "/static/thumbs/1203.3586v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1203.3586v1", "num_discussion": 0, "originally_published_time": "3/15/2012", "pid": "1203.3586v1", "published_time": "3/15/2012", "rawpid": "1203.3586", "tags": ["cs.IR", "cs.CL"], "title": "Automated Text Summarization Base on Lexicales Chain and graph Using of\n  WordNet and Wikipedia Knowledge Base"}, {"abstract": "The number of documents available into Internet moves each day up. For this\nreason, processing this amount of information effectively and expressibly\nbecomes a major concern for companies and scientists. Methods that represent a\ntextual document by a topic representation are widely used in Information\nRetrieval (IR) to process big data such as Wikipedia articles. One of the main\ndifficulty in using topic model on huge data collection is related to the\nmaterial resources (CPU time and memory) required for model estimate. To deal\nwith this issue, we propose to build topic spaces from summarized documents. In\nthis paper, we present a study of topic space representation in the context of\nbig data. The topic space representation behavior is analyzed on different\nlanguages. Experiments show that topic spaces estimated from text summaries are\nas relevant as those estimated from the complete documents. The real advantage\nof such an approach is the processing time gain: we showed that the processing\ntime can be drastically reduced using summarized documents (more than 60\\% in\ngeneral). This study finally points out the differences between thematic\nrepresentations of documents depending on the targeted languages such as\nEnglish or latin languages.", "authors": ["Mohamed Morchid", "Juan-Manuel Torres-Moreno", "Richard Dufour", "Javier Ram\u00edrez-Rodr\u00edguez", "Georges Linar\u00e8s"], "category": "cs.IR", "comment": "16 pages, 4 tables, 8 figures", "img": "/static/thumbs/1703.06630v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1703.06630v1", "num_discussion": 0, "originally_published_time": "3/20/2017", "pid": "1703.06630v1", "published_time": "3/20/2017", "rawpid": "1703.06630", "tags": ["cs.IR", "cs.CL"], "title": "Automatic Text Summarization Approaches to Speed up Topic Model Learning\n  Process"}, {"abstract": "The development of methods to deal with the informative contents of the text\nunits in the matching process is a major challenge in automatic summary\nevaluation systems that use fixed n-gram matching. The limitation causes\ninaccurate matching between units in a peer and reference summaries. The\npresent study introduces a new Keyphrase based Summary Evaluator KpEval for\nevaluating automatic summaries. The KpEval relies on the keyphrases since they\nconvey the most important concepts of a text. In the evaluation process, the\nkeyphrases are used in their lemma form as the matching text unit. The system\nwas applied to evaluate different summaries of Arabic multi-document data set\npresented at TAC2011. The results showed that the new evaluation technique\ncorrelates well with the known evaluation systems: Rouge1, Rouge2, RougeSU4,\nand AutoSummENG MeMoG. KpEval has the strongest correlation with AutoSummENG\nMeMoG, Pearson and spearman correlation coefficient measures are 0.8840, 0.9667\nrespectively.", "authors": ["Fatma Elghannam", "Tarek El-Shishtawy"], "category": "cs.CL", "comment": "4 pages, 1 figure, 3 tables", "img": "/static/thumbs/1505.06228v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1505.06228v1", "num_discussion": 0, "originally_published_time": "5/22/2015", "pid": "1505.06228v1", "published_time": "5/22/2015", "rawpid": "1505.06228", "tags": ["cs.CL", "94AXX"], "title": "Keyphrase Based Evaluation of Automatic Text Summarization"}, {"abstract": "Matching texts in highly inflected languages such as Arabic by simple\nstemming strategy is unlikely to perform well. In this paper, we present a\nstrategy for automatic text matching technique for for inflectional languages,\nusing Arabic as the test case. The system is an extension of ROUGE test in\nwhich texts are matched on token\u0027s lemma level. The experimental results show\nan enhancement of detecting similarities between different sentences having\nsame semantics but written in different lexical forms..", "authors": ["Tarek El-Shishtawy", "Fatma El-Ghannam"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1403.5596v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1403.5596v1", "num_discussion": 0, "originally_published_time": "3/22/2014", "pid": "1403.5596v1", "published_time": "3/22/2014", "rawpid": "1403.5596", "tags": ["cs.CL", "cs.IR"], "title": "A Lemma Based Evaluator for Semitic Language Text Summarization Systems"}, {"abstract": "Although the problem of automatic video summarization has recently received a\nlot of attention, the problem of creating a video summary that also highlights\nelements relevant to a search query has been less studied. We address this\nproblem by posing query-relevant summarization as a video frame subset\nselection problem, which lets us optimise for summaries which are\nsimultaneously diverse, representative of the entire video, and relevant to a\ntext query. We quantify relevance by measuring the distance between frames and\nqueries in a common textual-visual semantic embedding space induced by a neural\nnetwork. In addition, we extend the model to capture query-independent\nproperties, such as frame quality. We compare our method against previous state\nof the art on textual-visual embeddings for thumbnail selection and show that\nour model outperforms them on relevance prediction. Furthermore, we introduce a\nnew dataset, annotated with diversity and query-specific relevance labels. On\nthis dataset, we train and test our complete model for video summarization and\nshow that it outperforms standard baselines such as Maximal Marginal Relevance.", "authors": ["Arun Balajee Vasudevan", "Michael Gygli", "Anna Volokitin", "Luc Van Gool"], "category": "cs.CV", "comment": "Submitted to ACM Multimedia 2017", "img": "/static/thumbs/1705.00581v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1705.00581v1", "num_discussion": 0, "originally_published_time": "5/1/2017", "pid": "1705.00581v1", "published_time": "5/1/2017", "rawpid": "1705.00581", "tags": ["cs.CV", "cs.CL", "cs.MM"], "title": "Query-adaptive Video Summarization via Quality-aware Relevance\n  Estimation"}, {"abstract": "Neural sequence-to-sequence models have provided a viable new approach for\nabstractive text summarization (meaning they are not restricted to simply\nselecting and rearranging passages from the original text). However, these\nmodels have two shortcomings: they are liable to reproduce factual details\ninaccurately, and they tend to repeat themselves. In this work we propose a\nnovel architecture that augments the standard sequence-to-sequence attentional\nmodel in two orthogonal ways. First, we use a hybrid pointer-generator network\nthat can copy words from the source text via pointing, which aids accurate\nreproduction of information, while retaining the ability to produce novel words\nthrough the generator. Second, we use coverage to keep track of what has been\nsummarized, which discourages repetition. We apply our model to the CNN / Daily\nMail summarization task, outperforming the current abstractive state-of-the-art\nby at least 2 ROUGE points.", "authors": ["Abigail See", "Peter J. Liu", "Christopher D. Manning"], "category": "cs.CL", "comment": "Add METEOR evaluation results, add some citations, fix some equations\n  (what are now equations 1, 8...", "img": "/static/thumbs/1704.04368v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.04368v2", "num_discussion": 0, "originally_published_time": "4/14/2017", "pid": "1704.04368v2", "published_time": "4/25/2017", "rawpid": "1704.04368", "tags": ["cs.CL"], "title": "Get To The Point: Summarization with Pointer-Generator Networks"}, {"abstract": "Due to its promise to alleviate information overload, text summarization has\nattracted the attention of many researchers. However, it has remained a serious\nchallenge. Here, we first prove empirical limits on the recall (and F1-scores)\nof extractive summarizers on the DUC datasets under ROUGE evaluation for both\nthe single-document and multi-document summarization tasks. Next we define the\nconcept of compressibility of a document and present a new model of\nsummarization, which generalizes existing models in the literature and\nintegrates several dimensions of the summarization, viz., abstractive versus\nextractive, single versus multi-document, and syntactic versus semantic.\nFinally, we examine some new and existing single-document summarization\nalgorithms in a single framework and compare with state of the art summarizers\non DUC data.", "authors": ["Rakesh Verma", "Daniel Lee"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1704.05550v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.05550v1", "num_discussion": 0, "originally_published_time": "4/18/2017", "pid": "1704.05550v1", "published_time": "4/18/2017", "rawpid": "1704.05550", "tags": ["cs.CL", "cs.IR"], "title": "Extractive Summarization: Limits, Compression, Generalized Model and\n  Heuristics"}, {"abstract": "Distributed representation learned with neural networks has recently shown to\nbe effective in modeling natural languages at fine granularities such as words,\nphrases, and even sentences. Whether and how such an approach can be extended\nto help model larger spans of text, e.g., documents, is intriguing, and further\ninvestigation would still be desirable. This paper aims to enhance neural\nnetwork models for such a purpose. A typical problem of document-level modeling\nis automatic summarization, which aims to model documents in order to generate\nsummaries. In this paper, we propose neural models to train computers not just\nto pay attention to specific regions and content of input documents with\nattention models, but also distract them to traverse between different content\nof a document so as to better grasp the overall meaning for summarization.\nWithout engineering any features, we train the models on two large datasets.\nThe models achieve the state-of-the-art performance, and they significantly\nbenefit from the distraction modeling, particularly when input documents are\nlong.", "authors": ["Qian Chen", "Xiaodan Zhu", "Zhenhua Ling", "Si Wei", "Hui Jiang"], "category": "cs.CL", "comment": "Published in IJCAI-2016: the 25th International Joint Conference on\n  Artificial Intelligence", "img": "/static/thumbs/1610.08462v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1610.08462v1", "num_discussion": 0, "originally_published_time": "10/26/2016", "pid": "1610.08462v1", "published_time": "10/26/2016", "rawpid": "1610.08462", "tags": ["cs.CL"], "title": "Distraction-Based Neural Networks for Document Summarization"}, {"abstract": "We propose a general framework for topic-specific summarization of large text\ncorpora, and illustrate how it can be used for analysis in two quite different\ncontexts: an OSHA database of fatality and catastrophe reports (to facilitate\nsurveillance for patterns in circumstances leading to injury or death) and\nlegal decisions on workers\u0027 compensation claims (to explore relevant case law).\nOur summarization framework, built on sparse classification methods, is a\ncompromise between simple word frequency based methods currently in wide use,\nand more heavyweight, model-intensive methods such as Latent Dirichlet\nAllocation (LDA). For a particular topic of interest (e.g., mental health\ndisability, or chemical reactions), we regress a labeling of documents onto the\nhigh-dimensional counts of all the other words and phrases in the documents.\nThe resulting small set of phrases found as predictive are then harvested as\nthe summary. Using a branch-and-bound approach, this method can be extended to\nallow for phrases of arbitrary length, which allows for potentially rich\nsummarization. We discuss how focus on the purpose of the summaries can inform\nchoices of regularization parameters and model constraints. We evaluate this\ntool by comparing computational time and summary statistics of the resulting\nword lists to three other methods in the literature. We also present a new R\npackage, textreg. Overall, we argue that sparse methods have much to offer text\nanalysis, and is a branch of research that should be considered further in this\ncontext.", "authors": ["Luke Miratrix", "Robin Ackerman"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1511.06798v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1511.06798v2", "num_discussion": 0, "originally_published_time": "11/20/2015", "pid": "1511.06798v2", "published_time": "7/23/2016", "rawpid": "1511.06798", "tags": ["cs.CL", "cs.IR", "stat.AP"], "title": "Conducting sparse feature selection on arbitrarily long phrases in text\n  corpora with a focus on interpretability"}, {"abstract": "We present a submodular function-based framework for query-focused opinion\nsummarization. Within our framework, relevance ordering produced by a\nstatistical ranker, and information coverage with respect to topic distribution\nand diverse viewpoints are both encoded as submodular functions. Dispersion\nfunctions are utilized to minimize the redundancy. We are the first to evaluate\ndifferent metrics of text similarity for submodularity-based summarization\nmethods. By experimenting on community QA and blog summarization, we show that\nour system outperforms state-of-the-art approaches in both automatic evaluation\nand human evaluation. A human evaluation task is conducted on Amazon Mechanical\nTurk with scale, and shows that our systems are able to generate summaries of\nhigh overall quality and information diversity.", "authors": ["Lu Wang", "Hema Raghavan", "Claire Cardie", "Vittorio Castelli"], "category": "cs.CL", "comment": "COLING 2014", "img": "/static/thumbs/1606.05702v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1606.05702v1", "num_discussion": 0, "originally_published_time": "6/17/2016", "pid": "1606.05702v1", "published_time": "6/17/2016", "rawpid": "1606.05702", "tags": ["cs.CL"], "title": "Query-Focused Opinion Summarization for User-Generated Content"}, {"abstract": "We present a discriminative model for single-document summarization that\nintegrally combines compression and anaphoricity constraints. Our model selects\ntextual units to include in the summary based on a rich set of sparse features\nwhose weights are learned on a large corpus. We allow for the deletion of\ncontent within a sentence when that deletion is licensed by compression rules;\nin our framework, these are implemented as dependencies between subsentential\nunits of text. Anaphoricity constraints then improve cross-sentence coherence\nby guaranteeing that, for each pronoun included in the summary, the pronoun\u0027s\nantecedent is included as well or the pronoun is rewritten as a full mention.\nWhen trained end-to-end, our final system outperforms prior work on both ROUGE\nas well as on human judgments of linguistic quality.", "authors": ["Greg Durrett", "Taylor Berg-Kirkpatrick", "Dan Klein"], "category": "cs.CL", "comment": "ACL 2016", "img": "/static/thumbs/1603.08887v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1603.08887v2", "num_discussion": 0, "originally_published_time": "3/29/2016", "pid": "1603.08887v2", "published_time": "6/8/2016", "rawpid": "1603.08887", "tags": ["cs.CL"], "title": "Learning-Based Single-Document Summarization with Compression and\n  Anaphoricity Constraints"}, {"abstract": "We present a system based on sequential decision making for the online\nsummarization of massive document streams, such as those found on the web.\nGiven an event of interest (e.g. \"Boston marathon bombing\"), our system is able\nto filter the stream for relevance and produce a series of short text updates\ndescribing the event as it unfolds over time. Unlike previous work, our\napproach is able to jointly model the relevance, comprehensiveness, novelty,\nand timeliness required by time-sensitive queries. We demonstrate a 28.3%\nimprovement in summary F1 and a 43.8% improvement in time-sensitive F1 metrics.", "authors": ["Chris Kedzie", "Fernando Diaz", "Kathleen McKeown"], "category": "cs.CL", "comment": "in Proceedings of the 25th International Joint Conference on\n  Artificial Intelligence 2016", "img": "/static/thumbs/1605.03664v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1605.03664v1", "num_discussion": 0, "originally_published_time": "5/12/2016", "pid": "1605.03664v1", "published_time": "5/12/2016", "rawpid": "1605.03664", "tags": ["cs.CL"], "title": "Real-Time Web Scale Event Summarization Using Sequential Decision Making"}, {"abstract": "Evaluation of text summarization approaches have been mostly based on metrics\nthat measure similarities of system generated summaries with a set of human\nwritten gold-standard summaries. The most widely used metric in summarization\nevaluation has been the ROUGE family. ROUGE solely relies on lexical overlaps\nbetween the terms and phrases in the sentences; therefore, in cases of\nterminology variations and paraphrasing, ROUGE is not as effective. Scientific\narticle summarization is one such case that is different from general domain\nsummarization (e.g. newswire data). We provide an extensive analysis of ROUGE\u0027s\neffectiveness as an evaluation metric for scientific summarization; we show\nthat, contrary to the common belief, ROUGE is not much reliable in evaluating\nscientific summaries. We furthermore show how different variants of ROUGE\nresult in very different correlations with the manual Pyramid scores. Finally,\nwe propose an alternative metric for summarization evaluation which is based on\nthe content relevance between a system generated summary and the corresponding\nhuman written summaries. We call our metric SERA (Summarization Evaluation by\nRelevance Analysis). Unlike ROUGE, SERA consistently achieves high correlations\nwith manual scores which shows its effectiveness in evaluation of scientific\narticle summarization.", "authors": ["Arman Cohan", "Nazli Goharian"], "category": "cs.CL", "comment": "LREC 2016", "img": "/static/thumbs/1604.00400v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1604.00400v1", "num_discussion": 0, "originally_published_time": "4/1/2016", "pid": "1604.00400v1", "published_time": "4/1/2016", "rawpid": "1604.00400", "tags": ["cs.CL"], "title": "Revisiting Summarization Evaluation for Scientific Articles"}, {"abstract": "We assess the performance of generic text summarization algorithms applied to\nfilms and documentaries, using the well-known behavior of summarization of news\narticles as reference. We use three datasets: (i) news articles, (ii) film\nscripts and subtitles, and (iii) documentary subtitles. Standard ROUGE metrics\nare used for comparing generated summaries against news abstracts, plot\nsummaries, and synopses. We show that the best performing algorithms are LSA,\nfor news articles and documentaries, and LexRank and Support Sets, for films.\nDespite the different nature of films and documentaries, their relative\nbehavior is in accordance with that obtained for news articles.", "authors": ["Marta Apar\u00edcio", "Paulo Figueiredo", "Francisco Raposo", "David Martins de Matos", "Ricardo Ribeiro", "Lu\u00eds Marujo"], "category": "cs.CL", "comment": "7 pages, 9 tables, 4 figures, submitted to Pattern Recognition\n  Letters (Elsevier)", "img": "/static/thumbs/1506.01273v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1506.01273v3", "num_discussion": 0, "originally_published_time": "6/3/2015", "pid": "1506.01273v3", "published_time": "3/9/2016", "rawpid": "1506.01273", "tags": ["cs.CL", "cs.AI", "cs.IR", "I.2.7"], "title": "Summarization of Films and Documentaries Based on Subtitles and Scripts"}, {"abstract": "In order to satisfy processing time constraints, many MIR tasks process only\na segment of the whole music signal. This practice may lead to decreasing\nperformance, since the most important information for the tasks may not be in\nthose processed segments. In this paper, we leverage generic summarization\nalgorithms, previously applied to text and speech summarization, to summarize\nitems in music datasets. These algorithms build summaries, that are both\nconcise and diverse, by selecting appropriate segments from the input signal\nwhich makes them good candidates to summarize music as well. We evaluate the\nsummarization process on binary and multiclass music genre classification\ntasks, by comparing the performance obtained using summarized datasets against\nthe performances obtained using continuous segments (which is the traditional\nmethod used for addressing the previously mentioned time constraints) and full\nsongs of the same original dataset. We show that GRASSHOPPER, LexRank, LSA,\nMMR, and a Support Sets-based Centrality model improve classification\nperformance when compared to selected 30-second baselines. We also show that\nsummarized datasets lead to a classification performance whose difference is\nnot statistically significant from using full songs. Furthermore, we make an\nargument stating the advantages of sharing summarized datasets for future MIR\nresearch.", "authors": ["Francisco Raposo", "Ricardo Ribeiro", "David Martins de Matos"], "category": "cs.IR", "comment": "24 pages, 10 tables; Submitted to IEEE/ACM Transactions on Audio,\n  Speech and Language Processing", "img": "/static/thumbs/1503.06666v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1503.06666v3", "num_discussion": 0, "originally_published_time": "3/23/2015", "pid": "1503.06666v3", "published_time": "3/9/2016", "rawpid": "1503.06666", "tags": ["cs.IR", "cs.LG", "cs.SD", "H.5.5"], "title": "Using Generic Summarization to Improve Music Information Retrieval Tasks"}, {"abstract": "This paper aims to introduces a new algorithm for automatic speech-to-text\nsummarization based on statistical divergences of probabilities and graphs. The\ninput is a text from speech conversations with noise, and the output a compact\ntext summary. Our results, on the pilot task CCCS Multiling 2015 French corpus\nare very encouraging", "authors": ["Elvys Linhares Pontes", "Juan-Manuel Torres-Moreno", "Andr\u00e9a Carneiro Linhares"], "category": "cs.CL", "comment": "7 pages, 2 figures, CCCS Multiling 2015 Workshop", "img": "/static/thumbs/1601.07124v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1601.07124v1", "num_discussion": 0, "originally_published_time": "1/26/2016", "pid": "1601.07124v1", "published_time": "1/26/2016", "rawpid": "1601.07124", "tags": ["cs.CL", "cs.IR"], "title": "LIA-RAG: a system based on graphs and divergence of probabilities\n  applied to Speech-To-Text Summarization"}, {"abstract": "Events of various kinds are mentioned and discussed in text documents,\nwhether they are books, news articles, blogs or microblog feeds. The paper\nstarts by giving an overview of how events are treated in linguistics and\nphilosophy. We follow this discussion by surveying how events and associated\ninformation are handled in computationally. In particular, we look at how\ntextual documents can be mined to extract events and ancillary information.\nThese days, it is mostly through the application of various machine learning\ntechniques. We also discuss applications of event detection and extraction\nsystems, particularly in summarization, in the medical domain and in the\ncontext of Twitter posts. We end the paper with a discussion of challenges and\nfuture directions.", "authors": ["Jugal Kalita"], "category": "cs.CL", "comment": "This is work in progress. Please email jkalita@uccs.edu with any\n  comments for improvement", "img": "/static/thumbs/1601.04012v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1601.04012v1", "num_discussion": 0, "originally_published_time": "1/15/2016", "pid": "1601.04012v1", "published_time": "1/15/2016", "rawpid": "1601.04012", "tags": ["cs.CL"], "title": "Detecting and Extracting Events from Text Documents"}, {"abstract": "Summarization based on text extraction is inherently limited, but\ngeneration-style abstractive methods have proven challenging to build. In this\nwork, we propose a fully data-driven approach to abstractive sentence\nsummarization. Our method utilizes a local attention-based model that generates\neach word of the summary conditioned on the input sentence. While the model is\nstructurally simple, it can easily be trained end-to-end and scales to a large\namount of training data. The model shows significant performance gains on the\nDUC-2004 shared task compared with several strong baselines.", "authors": ["Alexander M. Rush", "Sumit Chopra", "Jason Weston"], "category": "cs.CL", "comment": "Proceedings of EMNLP 2015", "img": "/static/thumbs/1509.00685v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1509.00685v2", "num_discussion": 0, "originally_published_time": "9/2/2015", "pid": "1509.00685v2", "published_time": "9/3/2015", "rawpid": "1509.00685", "tags": ["cs.CL", "cs.AI"], "title": "A Neural Attention Model for Abstractive Sentence Summarization"}, {"abstract": "ROUGE is a widely adopted, automatic evaluation measure for text\nsummarization. While it has been shown to correlate well with human judgements,\nit is biased towards surface lexical similarities. This makes it unsuitable for\nthe evaluation of abstractive summarization, or summaries with substantial\nparaphrasing. We study the effectiveness of word embeddings to overcome this\ndisadvantage of ROUGE. Specifically, instead of measuring lexical overlaps,\nword embeddings are used to compute the semantic similarity of the words used\nin summaries instead. Our experimental results show that our proposal is able\nto achieve better correlations with human judgements when measured with the\nSpearman and Kendall rank coefficients.", "authors": ["Jun-Ping Ng", "Viktoria Abrecht"], "category": "cs.CL", "comment": "Pre-print - To appear in proceedings of the Conference on Empirical\n  Methods in Natural Language Pr...", "img": "/static/thumbs/1508.06034v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1508.06034v1", "num_discussion": 0, "originally_published_time": "8/25/2015", "pid": "1508.06034v1", "published_time": "8/25/2015", "rawpid": "1508.06034", "tags": ["cs.CL", "cs.IR"], "title": "Better Summarization Evaluation with Word Embeddings for ROUGE"}, {"abstract": "Summarization is one of the key features of human intelligence. It plays an\nimportant role in understanding and representation. With rapid and continual\nexpansion of texts, pictures and videos in cyberspace, automatic summarization\nbecomes more and more desirable. Text summarization has been studied for over\nhalf century, but it is still hard to automatically generate a satisfied\nsummary. Traditional methods process texts empirically and neglect the\nfundamental characteristics and principles of language use and understanding.\nThis paper summarizes previous text summarization approaches in a\nmulti-dimensional classification space, introduces a multi-dimensional\nmethodology for research and development, unveils the basic characteristics and\nprinciples of language use and understanding, investigates some fundamental\nmechanisms of summarization, studies the dimensions and forms of\nrepresentations, and proposes a multi-dimensional evaluation mechanisms.\nInvestigation extends to the incorporation of pictures into summary and to the\nsummarization of videos, graphs and pictures, and then reaches a general\nsummarization framework.", "authors": ["Hai Zhuge"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1507.00209v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1507.00209v1", "num_discussion": 0, "originally_published_time": "7/1/2015", "pid": "1507.00209v1", "published_time": "7/1/2015", "rawpid": "1507.00209", "tags": ["cs.CL", "cs.IR"], "title": "Dimensionality on Summarization"}, {"abstract": "Owing to the rapidly growing multimedia content available on the Internet,\nextractive spoken document summarization, with the purpose of automatically\nselecting a set of representative sentences from a spoken document to concisely\nexpress the most important theme of the document, has been an active area of\nresearch and experimentation. On the other hand, word embedding has emerged as\na newly favorite research subject because of its excellent performance in many\nnatural language processing (NLP)-related tasks. However, as far as we are\naware, there are relatively few studies investigating its use in extractive\ntext or speech summarization. A common thread of leveraging word embeddings in\nthe summarization process is to represent the document (or sentence) by\naveraging the word embeddings of the words occurring in the document (or\nsentence). Then, intuitively, the cosine similarity measure can be employed to\ndetermine the relevance degree between a pair of representations. Beyond the\ncontinued efforts made to improve the representation of words, this paper\nfocuses on building novel and efficient ranking models based on the general\nword embedding methods for extractive speech summarization. Experimental\nresults demonstrate the effectiveness of our proposed methods, compared to\nexisting state-of-the-art methods.", "authors": ["Kuan-Yu Chen", "Shih-Hung Liu", "Hsin-Min Wang", "Berlin Chen", "Hsin-Hsi Chen"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1506.04365v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1506.04365v1", "num_discussion": 0, "originally_published_time": "6/14/2015", "pid": "1506.04365v1", "published_time": "6/14/2015", "rawpid": "1506.04365", "tags": ["cs.CL", "cs.AI"], "title": "Leveraging Word Embeddings for Spoken Document Summarization"}, {"abstract": "We propose a new MDS paradigm called reader-aware multi-document\nsummarization (RA-MDS). Specifically, a set of reader comments associated with\nthe news reports are also collected. The generated summaries from the reports\nfor the event should be salient according to not only the reports but also the\nreader comments. To tackle this RA-MDS problem, we propose a\nsparse-coding-based method that is able to calculate the salience of the text\nunits by jointly considering news reports and reader comments. Another\nreader-aware characteristic of our framework is to improve linguistic quality\nvia entity rewriting. The rewriting consideration is jointly assessed together\nwith other summarization requirements under a unified optimization model. To\nsupport the generation of compressive summaries via optimization, we explore a\nfiner syntactic unit, namely, noun/verb phrase. In this work, we also generate\na data set for conducting RA-MDS. Extensive experiments on this data set and\nsome classical data sets demonstrate the effectiveness of our proposed\napproach.", "authors": ["Piji Li", "Lidong Bing", "Wai Lam", "Hang Li", "Yi Liao"], "category": "cs.CL", "comment": "7 pages, 2 figures, accepted as a full paper at IJCAI 2015", "img": "/static/thumbs/1504.07324v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1504.07324v1", "num_discussion": 0, "originally_published_time": "4/28/2015", "pid": "1504.07324v1", "published_time": "4/28/2015", "rawpid": "1504.07324", "tags": ["cs.CL", "cs.AI"], "title": "Reader-Aware Multi-Document Summarization via Sparse Coding"}, {"abstract": "MindMapping is a well-known technique used in note taking, which encourages\nlearning and studying. MindMapping has been manually adopted to help present\nknowledge and concepts in a visual form. Unfortunately, there is no reliable\nautomated approach to generate MindMaps from Natural Language text. This work\nfirstly introduces MindMap Multilevel Visualization concept which is to jointly\nvisualize and summarize textual information. The visualization is achieved\npictorially across multiple levels using semantic information (i.e. ontology),\nwhile the summarization is achieved by the information in the highest levels as\nthey represent abstract information in the text. This work also presents the\nfirst automated approach that takes a text input and generates a MindMap\nvisualization out of it. The approach could visualize text documents in\nmultilevel MindMaps, in which a high-level MindMap node could be expanded into\nchild MindMaps. \\ignore{ As far as we know, this is the first work that view\nMindMapping as a new approach to jointly summarize and visualize textual\ninformation.} The proposed method involves understanding of the input text and\nconverting it into intermediate Detailed Meaning Representation (DMR). The DMR\nis then visualized with two modes; Single level or Multiple levels, which is\nconvenient for larger text. The generated MindMaps from both approaches were\nevaluated based on Human Subject experiments performed on Amazon Mechanical\nTurk with various parameter settings.", "authors": ["Mohamed Elhoseiny", "Ahmed Elgammal"], "category": "cs.CL", "comment": "31 pages", "img": "/static/thumbs/1408.1031v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1408.1031v2", "num_discussion": 0, "originally_published_time": "8/1/2014", "pid": "1408.1031v2", "published_time": "12/23/2014", "rawpid": "1408.1031", "tags": ["cs.CL", "cs.HC"], "title": "Text to Multi-level MindMaps: A Novel Method for Hierarchical Visual\n  Abstraction of Natural Language Text"}, {"abstract": "Several generic summarization algorithms were developed in the past and\nsuccessfully applied in fields such as text and speech summarization. In this\npaper, we review and apply these algorithms to music. To evaluate this\nsummarization\u0027s performance, we adopt an extrinsic approach: we compare a Fado\nGenre Classifier\u0027s performance using truncated contiguous clips against the\nsummaries extracted with those algorithms on 2 different datasets. We show that\nMaximal Marginal Relevance (MMR), LexRank and Latent Semantic Analysis (LSA)\nall improve classification performance in both datasets used for testing.", "authors": ["Francisco Raposo", "Ricardo Ribeiro", "David Martins de Matos"], "category": "cs.IR", "comment": "12 pages, 1 table; Submitted to IEEE Signal Processing Letters", "img": "/static/thumbs/1406.4877v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1406.4877v1", "num_discussion": 0, "originally_published_time": "6/18/2014", "pid": "1406.4877v1", "published_time": "6/18/2014", "rawpid": "1406.4877", "tags": ["cs.IR", "cs.LG", "cs.SD", "H.5.5"], "title": "On the Application of Generic Summarization Algorithms to Music"}, {"abstract": "Sentence extraction based summarization methods has some limitations as it\ndoesn\u0027t go into the semantics of the document. Also, it lacks the capability of\nsentence generation which is intuitive to humans. Here we present a novel\nmethod to summarize text documents taking the process to semantic levels with\nthe use of WordNet and other resources, and using a technique for sentence\ngeneration. We involve semantic role labeling to get the semantic\nrepresentation of text and use of segmentation to form clusters of the related\npieces of text. Picking out the centroids and sentence generation completes the\ntask. We evaluate our system against human composed summaries and also present\nan evaluation done by humans to measure the quality attributes of our\nsummaries.", "authors": ["Divyanshu Bhartiya", "Ashudeep Singh"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1406.1203v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1406.1203v1", "num_discussion": 0, "originally_published_time": "6/4/2014", "pid": "1406.1203v1", "published_time": "6/4/2014", "rawpid": "1406.1203", "tags": ["cs.CL"], "title": "A Semantic Approach to Summarization"}, {"abstract": "In this paper we propose a general framework for topic-specific summarization\nof large text corpora and illustrate how it can be used for the analysis of\nnews databases. Our framework, concise comparative summarization (CCS), is\nbuilt on sparse classification methods. CCS is a lightweight and flexible tool\nthat offers a compromise between simple word frequency based methods currently\nin wide use and more heavyweight, model-intensive methods such as latent\nDirichlet allocation (LDA). We argue that sparse methods have much to offer for\ntext analysis and hope CCS opens the door for a new branch of research in this\nimportant field. For a particular topic of interest (e.g., China or energy),\nCSS automatically labels documents as being either on- or off-topic (usually\nvia keyword search), and then uses sparse classification methods to predict\nthese labels with the high-dimensional counts of all the other words and\nphrases in the documents. The resulting small set of phrases found as\npredictive are then harvested as the summary. To validate our tool, we, using\nnews articles from the New York Times international section, designed and\nconducted a human survey to compare the different summarizers with human\nunderstanding. We demonstrate our approach with two case studies, a media\nanalysis of the framing of \"Egypt\" in the New York Times throughout the Arab\nSpring and an informal comparison of the New York Times\u0027 and Wall Street\nJournal\u0027s coverage of \"energy.\" Overall, we find that the Lasso with $L^2$\nnormalization can be effectively and usefully used to summarize large corpora,\nregardless of document size.", "authors": ["Jinzhu Jia", "Luke Miratrix", "Bin Yu", "Brian Gawalt", "Laurent El Ghaoui", "Luke Barnesmoore", "Sophie Clavier"], "category": "cs.CL", "comment": "Published in at http://dx.doi.org/10.1214/13-AOAS698 the Annals of\n  Applied Statistics (http://www....", "img": "/static/thumbs/1404.7362v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1404.7362v1", "num_discussion": 0, "originally_published_time": "4/29/2014", "pid": "1404.7362v1", "published_time": "4/29/2014", "rawpid": "1404.7362", "tags": ["cs.CL", "stat.AP"], "title": "Concise comparative summaries (CCS) of large text corpora with a human\n  experiment"}, {"abstract": "In this study it is proven that the Hrebs used in Denotation analysis of\ntexts and Cohesion Chains (de?ned as a fusion between Lexical Chains and\nCoreference Chains) represent similar linguistic tools. This result gives us\nthe possibility to extend to Cohesion Chains (CCs) some important indicators\nas, for example the Kernel of CCs, the topicality of a CC, text concentration,\nCC-di?useness and mean di?useness of the text. Let us mention that nowhere in\nthe Lexical Chains or Coreference Chains literature these kinds of indicators\nare introduced and used since now. Similarly, some applications of CCs in the\nstudy of a text (as for example segmentation or summarization of a text) could\nbe realized starting from hrebs. As an illustration of the similarity between\nHrebs and CCs a detailed analyze of the poem \"Lacul\" by Mihai Eminescu is\ngiven.", "authors": ["D. Tatar", "M. Lupea", "E. Kapetanios"], "category": "cs.CL", "comment": "13 pages, KNOWLEDGE ENGINEERING: PRINCIPLES AND TECHNIQUES\n  Proceedings of the International Confer...", "img": "/static/thumbs/1401.3669v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1401.3669v1", "num_discussion": 0, "originally_published_time": "1/15/2014", "pid": "1401.3669v1", "published_time": "1/15/2014", "rawpid": "1401.3669", "tags": ["cs.CL"], "title": "Hrebs and Cohesion Chains as similar tools for semantic text properties\n  research"}, {"abstract": "We consider the unsupervised alignment of the full text of a book with a\nhuman-written summary. This presents challenges not seen in other text\nalignment problems, including a disparity in length and, consequent to this, a\nviolation of the expectation that individual words and phrases should align,\nsince large passages and chapters can be distilled into a single summary\nphrase. We present two new methods, based on hidden Markov models, specifically\ntargeted to this problem, and demonstrate gains on an extractive book\nsummarization task. While there is still much room for improvement,\nunsupervised alignment holds intrinsic value in offering insight into what\nfeatures of a book are deemed worthy of summarization.", "authors": ["David Bamman", "Noah A. Smith"], "category": "cs.CL", "comment": "This paper reflects work in progress", "img": "/static/thumbs/1305.1319v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1305.1319v1", "num_discussion": 0, "originally_published_time": "5/6/2013", "pid": "1305.1319v1", "published_time": "5/6/2013", "rawpid": "1305.1319", "tags": ["cs.CL"], "title": "New Alignment Methods for Discriminative Book Summarization"}, {"abstract": "Single document summarization generates summary by extracting the\nrepresentative sentences from the document. In this paper, we presented a novel\ntechnique for summarization of domain-specific text from a single web document\nthat uses statistical and linguistic analysis on the text in a reference corpus\nand the web document. The proposed summarizer uses the combinational function\nof Sentence Weight (SW) and Subject Weight (SuW) to determine the rank of a\nsentence, where SW is the function of number of terms (t_n) and number of words\n(w_n) in a sentence, and term frequency (t_f) in the corpus and SuW is the\nfunction of t_n and w_n in a subject, and t_f in the corpus. 30 percent of the\nranked sentences are considered to be the summary of the web document. We\ngenerated three web document summaries using our technique and compared each of\nthem with the summaries developed manually from 16 different human subjects.\nResults showed that 68 percent of the summaries produced by our approach\nsatisfy the manual summaries.", "authors": ["Rushdi Shams", "M. M. A. Hashem", "Afrina Hossain", "Suraiya Rumana Akter", "Monika Gope"], "category": "cs.IR", "comment": "", "img": "/static/thumbs/1304.2476v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1304.2476v1", "num_discussion": 0, "originally_published_time": "4/9/2013", "pid": "1304.2476v1", "published_time": "4/9/2013", "rawpid": "1304.2476", "tags": ["cs.IR", "cs.CL"], "title": "Corpus-based Web Document Summarization using Statistical and Linguistic\n  Approach"}, {"abstract": "This paper describes Artex, another algorithm for Automatic Text\nSummarization. In order to rank sentences, a simple inner product is calculated\nbetween each sentence, a document vector (text topic) and a lexical vector\n(vocabulary used by a sentence). Summaries are then generated by assembling the\nhighest ranked sentences. No ruled-based linguistic post-processing is\nnecessary in order to obtain summaries. Tests over several datasets (coming\nfrom Document Understanding Conferences (DUC), Text Analysis Conferences (TAC),\nevaluation campaigns, etc.) in French, English and Spanish have shown that\nsummarizer achieves interesting results.", "authors": ["Juan-Manuel Torres-Moreno"], "category": "cs.IR", "comment": "11 pages, 5 figures. arXiv admin note: substantial text overlap with\n  arXiv:1209.3126", "img": "/static/thumbs/1210.3312v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1210.3312v1", "num_discussion": 0, "originally_published_time": "10/11/2012", "pid": "1210.3312v1", "published_time": "10/11/2012", "rawpid": "1210.3312", "tags": ["cs.IR", "cs.AI", "cs.CL"], "title": "Artex is AnotheR TEXt summarizer"}, {"abstract": "This paper explores the real-time summarization of scheduled events such as\nsoccer games from torrential flows of Twitter streams. We propose and evaluate\nan approach that substantially shrinks the stream of tweets in real-time, and\nconsists of two steps: (i) sub-event detection, which determines if something\nnew has occurred, and (ii) tweet selection, which picks a representative tweet\nto describe each sub-event. We compare the summaries generated in three\nlanguages for all the soccer games in \"Copa America 2011\" to reference live\nreports offered by Yahoo! Sports journalists. We show that simple text analysis\nmethods which do not involve external knowledge lead to summaries that cover\n84% of the sub-events on average, and 100% of key types of sub-events (such as\ngoals in soccer). Our approach should be straightforwardly applicable to other\nkinds of scheduled events such as other sports, award ceremonies, keynote\ntalks, TV shows, etc.", "authors": ["Arkaitz Zubiaga", "Damiano Spina", "Enrique Amig\u00f3", "Julio Gonzalo"], "category": "cs.IR", "comment": "", "img": "/static/thumbs/1204.3731v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1204.3731v1", "num_discussion": 0, "originally_published_time": "4/17/2012", "pid": "1204.3731v1", "published_time": "4/17/2012", "rawpid": "1204.3731", "tags": ["cs.IR", "cs.CL", "cs.SI"], "title": "Towards Real-Time Summarization of Scheduled Events from Twitter Streams"}, {"abstract": "The rapid growth of scientific literature has made it difficult for the\nresearchers to quickly learn about the developments in their respective fields.\nScientific document summarization addresses this challenge by providing\nsummaries of the important contributions of scientific papers. We present a\nframework for scientific summarization which takes advantage of the citations\nand the scientific discourse structure. Citation texts often lack the evidence\nand context to support the content of the cited paper and are even sometimes\ninaccurate. We first address the problem of inaccuracy of the citation texts by\nfinding the relevant context from the cited paper. We propose three approaches\nfor contextualizing citations which are based on query reformulation, word\nembeddings, and supervised learning. We then train a model to identify the\ndiscourse facets for each citation. We finally propose a method for summarizing\nscientific papers by leveraging the faceted citations and their corresponding\ncontexts. We evaluate our proposed method on two scientific summarization\ndatasets in the biomedical and computational linguistics domains. Extensive\nevaluation results show that our methods can improve over the state of the art\nby large margins.", "authors": ["Arman Cohan", "Nazli Goharian"], "category": "cs.CL", "comment": "Preprint. The final publication is available at Springer via\n  http://dx.doi.org/10.1007/s00799-017-...", "img": "/static/thumbs/1706.03449v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1706.03449v1", "num_discussion": 0, "originally_published_time": "6/12/2017", "pid": "1706.03449v1", "published_time": "6/12/2017", "rawpid": "1706.03449", "tags": ["cs.CL", "cs.DL"], "title": "Scientific document summarization via citation contextualization and\n  scientific discourse"}, {"abstract": "Most video summarization approaches have focused on extracting a summary from\na single video; we propose an unsupervised framework for summarizing a\ncollection of videos. We observe that each video in the collection may contain\nsome information that other videos do not have, and thus exploring the\nunderlying complementarity could be beneficial in creating a diverse\ninformative summary. We develop a novel diversity-aware sparse optimization\nmethod for multi-video summarization by exploring the complementarity within\nthe videos. Our approach extracts a multi-video summary which is both\ninteresting and representative in describing the whole video collection. To\nefficiently solve our optimization problem, we develop an alternating\nminimization algorithm that minimizes the overall objective function with\nrespect to one video at a time while fixing the other videos. Moreover, we\nintroduce a new benchmark dataset, Tour20, that contains 140 videos with\nmultiple human created summaries, which were acquired in a controlled\nexperiment. Finally, by extensive experiments on the new Tour20 dataset and\nseveral other multi-view datasets, we show that the proposed approach clearly\noutperforms the state-of-the-art methods on the two problems-topic-oriented\nvideo summarization and multi-view video summarization in a camera network.", "authors": ["Rameswar Panda", "Niluthpol Chowdhury Mithun", "Amit K. Roy-Chowdhury"], "category": "cs.CV", "comment": "IEEE Trans. on Image Processing, 2017 (In Press)", "img": "/static/thumbs/1706.03123v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1706.03123v1", "num_discussion": 0, "originally_published_time": "6/9/2017", "pid": "1706.03123v1", "published_time": "6/9/2017", "rawpid": "1706.03123", "tags": ["cs.CV"], "title": "Diversity-aware Multi-Video Summarization"}, {"abstract": "Most traditional video summarization methods are designed to generate\neffective summaries for single-view videos, and thus they cannot fully exploit\nthe complicated intra and inter-view correlations in summarizing multi-view\nvideos in a camera network. In this paper, with the aim of summarizing\nmulti-view videos, we introduce a novel unsupervised framework via joint\nembedding and sparse representative selection. The objective function is\ntwo-fold. The first is to capture the multi-view correlations via an embedding,\nwhich helps in extracting a diverse set of representatives. The second is to\nuse a `2;1- norm to model the sparsity while selecting representative shots for\nthe summary. We propose to jointly optimize both of the objectives, such that\nembedding can not only characterize the correlations, but also indicate the\nrequirements of sparse representative selection. We present an efficient\nalternating algorithm based on half-quadratic minimization to solve the\nproposed non-smooth and non-convex objective with convergence analysis. A key\nadvantage of the proposed approach with respect to the state-of-the-art is that\nit can summarize multi-view videos without assuming any prior\ncorrespondences/alignment between them, e.g., uncalibrated camera networks.\nRigorous experiments on several multi-view datasets demonstrate that our\napproach clearly outperforms the state-of-the-art methods.", "authors": ["Rameswar Panda", "Amit K. Roy-Chowdhury"], "category": "cs.CV", "comment": "IEEE Trans. on Multimedia, 2017 (In Press)", "img": "/static/thumbs/1706.03121v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1706.03121v1", "num_discussion": 0, "originally_published_time": "6/9/2017", "pid": "1706.03121v1", "published_time": "6/9/2017", "rawpid": "1706.03121", "tags": ["cs.CV"], "title": "Multi-View Surveillance Video Summarization via Joint Embedding and\n  Sparse Optimization"}, {"abstract": "Citation texts are sometimes not very informative or in some cases inaccurate\nby themselves; they need the appropriate context from the referenced paper to\nreflect its exact contributions. To address this problem, we propose an\nunsupervised model that uses distributed representation of words as well as\ndomain knowledge to extract the appropriate context from the reference paper.\nEvaluation results show the effectiveness of our model by significantly\noutperforming the state-of-the-art. We furthermore demonstrate how an effective\ncontextualization method results in improving citation-based summarization of\nthe scientific articles.", "authors": ["Arman Cohan", "Nazli Goharian"], "category": "cs.CL", "comment": "SIGIR 2017", "img": "/static/thumbs/1705.08063v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1705.08063v1", "num_discussion": 0, "originally_published_time": "5/23/2017", "pid": "1705.08063v1", "published_time": "5/23/2017", "rawpid": "1705.08063", "tags": ["cs.CL", "cs.IR"], "title": "Contextualizing Citations for Scientific Summarization using Word\n  Embeddings and Domain Knowledge"}, {"abstract": "Attentional, RNN-based encoder-decoder models for abstractive summarization\nhave achieved good performance on short input and output sequences. However,\nfor longer documents and summaries, these models often include repetitive and\nincoherent phrases. We introduce a neural network model with intra-attention\nand a new training method. This method combines standard supervised word\nprediction and reinforcement learning (RL). Models trained only with the former\noften exhibit \"exposure bias\" -- they assume ground truth is provided at each\nstep during training. However, when standard word prediction is combined with\nthe global sequence prediction training of RL the resulting summaries become\nmore readable. We evaluate this model on the CNN/Daily Mail and New York Times\ndatasets. Our model obtains a 41.16 ROUGE-1 score on the CNN/Daily Mail\ndataset, a 5.7 absolute points improvement over previous state-of-the-art\nmodels. It also performs well as the first abstractive model on the New York\nTimes corpus. Human evaluation also shows that our model produces higher\nquality summaries.", "authors": ["Romain Paulus", "Caiming Xiong", "Richard Socher"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1705.04304v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1705.04304v2", "num_discussion": 0, "originally_published_time": "5/11/2017", "pid": "1705.04304v2", "published_time": "5/19/2017", "rawpid": "1705.04304", "tags": ["cs.CL"], "title": "A Deep Reinforced Model for Abstractive Summarization"}, {"abstract": "Abstractive summarization aims to generate a shorter version of the document\ncovering all the salient points in a compact and coherent fashion. On the other\nhand, query-based summarization highlights those points that are relevant in\nthe context of a given query. The encode-attend-decode paradigm has achieved\nnotable success in machine translation, extractive summarization, dialog\nsystems, etc. But it suffers from the drawback of generation of repeated\nphrases. In this work we propose a model for the query-based summarization task\nbased on the encode-attend-decode paradigm with two key additions (i) a query\nattention model (in addition to document attention model) which learns to focus\non different portions of the query at different time steps (instead of using a\nstatic representation for the query) and (ii) a new diversity based attention\nmodel which aims to alleviate the problem of repeating phrases in the summary.\nIn order to enable the testing of this model we introduce a new query-based\nsummarization dataset building on debatepedia. Our experiments show that with\nthese two additions the proposed model clearly outperforms vanilla\nencode-attend-decode models with a gain of 28\\% (absolute) in ROUGE-L scores.", "authors": ["Preksha Nema", "Mitesh Khapra", "Anirban Laha", "Balaraman Ravindran"], "category": "cs.CL", "comment": "Accepted at ACL 2017", "img": "/static/thumbs/1704.08300v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.08300v1", "num_discussion": 0, "originally_published_time": "4/26/2017", "pid": "1704.08300v1", "published_time": "4/26/2017", "rawpid": "1704.08300", "tags": ["cs.CL"], "title": "Diversity driven Attention Model for Query-based Abstractive\n  Summarization"}, {"abstract": "We propose a selective encoding model to extend the sequence-to-sequence\nframework for abstractive sentence summarization. It consists of a sentence\nencoder, a selective gate network, and an attention equipped decoder. The\nsentence encoder and decoder are built with recurrent neural networks. The\nselective gate network constructs a second level sentence representation by\ncontrolling the information flow from encoder to decoder. The second level\nrepresentation is tailored for sentence summarization task, which leads to\nbetter performance. We evaluate our model on the English Gigaword, DUC 2004 and\nMSR abstractive sentence summarization datasets. The experimental results show\nthat the proposed selective encoding model outperforms the state-of-the-art\nbaseline models.", "authors": ["Qingyu Zhou", "Nan Yang", "Furu Wei", "Ming Zhou"], "category": "cs.CL", "comment": "10 pages; To appear in ACL 2017", "img": "/static/thumbs/1704.07073v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.07073v1", "num_discussion": 0, "originally_published_time": "4/24/2017", "pid": "1704.07073v1", "published_time": "4/24/2017", "rawpid": "1704.07073", "tags": ["cs.CL"], "title": "Selective Encoding for Abstractive Sentence Summarization"}, {"abstract": "We propose a summarization approach for scientific articles which takes\nadvantage of citation-context and the document discourse model. While citations\nhave been previously used in generating scientific summaries, they lack the\nrelated context from the referenced article and therefore do not accurately\nreflect the article\u0027s content. Our method overcomes the problem of\ninconsistency between the citation summary and the article\u0027s content by\nproviding context for each citation. We also leverage the inherent scientific\narticle\u0027s discourse for producing better summaries. We show that our proposed\nmethod effectively improves over existing summarization approaches (greater\nthan 30% improvement over the best performing baseline) in terms of\n\\textsc{Rouge} scores on TAC2014 scientific summarization dataset. While the\ndataset we use for evaluation is in the biomedical domain, most of our\napproaches are general and therefore adaptable to other domains.", "authors": ["Arman Cohan", "Nazli Goharian"], "category": "cs.CL", "comment": "EMNLP 2015", "img": "/static/thumbs/1704.06619v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.06619v1", "num_discussion": 0, "originally_published_time": "4/21/2017", "pid": "1704.06619v1", "published_time": "4/21/2017", "rawpid": "1704.06619", "tags": ["cs.CL", "cs.IR"], "title": "Scientific Article Summarization Using Citation-Context and Article\u0027s\n  Discourse Structure"}, {"abstract": "Most extractive summarization methods focus on the main body of the document\nfrom which sentences need to be extracted. The gist of the document often lies\nin the side information of the document, such as title and image captions.\nThese types of side information are often available for newswire articles. We\npropose to explore side information in the context of single-document\nextractive summarization. We develop a framework for single-document\nsummarization composed of a hierarchical document encoder and an\nattention-based extractor with attention over side information. We evaluate our\nmodels on a large scale news dataset. We show that extractive summarization\nwith side information consistently outperforms its counterpart (that does not\nuse any side information), in terms on both informativeness and fluency.", "authors": ["Shashi Narayan", "Nikos Papasarantopoulos", "Mirella Lapata", "Shay B. Cohen"], "category": "cs.CL", "comment": "10 pages", "img": "/static/thumbs/1704.04530v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.04530v1", "num_discussion": 0, "originally_published_time": "4/14/2017", "pid": "1704.04530v1", "published_time": "4/14/2017", "rawpid": "1704.04530", "tags": ["cs.CL"], "title": "Neural Extractive Summarization with Side Information"}, {"abstract": "Multi-person tracking plays a critical role in the analysis of surveillance\nvideo. However, most existing work focus on shorter-term (e.g. minute-long or\nhour-long) video sequences. Therefore, we propose a multi-person tracking\nalgorithm for very long-term (e.g. month-long) multi-camera surveillance\nscenarios. Long-term tracking is challenging because 1) the apparel/appearance\nof the same person will vary greatly over multiple days and 2) a person will\nleave and re-enter the scene numerous times. To tackle these challenges, we\nleverage face recognition information, which is robust to apparel change, to\nautomatically reinitialize our tracker over multiple days of recordings.\nUnfortunately, recognized faces are unavailable oftentimes. Therefore, our\ntracker propagates identity information to frames without recognized faces by\nuncovering the appearance and spatial manifold formed by person detections. We\ntested our algorithm on a 23-day 15-camera data set (4,935 hours total), and we\nwere able to localize a person 53.2% of the time with 69.8% precision. We\nfurther performed video summarization experiments based on our tracking output.\nResults on 116.25 hours of video showed that we were able to generate a\nreasonable visual diary (i.e. a summary of what a person did) for different\npeople, thus potentially opening the door to automatic summarization of the\nvast amount of surveillance video generated every day.", "authors": ["Shoou-I Yu", "Yi Yang", "Xuanchong Li", "Alexander G. Hauptmann"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1604.07468v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1604.07468v2", "num_discussion": 0, "originally_published_time": "4/25/2016", "pid": "1604.07468v2", "published_time": "4/11/2017", "rawpid": "1604.07468", "tags": ["cs.CV"], "title": "Long-Term Identity-Aware Multi-Person Tracking for Surveillance Video\n  Summarization"}, {"abstract": "This paper addresses automatic summarization and search in visual data\ncomprising of videos, live streams and image collections in a unified manner.\nIn particular, we propose a framework for multi-faceted summarization which\nextracts key-frames (image summaries), skims (video summaries) and entity\nsummaries (summarization at the level of entities like objects, scenes, humans\nand faces in the video). The user can either view these as extractive\nsummarization, or query focused summarization. Our approach first pre-processes\nthe video or image collection once, to extract all important visual features,\nfollowing which we provide an interactive mechanism to the user to summarize\nthe video based on their choice. We investigate several diversity, coverage and\nrepresentation models for all these problems, and argue the utility of these\ndifferent mod- els depending on the application. While most of the prior work\non submodular summarization approaches has focused on combining several models\nand learning weighted mixtures, we focus on the explain-ability of different\nthe diversity, coverage and representation models and their scalability. Most\nimportantly, we also show that we can summarize hours of video data in a few\nseconds, and our system allows the user to generate summaries of various\nlengths and types interactively on the fly.", "authors": ["Anurag Sahoo", "Vishal Kaushal", "Khoshrav Doctor", "Suyash Shetty", "Rishabh Iyer", "Ganesh Ramakrishnan"], "category": "cs.CV", "comment": "18 pages, 11 Figures", "img": "/static/thumbs/1704.01466v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.01466v1", "num_discussion": 0, "originally_published_time": "4/4/2017", "pid": "1704.01466v1", "published_time": "4/4/2017", "rawpid": "1704.01466", "tags": ["cs.CV", "cs.DM"], "title": "A Unified Multi-Faceted Video Summarization System"}, {"abstract": "We present a robust approach for detecting intrinsic sentence importance in\nnews, by training on two corpora of document-summary pairs. When used for\nsingle-document summarization, our approach, combined with the \"beginning of\ndocument\" heuristic, outperforms a state-of-the-art summarizer and the\nbeginning-of-article baseline in both automatic and manual evaluations. These\nresults represent an important advance because in the absence of cross-document\nrepetition, single document summarizers for news have not been able to\nconsistently outperform the strong beginning-of-article baseline.", "authors": ["Yinfei Yang", "Forrest Sheng Bao", "Ani Nenkova"], "category": "cs.CL", "comment": "Accepted By EACL 2017", "img": "/static/thumbs/1702.07998v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1702.07998v1", "num_discussion": 0, "originally_published_time": "2/26/2017", "pid": "1702.07998v1", "published_time": "2/26/2017", "rawpid": "1702.07998", "tags": ["cs.CL"], "title": "Detecting (Un)Important Content for Single-Document News Summarization"}, {"abstract": "This paper tackles the reduction of redundant repeating generation that is\noften observed in RNN-based encoder-decoder models. Our basic idea is to\njointly estimate the upper-bound frequency of each target vocabulary in the\nencoder and control the output words based on the estimation in the decoder.\nOur method shows significant improvement over a strong RNN-based\nencoder-decoder baseline and achieved its best results on an abstractive\nsummarization benchmark.", "authors": ["Jun Suzuki", "Masaaki Nagata"], "category": "cs.CL", "comment": "7 pages, a draft version of EACL-2017", "img": "/static/thumbs/1701.00138v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1701.00138v2", "num_discussion": 0, "originally_published_time": "12/31/2016", "pid": "1701.00138v2", "published_time": "2/13/2017", "rawpid": "1701.00138", "tags": ["cs.CL", "cs.AI", "stat.ML"], "title": "Cutting-off Redundant Repeating Generations for Neural Abstractive\n  Summarization"}, {"abstract": "Applying generic media-agnostic summarization to music allows for higher\nefficiency in automatic processing, storage, and communication of datasets\nwhile also alleviating copyright issues. This process has already been proven\nuseful in the context of music genre classification. In this paper, we\ngeneralize conclusions from previous work by evaluating the impact of generic\nsummarization in music from a probabilistic perspective and agnostic relative\nto certain tasks. We estimate Gaussian distributions for original and\nsummarized songs and compute their relative entropy to measure how much\ninformation is lost in the summarization process. Based on this observation, we\nfurther propose a simple yet expressive summarization method that objectively\noutperforms previous methods and is better suited to avoid copyright issues. We\npresent results suggesting that relative entropy is a good predictor of\nsummarization performance in the context of tasks relying on a bag-of-features\nmodel.", "authors": ["Francisco Raposo", "David Martins de Matos", "Ricardo Ribeiro"], "category": "cs.IR", "comment": "5 pages, 1 table", "img": "/static/thumbs/1612.02350v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1612.02350v2", "num_discussion": 0, "originally_published_time": "12/7/2016", "pid": "1612.02350v2", "published_time": "12/28/2016", "rawpid": "1612.02350", "tags": ["cs.IR", "cs.LG", "cs.SD", "H.5.5"], "title": "An Information-theoretic Approach to Machine-oriented Music\n  Summarization"}, {"abstract": "Statistical topic models efficiently facilitate the exploration of\nlarge-scale data sets. Many models have been developed and broadly used to\nsummarize the semantic structure in news, science, social media, and digital\nhumanities. However, a common and practical objective in data exploration tasks\nis not to enumerate all existing topics, but to quickly extract representative\nones that broadly cover the content of the corpus, i.e., a few topics that\nserve as a good summary of the data. Most existing topic models fit exactly the\nsame number of topics as a user specifies, which have imposed an unnecessary\nburden to the users who have limited prior knowledge. We instead propose new\nmodels that are able to learn fewer but more representative topics for the\npurpose of data summarization. We propose a reinforced random walk that allows\nprominent topics to absorb tokens from similar and smaller topics, thus\nenhances the diversity among the top topics extracted. With this reinforced\nrandom walk as a general process embedded in classical topic models, we obtain\n\\textit{diverse topic models} that are able to extract the most prominent and\ndiverse topics from data. The inference procedures of these diverse topic\nmodels remain as simple and efficient as the classical models. Experimental\nresults demonstrate that the diverse topic models not only discover topics that\nbetter summarize the data, but also require minimal prior knowledge of the\nusers.", "authors": ["Jian Tang", "Cheng Li", "Ming Zhang", "Qiaozhu Mei"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1611.09921v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1611.09921v2", "num_discussion": 0, "originally_published_time": "11/29/2016", "pid": "1611.09921v2", "published_time": "12/1/2016", "rawpid": "1611.09921", "tags": ["cs.LG", "cs.CL", "cs.IR"], "title": "Less is More: Learning Prominent and Diverse Topics for Data\n  Summarization"}, {"abstract": "We present two novel and contrasting Recurrent Neural Network (RNN) based\narchitectures for extractive summarization of documents. The Classifier based\narchitecture sequentially accepts or rejects each sentence in the original\ndocument order for its membership in the final summary. The Selector\narchitecture, on the other hand, is free to pick one sentence at a time in any\narbitrary order to piece together the summary.\n  Our models under both architectures jointly capture the notions of salience\nand redundancy of sentences. In addition, these models have the advantage of\nbeing very interpretable, since they allow visualization of their predictions\nbroken up by abstract features such as information content, salience and\nredundancy.\n  We show that our models reach or outperform state-of-the-art supervised\nmodels on two different corpora. We also recommend the conditions under which\none architecture is superior to the other based on experimental evidence.", "authors": ["Ramesh Nallapati", "Bowen Zhou", "Mingbo Ma"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1611.04244v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1611.04244v1", "num_discussion": 0, "originally_published_time": "11/14/2016", "pid": "1611.04244v1", "published_time": "11/14/2016", "rawpid": "1611.04244", "tags": ["cs.CL"], "title": "Classify or Select: Neural Architectures for Extractive Document\n  Summarization"}, {"abstract": "We present SummaRuNNer, a Recurrent Neural Network (RNN) based sequence model\nfor extractive summarization of documents and show that it achieves performance\nbetter than or comparable to state-of-the-art. Our model has the additional\nadvantage of being very interpretable, since it allows visualization of its\npredictions broken up by abstract features such as information content,\nsalience and novelty. Another novel contribution of our work is abstractive\ntraining of our extractive model that can train on human generated reference\nsummaries alone, eliminating the need for sentence-level extractive labels.", "authors": ["Ramesh Nallapati", "Feifei Zhai", "Bowen Zhou"], "category": "cs.CL", "comment": "Published at AAAI 2017, The Thirty-First AAAI Conference on\n  Artificial Intelligence (AAAI-2017)", "img": "/static/thumbs/1611.04230v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1611.04230v1", "num_discussion": 0, "originally_published_time": "11/14/2016", "pid": "1611.04230v1", "published_time": "11/14/2016", "rawpid": "1611.04230", "tags": ["cs.CL"], "title": "SummaRuNNer: A Recurrent Neural Network based Sequence Model for\n  Extractive Summarization of Documents"}, {"abstract": "Many applications benefit from sampling algorithms where a small number of\nwell chosen samples are used to generalize different properties of a large\ndataset. In this paper, we use diverse sampling for streaming video\nsummarization. Several emerging applications support streaming video, but\nexisting summarization algorithms need access to the entire video which\nrequires a lot of memory and computational power. We propose a memory efficient\nand computationally fast, online algorithm that uses competitive learning for\ndiverse sampling. Our algorithm is a generalization of online K-means such that\nthe cost function reduces clustering error, while also ensuring a diverse set\nof samples. The diversity is measured as the volume of a convex hull around the\nsamples. Finally, the performance of the proposed algorithm is measured against\nhuman users for 50 videos in the VSUMM dataset. The algorithm performs better\nthan batch mode summarization, while requiring significantly lower memory and\ncomputational requirements.", "authors": ["Rushil Anirudh", "Ahnaf Masroor", "Pavan Turaga"], "category": "cs.CV", "comment": "Published at ICIP 2016", "img": "/static/thumbs/1610.09582v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1610.09582v1", "num_discussion": 0, "originally_published_time": "10/29/2016", "pid": "1610.09582v1", "published_time": "10/29/2016", "rawpid": "1610.09582", "tags": ["cs.CV"], "title": "Diversity Promoting Online Sampling for Streaming Video Summarization"}, {"abstract": "This paper presents a video summarization technique for an Internet video to\nprovide a quick way to overview its content. This is a challenging problem\nbecause finding important or informative parts of the original video requires\nto understand its content. Furthermore the content of Internet videos is very\ndiverse, ranging from home videos to documentaries, which makes video\nsummarization much more tough as prior knowledge is almost not available. To\ntackle this problem, we propose to use deep video features that can encode\nvarious levels of content semantics, including objects, actions, and scenes,\nimproving the efficiency of standard video summarization techniques. For this,\nwe design a deep neural network that maps videos as well as descriptions to a\ncommon semantic space and jointly trained it with associated pairs of videos\nand descriptions. To generate a video summary, we extract the deep features\nfrom each segment of the original video and apply a clustering-based\nsummarization technique to them. We evaluate our video summaries using the\nSumMe dataset as well as baseline approaches. The results demonstrated the\nadvantages of incorporating our deep semantic features in a video summarization\ntechnique.", "authors": ["Mayu Otani", "Yuta Nakashima", "Esa Rahtu", "Janne Heikkil\u00e4", "Naokazu Yokoya"], "category": "cs.CV", "comment": "16 pages, the 13th Asian Conference on Computer Vision (ACCV\u002716)", "img": "/static/thumbs/1609.08758v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1609.08758v1", "num_discussion": 0, "originally_published_time": "9/28/2016", "pid": "1609.08758v1", "published_time": "9/28/2016", "rawpid": "1609.08758", "tags": ["cs.CV"], "title": "Video Summarization using Deep Semantic Features"}, {"abstract": "Query relevance ranking and sentence saliency ranking are the two main tasks\nin extractive query-focused summarization. Previous supervised summarization\nsystems often perform the two tasks in isolation. However, since reference\nsummaries are the trade-off between relevance and saliency, using them as\nsupervision, neither of the two rankers could be trained well. This paper\nproposes a novel summarization system called AttSum, which tackles the two\ntasks jointly. It automatically learns distributed representations for\nsentences as well as the document cluster. Meanwhile, it applies the attention\nmechanism to simulate the attentive reading of human behavior when a query is\ngiven. Extensive experiments are conducted on DUC query-focused summarization\nbenchmark datasets. Without using any hand-crafted features, AttSum achieves\ncompetitive performance. It is also observed that the sentences recognized to\nfocus on the query indeed meet the query need.", "authors": ["Ziqiang Cao", "Wenjie Li", "Sujian Li", "Furu Wei", "Yanran Li"], "category": "cs.IR", "comment": "10 pages, 1 figure", "img": "/static/thumbs/1604.00125v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1604.00125v2", "num_discussion": 0, "originally_published_time": "4/1/2016", "pid": "1604.00125v2", "published_time": "9/27/2016", "rawpid": "1604.00125", "tags": ["cs.IR", "cs.CL"], "title": "AttSum: Joint Learning of Focusing and Summarization with Neural\n  Attention"}, {"abstract": "Automatic summarization techniques on meeting conversations developed so far\nhave been primarily extractive, resulting in poor summaries. To improve this,\nwe propose an approach to generate abstractive summaries by fusing important\ncontent from several utterances. Any meeting is generally comprised of several\ndiscussion topic segments. For each topic segment within a meeting\nconversation, we aim to generate a one sentence summary from the most important\nutterances using an integer linear programming-based sentence fusion approach.\nExperimental results show that our method can generate more informative\nsummaries than the baselines.", "authors": ["Siddhartha Banerjee", "Prasenjit Mitra", "Kazunari Sugiyama"], "category": "cs.CL", "comment": "WWW \u002715 Companion Proceedings of the 24th International Conference on\n  World Wide Web, Pages 5-6", "img": "/static/thumbs/1609.07035v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1609.07035v1", "num_discussion": 0, "originally_published_time": "9/22/2016", "pid": "1609.07035v1", "published_time": "9/22/2016", "rawpid": "1609.07035", "tags": ["cs.CL"], "title": "Abstractive Meeting Summarization UsingDependency Graph Fusion"}, {"abstract": "Abstractive summarization is an ideal form of summarization since it can\nsynthesize information from multiple documents to create concise informative\nsummaries. In this work, we aim at developing an abstractive summarizer. First,\nour proposed approach identifies the most important document in the\nmulti-document set. The sentences in the most important document are aligned to\nsentences in other documents to generate clusters of similar sentences. Second,\nwe generate K-shortest paths from the sentences in each cluster using a\nword-graph structure. Finally, we select sentences from the set of shortest\npaths generated from all the clusters employing a novel integer linear\nprogramming (ILP) model with the objective of maximizing information content\nand readability of the final summary. Our ILP model represents the shortest\npaths as binary variables and considers the length of the path, information\nscore and linguistic quality score in the objective function. Experimental\nresults on the DUC 2004 and 2005 multi-document summarization datasets show\nthat our proposed approach outperforms all the baselines and state-of-the-art\nextractive summarizers as measured by the ROUGE scores. Our method also\noutperforms a recent abstractive summarization technique. In manual evaluation,\nour approach also achieves promising results on informativeness and\nreadability.", "authors": ["Siddhartha Banerjee", "Prasenjit Mitra", "Kazunari Sugiyama"], "category": "cs.CL", "comment": "IJCAI\u002715 Proceedings of the 24th International Conference on\n  Artificial Intelligence, Pages 1208-1...", "img": "/static/thumbs/1609.07034v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1609.07034v1", "num_discussion": 0, "originally_published_time": "9/22/2016", "pid": "1609.07034v1", "published_time": "9/22/2016", "rawpid": "1609.07034", "tags": ["cs.CL"], "title": "Multi-document abstractive summarization using ILP based multi-sentence\n  compression"}, {"abstract": "Novel information retrieval methods to identify citations relevant to a\nclinical topic can overcome the knowledge gap existing between the primary\nliterature (MEDLINE) and online clinical knowledge resources such as UpToDate.\nSearching the MEDLINE database directly or with query expansion methods returns\na large number of citations that are not relevant to the query. The current\nstudy presents a citation retrieval system that retrieves citations for\nevidence-based clinical knowledge summarization. This approach combines query\nexpansion, concept-based screening algorithm, and concept-based vector\nsimilarity. We also propose an information extraction framework for automated\nconcept (Population, Intervention, Comparison, and Disease) extraction. We\nevaluated our proposed system on all topics (as queries) available from\nUpToDate for two diseases, heart failure (HF) and atrial fibrillation (AFib).\nThe system achieved an overall F-score of 41.2% on HF topics and 42.4% on AFib\ntopics on a gold standard of citations available in UpToDate. This is\nsignificantly high when compared to a query-expansion based baseline (F-score\nof 1.3% on HF and 2.2% on AFib) and a system that uses query expansion with\ndisease hyponyms and journal names, concept-based screening, and term-based\nvector similarity system (F-score of 37.5% on HF and 39.5% on AFib). Evaluating\nthe system with top K relevant citations, where K is the number of citations in\nthe gold standard achieved a much higher overall F-score of 69.9% on HF topics\nand 75.1% on AFib topics. In addition, the system retrieved up to 18 new\nrelevant citations per topic when tested on ten HF and six AFib clinical\ntopics.", "authors": ["Kalpana Raja", "Andrew J Sauer", "Ravi P Garg", "Melanie R Klerer", "Siddhartha R Jonnalagadda"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1609.01597v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1609.01597v1", "num_discussion": 0, "originally_published_time": "9/6/2016", "pid": "1609.01597v1", "published_time": "9/6/2016", "rawpid": "1609.01597", "tags": ["cs.CL", "cs.IR"], "title": "A Hybrid Citation Retrieval Algorithm for Evidence-based Clinical\n  Knowledge Summarization: Combining Concept Extraction, Vector Similarity and\n  Query Expansion for High Precision"}, {"abstract": "While most existing video summarization approaches aim to extract an\ninformative summary of a single video, we propose a novel framework for\nsummarizing multi-view videos by exploiting both intra- and inter-view content\ncorrelations in a joint embedding space. We learn the embedding by minimizing\nan objective function that has two terms: one due to intra-view correlations\nand another due to inter-view correlations across the multiple views. The\nsolution can be obtained directly by solving one Eigen-value problem that is\nlinear in the number of multi-view videos. We then employ a sparse\nrepresentative selection approach over the learned embedding space to summarize\nthe multi-view videos. Experimental results on several benchmark datasets\ndemonstrate that our proposed approach clearly outperforms the\nstate-of-the-art.", "authors": ["Rameswar Panda", "Abir Das", "Amit K. Roy-Chowdhury"], "category": "cs.CV", "comment": "Accepted in ICPR 2016", "img": "/static/thumbs/1608.00310v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1608.00310v1", "num_discussion": 0, "originally_published_time": "8/1/2016", "pid": "1608.00310v1", "published_time": "8/1/2016", "rawpid": "1608.00310", "tags": ["cs.CV"], "title": "Video Summarization in a Multi-View Camera Network"}, {"abstract": "We propose a novel supervised learning technique for summarizing videos by\nautomatically selecting keyframes or key subshots. Casting the problem as a\nstructured prediction problem on sequential data, our main idea is to use Long\nShort-Term Memory (LSTM), a special type of recurrent neural networks to model\nthe variable-range dependencies entailed in the task of video summarization.\nOur learning models attain the state-of-the-art results on two benchmark video\ndatasets. Detailed analysis justifies the design of the models. In particular,\nwe show that it is crucial to take into consideration the sequential structures\nin videos and model them. Besides advances in modeling techniques, we introduce\ntechniques to address the need of a large number of annotated data for training\ncomplex learning models. There, our main idea is to exploit the existence of\nauxiliary annotated video datasets, albeit heterogeneous in visual styles and\ncontents. Specifically, we show domain adaptation techniques can improve\nsummarization by reducing the discrepancies in statistical properties across\nthose datasets.", "authors": ["Ke Zhang", "Wei-Lun Chao", "Fei Sha", "Kristen Grauman"], "category": "cs.CV", "comment": "To appear in ECCV 2016", "img": "/static/thumbs/1605.08110v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1605.08110v2", "num_discussion": 0, "originally_published_time": "5/26/2016", "pid": "1605.08110v2", "published_time": "7/29/2016", "rawpid": "1605.08110", "tags": ["cs.CV", "cs.LG"], "title": "Video Summarization with Long Short-term Memory"}, {"abstract": "Word embedding methods revolve around learning continuous distributed vector\nrepresentations of words with neural networks, which can capture semantic\nand/or syntactic cues, and in turn be used to induce similarity measures among\nwords, sentences and documents in context. Celebrated methods can be\ncategorized as prediction-based and count-based methods according to the\ntraining objectives and model architectures. Their pros and cons have been\nextensively analyzed and evaluated in recent studies, but there is relatively\nless work continuing the line of research to develop an enhanced learning\nmethod that brings together the advantages of the two model families. In\naddition, the interpretation of the learned word representations still remains\nsomewhat opaque. Motivated by the observations and considering the pressing\nneed, this paper presents a novel method for learning the word representations,\nwhich not only inherits the advantages of classic word embedding methods but\nalso offers a clearer and more rigorous interpretation of the learned word\nrepresentations. Built upon the proposed word embedding method, we further\nformulate a translation-based language modeling framework for the extractive\nspeech summarization task. A series of empirical evaluations demonstrate the\neffectiveness of the proposed word representation learning and language\nmodeling techniques in extractive speech summarization.", "authors": ["Kuan-Yu Chen", "Shih-Hung Liu", "Berlin Chen", "Hsin-Min Wang", "Hsin-Hsi Chen"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1607.06532v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1607.06532v1", "num_discussion": 0, "originally_published_time": "7/22/2016", "pid": "1607.06532v1", "published_time": "7/22/2016", "rawpid": "1607.06532", "tags": ["cs.CL", "cs.AI", "cs.IR", "cs.MM"], "title": "Novel Word Embedding and Translation-based Language Modeling for\n  Extractive Speech Summarization"}, {"abstract": "Video data is explosively growing. As a result of the \"big video data\",\nintelligent algorithms for automatic video summarization have re-emerged as a\npressing need. We develop a probabilistic model, Sequential and Hierarchical\nDeterminantal Point Process (SH-DPP), for query-focused extractive video\nsummarization. Given a user query and a long video sequence, our algorithm\nreturns a summary by selecting key shots from the video. The decision to\ninclude a shot in the summary depends on the shot\u0027s relevance to the user query\nand importance in the context of the video, jointly. We verify our approach on\ntwo densely annotated video datasets. The query-focused video summarization is\nparticularly useful for search engines, e.g., to display snippets of videos.", "authors": ["Aidean Sharghi", "Boqing Gong", "Mubarak Shah"], "category": "cs.CV", "comment": "Accepted to ECCV 2016", "img": "/static/thumbs/1607.05177v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1607.05177v1", "num_discussion": 0, "originally_published_time": "7/18/2016", "pid": "1607.05177v1", "published_time": "7/18/2016", "rawpid": "1607.05177", "tags": ["cs.CV"], "title": "Query-Focused Extractive Video Summarization"}, {"abstract": "In this work, we introduce temporal hierarchies to the sequence to sequence\n(seq2seq) model to tackle the problem of abstractive summarization of\nscientific articles. The proposed Multiple Timescale model of the Gated\nRecurrent Unit (MTGRU) is implemented in the encoder-decoder setting to better\ndeal with the presence of multiple compositionalities in larger texts. The\nproposed model is compared to the conventional RNN encoder-decoder, and the\nresults demonstrate that our model trains faster and shows significant\nperformance gains. The results also show that the temporal hierarchies help\nimprove the ability of seq2seq models to capture compositionalities better\nwithout the presence of highly complex architectural hierarchies.", "authors": ["Minsoo Kim", "Moirangthem Dennis Singh", "Minho Lee"], "category": "cs.CL", "comment": "To appear in RepL4NLP at ACL 2016", "img": "/static/thumbs/1607.00718v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1607.00718v1", "num_discussion": 0, "originally_published_time": "7/4/2016", "pid": "1607.00718v1", "published_time": "7/4/2016", "rawpid": "1607.00718", "tags": ["cs.CL"], "title": "Towards Abstraction from Extraction: Multiple Timescale Gated Recurrent\n  Unit for Summarization"}, {"abstract": "Traditional approaches to extractive summarization rely heavily on\nhuman-engineered features. In this work we propose a data-driven approach based\non neural networks and continuous sentence features. We develop a general\nframework for single-document summarization composed of a hierarchical document\nencoder and an attention-based extractor. This architecture allows us to\ndevelop different classes of summarization models which can extract sentences\nor words. We train our models on large scale corpora containing hundreds of\nthousands of document-summary pairs. Experimental results on two summarization\ndatasets demonstrate that our models obtain results comparable to the state of\nthe art without any access to linguistic annotation.", "authors": ["Jianpeng Cheng", "Mirella Lapata"], "category": "cs.CL", "comment": "ACL2016 conference paper with appendix", "img": "/static/thumbs/1603.07252v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1603.07252v3", "num_discussion": 0, "originally_published_time": "3/23/2016", "pid": "1603.07252v3", "published_time": "7/1/2016", "rawpid": "1603.07252", "tags": ["cs.CL"], "title": "Neural Summarization by Extracting Sentences and Words"}, {"abstract": "We present a novel unsupervised framework for focused meeting summarization\nthat views the problem as an instance of relation extraction. We adapt an\nexisting in-domain relation learner (Chen et al., 2011) by exploiting a set of\ntask-specific constraints and features. We evaluate the approach on a decision\nsummarization task and show that it outperforms unsupervised utterance-level\nextractive summarization baselines as well as an existing generic\nrelation-extraction-based summarization method. Moreover, our approach produces\nsummaries competitive with those generated by supervised methods in terms of\nthe standard ROUGE score.", "authors": ["Lu Wang", "Claire Cardie"], "category": "cs.CL", "comment": "SIGDIAL 2012", "img": "/static/thumbs/1606.07849v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1606.07849v1", "num_discussion": 0, "originally_published_time": "6/24/2016", "pid": "1606.07849v1", "published_time": "6/24/2016", "rawpid": "1606.07849", "tags": ["cs.CL"], "title": "Focused Meeting Summarization via Unsupervised Relation Extraction"}, {"abstract": "We present a token-level decision summarization framework that utilizes the\nlatent topic structures of utterances to identify \"summary-worthy\" words.\nConcretely, a series of unsupervised topic models is explored and experimental\nresults show that fine-grained topic models, which discover topics at the\nutterance-level rather than the document-level, can better identify the gist of\nthe decision-making process. Moreover, our proposed token-level summarization\napproach, which is able to remove redundancies within utterances, outperforms\nexisting utterance ranking based summarization methods. Finally, context\ninformation is also investigated to add additional relevant information to the\nsummary.", "authors": ["Lu Wang", "Claire Cardie"], "category": "cs.CL", "comment": "SIGDIAL 2012", "img": "/static/thumbs/1606.07829v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1606.07829v1", "num_discussion": 0, "originally_published_time": "6/24/2016", "pid": "1606.07829v1", "published_time": "6/24/2016", "rawpid": "1606.07829", "tags": ["cs.CL"], "title": "Unsupervised Topic Modeling Approaches to Decision Summarization in\n  Spoken Meetings"}, {"abstract": "We consider the problem of using sentence compression techniques to\nfacilitate query-focused multi-document summarization. We present a\nsentence-compression-based framework for the task, and design a series of\nlearning-based compression models built on parse trees. An innovative beam\nsearch decoder is proposed to efficiently find highly probable compressions.\nUnder this framework, we show how to integrate various indicative metrics such\nas linguistic motivation and query relevance into the compression process by\nderiving a novel formulation of a compression scoring function. Our best model\nachieves statistically significant improvement over the state-of-the-art\nsystems on several metrics (e.g. 8.0% and 5.4% improvements in ROUGE-2\nrespectively) for the DUC 2006 and 2007 summarization task.", "authors": ["Lu Wang", "Hema Raghavan", "Vittorio Castelli", "Radu Florian", "Claire Cardie"], "category": "cs.CL", "comment": "ACL 2013", "img": "/static/thumbs/1606.07548v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1606.07548v1", "num_discussion": 0, "originally_published_time": "6/24/2016", "pid": "1606.07548v1", "published_time": "6/24/2016", "rawpid": "1606.07548", "tags": ["cs.CL"], "title": "A Sentence Compression Based Framework to Query-Focused Multi-Document\n  Summarization"}, {"abstract": "In the era of Big Data and Deep Learning, there is a common view that machine\nlearning approaches are the only way to cope with the robust and scalable\ninformation extraction and summarization. It has been recently proposed that\nthe CNL approach could be scaled up, building on the concept of embedded CNL\nand, thus, allowing for CNL-based information extraction from e.g. normative or\nmedical texts that are rather controlled by nature but still infringe the\nboundaries of CNL. Although it is arguable if CNL can be exploited to approach\nthe robust wide-coverage semantic parsing for use cases like media monitoring,\nits potential becomes much more obvious in the opposite direction: generation\nof story highlights from the summarized AMR graphs, which is in the focus of\nthis position paper.", "authors": ["Normunds Gruzitis", "Guntis Barzdins"], "category": "cs.CL", "comment": "Proceedings of the 5th Workshop on Controlled Natural Language, 2016\n  (to appear)", "img": "/static/thumbs/1606.05994v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1606.05994v1", "num_discussion": 0, "originally_published_time": "6/20/2016", "pid": "1606.05994v1", "published_time": "6/20/2016", "rawpid": "1606.05994", "tags": ["cs.CL"], "title": "The Role of CNL and AMR in Scalable Abstractive Summarization for\n  Multilingual Media Monitoring"}, {"abstract": "In this paper we explore the problem of document summarization in Persian\nlanguage from two distinct angles. In our first approach, we modify a popular\nand widely cited Persian document summarization framework to see how it works\non a realistic corpus of news articles. Human evaluation on generated summaries\nshows that graph-based methods perform better than the modified systems. We\ncarry this intuition forward in our second approach, and probe deeper into the\nnature of graph-based systems by designing several summarizers based on\ncentrality measures. Ad hoc evaluation using ROUGE score on these summarizers\nsuggests that there is a small class of centrality measures that perform better\nthan three strong unsupervised baselines.", "authors": ["Saeid Parvandeh", "Shibamouli Lahiri", "Fahimeh Boroumand"], "category": "cs.CL", "comment": "42 pages, 9 figures", "img": "/static/thumbs/1606.03143v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1606.03143v1", "num_discussion": 0, "originally_published_time": "6/9/2016", "pid": "1606.03143v1", "published_time": "6/9/2016", "rawpid": "1606.03143", "tags": ["cs.CL"], "title": "PerSum: Novel Systems for Document Summarization in Persian"}, {"abstract": "Attention mechanisms in neural networks have proved useful for problems in\nwhich the input and output do not have fixed dimension. Often there exist\nfeatures that are locally translation invariant and would be valuable for\ndirecting the model\u0027s attention, but previous attentional architectures are not\nconstructed to learn such features specifically. We introduce an attentional\nneural network that employs convolution on the input tokens to detect local\ntime-invariant and long-range topical attention features in a context-dependent\nway. We apply this architecture to the problem of extreme summarization of\nsource code snippets into short, descriptive function name-like summaries.\nUsing those features, the model sequentially generates a summary by\nmarginalizing over two attention mechanisms: one that predicts the next summary\ntoken based on the attention weights of the input tokens and another that is\nable to copy a code token as-is directly into the summary. We demonstrate our\nconvolutional attention neural network\u0027s performance on 10 popular Java\nprojects showing that it achieves better performance compared to previous\nattentional mechanisms.", "authors": ["Miltiadis Allamanis", "Hao Peng", "Charles Sutton"], "category": "cs.LG", "comment": "Code, data and visualization at\n  http://groups.inf.ed.ac.uk/cup/codeattention/", "img": "/static/thumbs/1602.03001v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1602.03001v2", "num_discussion": 0, "originally_published_time": "2/9/2016", "pid": "1602.03001v2", "published_time": "5/25/2016", "rawpid": "1602.03001", "tags": ["cs.LG", "cs.CL", "cs.SE"], "title": "A Convolutional Attention Network for Extreme Summarization of Source\n  Code"}, {"abstract": "Video summarization has unprecedented importance to help us digest, browse,\nand search today\u0027s ever-growing video collections. We propose a novel subset\nselection technique that leverages supervision in the form of human-created\nsummaries to perform automatic keyframe-based video summarization. The main\nidea is to nonparametrically transfer summary structures from annotated videos\nto unseen test videos. We show how to extend our method to exploit semantic\nside information about the video\u0027s category/genre to guide the transfer process\nby those training videos semantically consistent with the test input. We also\nshow how to generalize our method to subshot-based summarization, which not\nonly reduces computational costs but also provides more flexible ways of\ndefining visual similarity across subshots spanning several frames. We conduct\nextensive evaluation on several benchmarks and demonstrate promising results,\noutperforming existing methods in several settings.", "authors": ["Ke Zhang", "Wei-Lun Chao", "Fei Sha", "Kristen Grauman"], "category": "cs.CV", "comment": "CVPR 2016 camera ready", "img": "/static/thumbs/1603.03369v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1603.03369v3", "num_discussion": 0, "originally_published_time": "3/10/2016", "pid": "1603.03369v3", "published_time": "4/29/2016", "rawpid": "1603.03369", "tags": ["cs.CV"], "title": "Summary Transfer: Exemplar-based Subset Selection for Video\n  Summarization"}, {"abstract": "This article presents new alternatives to the similarity function for the\nTextRank algorithm for automatic summarization of texts. We describe the\ngeneralities of the algorithm and the different functions we propose. Some of\nthese variants achieve a significative improvement using the same metrics and\ndataset as the original publication.", "authors": ["Federico Barrios", "Federico L\u00f3pez", "Luis Argerich", "Rosa Wachenchauzer"], "category": "cs.CL", "comment": "8 pages, 2 figures. Presented at the Argentine Symposium on\n  Artificial Intelligence (ASAI) 2015 - ...", "img": "/static/thumbs/1602.03606v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1602.03606v1", "num_discussion": 0, "originally_published_time": "2/11/2016", "pid": "1602.03606v1", "published_time": "2/11/2016", "rawpid": "1602.03606", "tags": ["cs.CL", "cs.IR", "I.2.7"], "title": "Variations of the Similarity Function of TextRank for Automated\n  Summarization"}, {"abstract": "Extractive summarization aims at selecting a set of indicative sentences from\na source document as a summary that can express the major theme of the\ndocument. A general consensus on extractive summarization is that both\nrelevance and coverage are critical issues to address. The existing methods\ndesigned to model coverage can be characterized by either reducing redundancy\nor increasing diversity in the summary. Maximal margin relevance (MMR) is a\nwidely-cited method since it takes both relevance and redundancy into account\nwhen generating a summary for a given document. In addition to MMR, there is\nonly a dearth of research concentrating on reducing redundancy or increasing\ndiversity for the spoken document summarization task, as far as we are aware.\nMotivated by these observations, two major contributions are presented in this\npaper. First, in contrast to MMR, which considers coverage by reducing\nredundancy, we propose two novel coverage-based methods, which directly\nincrease diversity. With the proposed methods, a set of representative\nsentences, which not only are relevant to the given document but also cover\nmost of the important sub-themes of the document, can be selected\nautomatically. Second, we make a step forward to plug in several\ndocument/sentence representation methods into the proposed framework to further\nenhance the summarization performance. A series of empirical evaluations\ndemonstrate the effectiveness of our proposed methods.", "authors": ["Kuan-Yu Chen", "Shih-Hung Liu", "Berlin Chen", "Hsin-Min Wang"], "category": "cs.CL", "comment": "arXiv admin note: text overlap with arXiv:1506.04365", "img": "/static/thumbs/1601.05194v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1601.05194v1", "num_discussion": 0, "originally_published_time": "1/20/2016", "pid": "1601.05194v1", "published_time": "1/20/2016", "rawpid": "1601.05194", "tags": ["cs.CL", "cs.IR"], "title": "Improved Spoken Document Summarization with Coverage Modeling Techniques"}, {"abstract": "We address the problem of maximizing an unknown submodular function that can\nonly be accessed via noisy evaluations. Our work is motivated by the task of\nsummarizing content, e.g., image collections, by leveraging users\u0027 feedback in\nform of clicks or ratings. For summarization tasks with the goal of maximizing\ncoverage and diversity, submodular set functions are a natural choice. When the\nunderlying submodular function is unknown, users\u0027 feedback can provide noisy\nevaluations of the function that we seek to maximize. We provide a generic\nalgorithm -- \\submM{} -- for maximizing an unknown submodular function under\ncardinality constraints. This algorithm makes use of a novel exploration module\n-- \\blbox{} -- that proposes good elements based on adaptively sampling noisy\nfunction evaluations. \\blbox{} is able to accommodate different kinds of\nobservation models such as value queries and pairwise comparisons. We provide\nPAC-style guarantees on the quality and sampling cost of the solution obtained\nby \\submM{}. We demonstrate the effectiveness of our approach in an\ninteractive, crowdsourced image collection summarization application.", "authors": ["Adish Singla", "Sebastian Tschiatschek", "Andreas Krause"], "category": "cs.AI", "comment": "Extended version of AAAI\u002716 paper", "img": "/static/thumbs/1511.07211v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1511.07211v2", "num_discussion": 0, "originally_published_time": "11/23/2015", "pid": "1511.07211v2", "published_time": "12/1/2015", "rawpid": "1511.07211", "tags": ["cs.AI", "cs.LG", "stat.ML"], "title": "Noisy Submodular Maximization via Adaptive Sampling with Applications to\n  Crowdsourced Image Collection Summarization"}, {"abstract": "This paper considers Aspect-based Opinion Summarization (AOS) of reviews on\nparticular products. To enable real applications, an AOS system needs to\naddress two core subtasks, aspect extraction and sentiment classification. Most\nexisting approaches to aspect extraction, which use linguistic analysis or\ntopic modeling, are general across different products but not precise enough or\nsuitable for particular products. Instead we take a less general but more\nprecise scheme, directly mapping each review sentence into pre-defined aspects.\nTo tackle aspect mapping and sentiment classification, we propose two\nConvolutional Neural Network (CNN) based methods, cascaded CNN and multitask\nCNN. Cascaded CNN contains two levels of convolutional networks. Multiple CNNs\nat level 1 deal with aspect mapping task, and a single CNN at level 2 deals\nwith sentiment classification. Multitask CNN also contains multiple aspect CNNs\nand a sentiment CNN, but different networks share the same word embeddings.\nExperimental results indicate that both cascaded and multitask CNNs outperform\nSVM-based methods by large margins. Multitask CNN generally performs better\nthan cascaded CNN.", "authors": ["Haibing Wu", "Yiwei Gu", "Shangdi Sun", "Xiaodong Gu"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1511.09128v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1511.09128v1", "num_discussion": 0, "originally_published_time": "11/30/2015", "pid": "1511.09128v1", "published_time": "11/30/2015", "rawpid": "1511.09128", "tags": ["cs.CL", "cs.IR", "cs.LG"], "title": "Aspect-based Opinion Summarization with Convolutional Neural Networks"}, {"abstract": "The development of summarization research has been significantly hampered by\nthe costly acquisition of reference summaries. This paper proposes an effective\nway to automatically collect large scales of news-related multi-document\nsummaries with reference to social media\u0027s reactions. We utilize two types of\nsocial labels in tweets, i.e., hashtags and hyper-links. Hashtags are used to\ncluster documents into different topic sets. Also, a tweet with a hyper-link\noften highlights certain key points of the corresponding document. We\nsynthesize a linked document cluster to form a reference summary which can\ncover most key points. To this aim, we adopt the ROUGE metrics to measure the\ncoverage ratio, and develop an Integer Linear Programming solution to discover\nthe sentence set reaching the upper bound of ROUGE. Since we allow summary\nsentences to be selected from both documents and high-quality tweets, the\ngenerated reference summaries could be abstractive. Both informativeness and\nreadability of the collected summaries are verified by manual judgment. In\naddition, we train a Support Vector Regression summarizer on DUC generic\nmulti-document summarization benchmarks. With the collected data as extra\ntraining resource, the performance of the summarizer improves a lot on all the\ntest sets. We release this dataset for further research.", "authors": ["Ziqiang Cao", "Chengyao Chen", "Wenjie Li", "Sujian Li", "Furu Wei", "Ming Zhou"], "category": "cs.IR", "comment": "7 pages, 1 figure in AAAI 2016", "img": "/static/thumbs/1511.08417v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1511.08417v1", "num_discussion": 0, "originally_published_time": "11/26/2015", "pid": "1511.08417v1", "published_time": "11/26/2015", "rawpid": "1511.08417", "tags": ["cs.IR", "cs.CL"], "title": "TGSum: Build Tweet Guided Multi-Document Summarization Dataset"}, {"abstract": "Traditional methods on video summarization are designed to generate summaries\nfor single-view video records; and thus they cannot fully exploit the\nredundancy in multi-view video records. In this paper, we present a multi-view\nmetric learning framework for multi-view video summarization that combines the\nadvantages of maximum margin clustering with the disagreement minimization\ncriterion. The learning framework thus has the ability to find a metric that\nbest separates the data, and meanwhile to force the learned metric to maintain\noriginal intrinsic information between data points, for example geometric\ninformation. Facilitated by such a framework, a systematic solution to the\nmulti-view video summarization problem is developed. To the best of our\nknowledge, it is the first time to address multi-view video summarization from\nthe viewpoint of metric learning. The effectiveness of the proposed method is\ndemonstrated by experiments.", "authors": ["Yanwei Fu", "Lingbo Wang", "Yanwen Guo"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1405.6434v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1405.6434v2", "num_discussion": 0, "originally_published_time": "5/25/2014", "pid": "1405.6434v2", "published_time": "11/25/2015", "rawpid": "1405.6434", "tags": ["cs.CV", "cs.LG", "cs.MM"], "title": "Multi-view Metric Learning for Multi-view Video Summarization"}, {"abstract": "With the rapid increase of users of wearable cameras in recent years and of\nthe amount of data they produce, there is a strong need for automatic retrieval\nand summarization techniques. This work addresses the problem of automatically\nsummarizing egocentric photo streams captured through a wearable camera by\ntaking an image retrieval perspective. After removing non-informative images by\na new CNN-based filter, images are ranked by relevance to ensure semantic\ndiversity and finally re-ranked by a novelty criterion to reduce redundancy. To\nassess the results, a new evaluation metric is proposed which takes into\naccount the non-uniqueness of the solution. Experimental results applied on a\ndatabase of 7,110 images from 6 different subjects and evaluated by experts\ngave 95.74% of experts satisfaction and a Mean Opinion Score of 4.57 out of\n5.0.", "authors": ["Aniol Lidon", "Marc Bola\u00f1os", "Mariella Dimiccoli", "Petia Radeva", "Maite Garolera", "Xavier Gir\u00f3-i-Nieto"], "category": "cs.CV", "comment": "12 pages, 16 figures, 2 tables. Submitted to Transactions on Human\n  Machine Systems", "img": "/static/thumbs/1511.00438v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1511.00438v2", "num_discussion": 0, "originally_published_time": "11/2/2015", "pid": "1511.00438v2", "published_time": "11/20/2015", "rawpid": "1511.00438", "tags": ["cs.CV"], "title": "Semantic Summarization of Egocentric Photo Stream Events"}, {"abstract": "Emotional content is a key element in user-generated videos. However, it is\ndifficult to understand emotions conveyed in such videos due to the complex and\nunstructured nature of user-generated content and the sparsity of video frames\nthat express emotion. In this paper, for the first time, we study the problem\nof transferring knowledge from heterogeneous external sources, including image\nand textual data, to facilitate three related tasks in video emotion\nunderstanding: emotion recognition, emotion attribution and emotion-oriented\nsummarization. Specifically, our framework (1) learns a video encoding from an\nauxiliary emotional image dataset in order to improve supervised video emotion\nrecognition, and (2) transfers knowledge from an auxiliary textual corpus for\nzero-shot \\pl{recognition} of emotion classes unseen during training. The\nproposed technique for knowledge transfer facilitates novel applications of\nemotion attribution and emotion-oriented summarization. A comprehensive set of\nexperiments on multiple datasets demonstrate the effectiveness of our\nframework.", "authors": ["Baohan Xu", "Yanwei Fu", "Yu-Gang Jiang", "Boyang Li", "Leonid Sigal"], "category": "cs.CV", "comment": "13 pages, 11 figures", "img": "/static/thumbs/1511.04798v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1511.04798v1", "num_discussion": 0, "originally_published_time": "11/16/2015", "pid": "1511.04798v1", "published_time": "11/16/2015", "rawpid": "1511.04798", "tags": ["cs.CV", "cs.AI", "cs.MM"], "title": "Heterogeneous Knowledge Transfer in Video Emotion Recognition,\n  Attribution and Summarization"}, {"abstract": "State-of-the-art extractive multi-document summarization systems are usually\ndesigned without any concern about privacy issues, meaning that all documents\nare open to third parties. In this paper we propose a privacy-preserving\napproach to multi-document summarization. Our approach enables other parties to\nobtain summaries without learning anything else about the original documents\u0027\ncontent. We use a hashing scheme known as Secure Binary Embeddings to convert\ndocuments representation containing key phrases and bag-of-words into bit\nstrings, allowing the computation of approximate distances, instead of exact\nones. Our experiments indicate that our system yields similar results to its\nnon-private counterpart on standard multi-document evaluation datasets.", "authors": ["Lu\u00eds Marujo", "Jos\u00e9 Port\u00ealo", "Wang Ling", "David Martins de Matos", "Jo\u00e3o P. Neto", "Anatole Gershman", "Jaime Carbonell", "Isabel Trancoso", "Bhiksha Raj"], "category": "cs.IR", "comment": "4 pages, In Proceedings of 2nd ACM SIGIR Workshop on\n  Privacy-Preserving Information Retrieval, Aug...", "img": "/static/thumbs/1508.01420v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1508.01420v1", "num_discussion": 0, "originally_published_time": "8/6/2015", "pid": "1508.01420v1", "published_time": "8/6/2015", "rawpid": "1508.01420", "tags": ["cs.IR", "cs.CL", "cs.CR", "H.3; I.2.7; K.4.1"], "title": "Privacy-Preserving Multi-Document Summarization"}, {"abstract": "The growing rate of public space CCTV installations has generated a need for\nautomated methods for exploiting video surveillance data including scene\nunderstanding, query, behaviour annotation and summarization. For this reason,\nextensive research has been performed on surveillance scene understanding and\nanalysis. However, most studies have considered single scenes, or groups of\nadjacent scenes. The semantic similarity between different but related scenes\n(e.g., many different traffic scenes of similar layout) is not generally\nexploited to improve any automated surveillance tasks and reduce manual effort.\nExploiting commonality, and sharing any supervised annotations, between\ndifferent scenes is however challenging due to: Some scenes are totally\nun-related -- and thus any information sharing between them would be\ndetrimental; while others may only share a subset of common activities -- and\nthus information sharing is only useful if it is selective. Moreover,\nsemantically similar activities which should be modelled together and shared\nacross scenes may have quite different pixel-level appearance in each scene. To\naddress these issues we develop a new framework for distributed multiple-scene\nglobal understanding that clusters surveillance scenes by their ability to\nexplain each other\u0027s behaviours; and further discovers which subset of\nactivities are shared versus scene-specific within each cluster. We show how to\nuse this structured representation of multiple scenes to improve common\nsurveillance tasks including scene activity understanding, cross-scene\nquery-by-example, behaviour classification with reduced supervised labelling\nrequirements, and video summarization. In each case we demonstrate how our\nmulti-scene model improves on a collection of standard single scene models and\na flat model of all scenes.", "authors": ["Xun Xu", "Timothy Hospedales", "Shaogang Gong"], "category": "cs.CV", "comment": "Multi-Scene Traffic Behaviour Analysis ---- Accepted at IEEE\n  Transactions on Circuits and Systems ...", "img": "/static/thumbs/1507.07458v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1507.07458v1", "num_discussion": 0, "originally_published_time": "7/27/2015", "pid": "1507.07458v1", "published_time": "7/27/2015", "rawpid": "1507.07458", "tags": ["cs.CV"], "title": "Discovery of Shared Semantic Spaces for Multi-Scene Video Query and\n  Summarization"}, {"abstract": "Existing multi-document summarization systems usually rely on a specific\nsummarization model (i.e., a summarization method with a specific parameter\nsetting) to extract summaries for different document sets with different\ntopics. However, according to our quantitative analysis, none of the existing\nsummarization models can always produce high-quality summaries for different\ndocument sets, and even a summarization model with good overall performance may\nproduce low-quality summaries for some document sets. On the contrary, a\nbaseline summarization model may produce high-quality summaries for some\ndocument sets. Based on the above observations, we treat the summaries produced\nby different summarization models as candidate summaries, and then explore\ndiscriminative reranking techniques to identify high-quality summaries from the\ncandidates for difference document sets. We propose to extract a set of\ncandidate summaries for each document set based on an ILP framework, and then\nleverage Ranking SVM for summary reranking. Various useful features have been\ndeveloped for the reranking process, including word-level features,\nsentence-level features and summary-level features. Evaluation results on the\nbenchmark DUC datasets validate the efficacy and robustness of our proposed\napproach.", "authors": ["Xiaojun Wan", "Ziqiang Cao", "Furu Wei", "Sujian Li", "Ming Zhou"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1507.02062v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1507.02062v1", "num_discussion": 0, "originally_published_time": "7/8/2015", "pid": "1507.02062v1", "published_time": "7/8/2015", "rawpid": "1507.02062", "tags": ["cs.CL"], "title": "Multi-Document Summarization via Discriminative Summary Reranking"}, {"abstract": "We propose an abstraction-based multi-document summarization framework that\ncan construct new sentences by exploring more fine-grained syntactic units than\nsentences, namely, noun/verb phrases. Different from existing abstraction-based\napproaches, our method first constructs a pool of concepts and facts\nrepresented by phrases from the input documents. Then new sentences are\ngenerated by selecting and merging informative phrases to maximize the salience\nof phrases and meanwhile satisfy the sentence construction constraints. We\nemploy integer linear optimization for conducting phrase selection and merging\nsimultaneously in order to achieve the global optimal solution for a summary.\nExperimental results on the benchmark data set TAC 2011 show that our framework\noutperforms the state-of-the-art models under automated pyramid evaluation\nmetric, and achieves reasonably well results on manual linguistic quality\nevaluation.", "authors": ["Lidong Bing", "Piji Li", "Yi Liao", "Wai Lam", "Weiwei Guo", "Rebecca J. Passonneau"], "category": "cs.CL", "comment": "11 pages, 1 figure, accepted as a full paper at ACL 2015", "img": "/static/thumbs/1506.01597v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1506.01597v2", "num_discussion": 0, "originally_published_time": "6/4/2015", "pid": "1506.01597v2", "published_time": "6/5/2015", "rawpid": "1506.01597", "tags": ["cs.CL", "cs.AI"], "title": "Abstractive Multi-Document Summarization via Phrase Selection and\n  Merging"}, {"abstract": "We present a video summarization approach for egocentric or \"wearable\" camera\ndata. Given hours of video, the proposed method produces a compact storyboard\nsummary of the camera wearer\u0027s day. In contrast to traditional keyframe\nselection techniques, the resulting summary focuses on the most important\nobjects and people with which the camera wearer interacts. To accomplish this,\nwe develop region cues indicative of high-level saliency in egocentric\nvideo---such as the nearness to hands, gaze, and frequency of occurrence---and\nlearn a regressor to predict the relative importance of any new region based on\nthese cues. Using these predictions and a simple form of temporal event\ndetection, our method selects frames for the storyboard that reflect the key\nobject-driven happenings. We adjust the compactness of the final summary given\neither an importance selection criterion or a length budget; for the latter, we\ndesign an efficient dynamic programming solution that accounts for importance,\nvisual uniqueness, and temporal displacement. Critically, the approach is\nneither camera-wearer-specific nor object-specific; that means the learned\nimportance metric need not be trained for a given user or context, and it can\npredict the importance of objects and people that have never been seen\npreviously. Our results on two egocentric video datasets show the method\u0027s\npromise relative to existing techniques for saliency and summarization.", "authors": ["Yong Jae Lee", "Kristen Grauman"], "category": "cs.CV", "comment": "Published in the International Journal of Computer Vision (IJCV),\n  January 2015", "img": "/static/thumbs/1505.04803v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1505.04803v1", "num_discussion": 0, "originally_published_time": "5/18/2015", "pid": "1505.04803v1", "published_time": "5/18/2015", "rawpid": "1505.04803", "tags": ["cs.CV"], "title": "Predicting Important Objects for Egocentric Video Summarization"}, {"abstract": "The application and usage of opinion mining, especially for business\nintelligence, product recommendation, targeted marketing etc. have fascinated\nmany research attentions around the globe. Various research efforts attempted\nto mine opinions from customer reviews at different levels of granularity,\nincluding word-, sentence-, and document-level. However, development of a fully\nautomatic opinion mining and sentiment analysis system is still elusive. Though\nthe development of opinion mining and sentiment analysis systems are getting\nmomentum, most of them attempt to perform document-level sentiment analysis,\nclassifying a review document as positive, negative, or neutral. Such\ndocument-level opinion mining approaches fail to provide insight about users\nsentiment on individual features of a product or service. Therefore, it seems\nto be a great help for both customers and manufacturers, if the reviews could\nbe processed at a finer-grained level and presented in a summarized form\nthrough some visual means, highlighting individual features of a product and\nusers sentiment expressed over them. In this paper, the design of a unified\nopinion mining and sentiment analysis framework is presented at the\nintersection of both machine learning and natural language processing\napproaches. Also, design of a novel feature-level review summarization scheme\nis proposed to visualize mined features, opinions and their polarity values in\na comprehendible way.", "authors": ["Ahmad Kamal"], "category": "cs.IR", "comment": "6 pages, 5 figures, 2 tables", "img": "/static/thumbs/1504.03068v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1504.03068v2", "num_discussion": 0, "originally_published_time": "4/13/2015", "pid": "1504.03068v2", "published_time": "4/23/2015", "rawpid": "1504.03068", "tags": ["cs.IR", "cs.CL"], "title": "Review Mining for Feature Based Opinion Summarization and Visualization"}, {"abstract": "Compact keyframe-based video summaries are a popular way of generating\nviewership on video sharing platforms. Yet, creating relevant and compelling\nsummaries for arbitrarily long videos with a small number of keyframes is a\nchallenging task. We propose a comprehensive keyframe-based summarization\nframework combining deep convolutional neural networks and restricted Boltzmann\nmachines. An original co-regularization scheme is used to discover meaningful\nsubject-scene associations. The resulting multimodal representations are then\nused to select highly-relevant keyframes. A comprehensive user study is\nconducted comparing our proposed method to a variety of schemes, including the\nsummarization currently in use by one of the most popular video sharing\nwebsites. The results show that our method consistently outperforms the\nbaseline schemes for any given amount of keyframes both in terms of\nattractiveness and informativeness. The lead is even more significant for\nsmaller summaries.", "authors": ["Olivier Mor\u00e8re", "Hanlin Goh", "Antoine Veillard", "Vijay Chandrasekhar", "Jie Lin"], "category": "cs.CV", "comment": "Video summarization, deep convolutional neural networks,\n  co-regularized restricted Boltzmann machi...", "img": "/static/thumbs/1501.07738v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1501.07738v1", "num_discussion": 0, "originally_published_time": "1/30/2015", "pid": "1501.07738v1", "published_time": "1/30/2015", "rawpid": "1501.07738", "tags": ["cs.CV"], "title": "Co-Regularized Deep Representations for Video Summarization"}, {"abstract": "Multi-document summarization is a process of automatic generation of a\ncompressed version of the given collection of documents. Recently, the\ngraph-based models and ranking algorithms have been actively investigated by\nthe extractive document summarization community. While most work to date\nfocuses on homogeneous connecteness of sentences and heterogeneous connecteness\nof documents and sentences (e.g. sentence similarity weighted by document\nimportance), in this paper we present a novel 3-layered graph model that\nemphasizes not only sentence and document level relations but also the\ninfluence of under sentence level relations (e.g. a part of sentence\nsimilarity).", "authors": ["Ercan Canhasi"], "category": "cs.IR", "comment": "", "img": "/static/thumbs/1405.7975v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1405.7975v1", "num_discussion": 0, "originally_published_time": "5/17/2014", "pid": "1405.7975v1", "published_time": "5/17/2014", "rawpid": "1405.7975", "tags": ["cs.IR", "cs.CL"], "title": "Multi-layered graph-based multi-document summarization model"}, {"abstract": "We study the problem of predicting a set or list of options under knapsack\nconstraint. The quality of such lists are evaluated by a submodular reward\nfunction that measures both quality and diversity. Similar to DAgger (Ross et\nal., 2010), by a reduction to online learning, we show how to adapt two\nsequence prediction models to imitate greedy maximization under knapsack\nconstraint problems: CONSEQOPT (Dey et al., 2012) and SCP (Ross et al., 2013).\nExperiments on extractive multi-document summarization show that our approach\noutperforms existing state-of-the-art methods.", "authors": ["Jiaji Zhou", "Stephane Ross", "Yisong Yue", "Debadeepta Dey", "J. Andrew Bagnell"], "category": "cs.LG", "comment": "8 pages, ICML 2013 Workshop on Inferning: Interactions between\n  Inference and Learning", "img": "/static/thumbs/1308.3541v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1308.3541v2", "num_discussion": 0, "originally_published_time": "8/16/2013", "pid": "1308.3541v2", "published_time": "3/15/2014", "rawpid": "1308.3541", "tags": ["cs.LG"], "title": "Knapsack Constrained Contextual Submodular List Prediction with\n  Application to Multi-document Summarization"}, {"abstract": "Graph-based semi-supervised learning has proven to be an effective approach\nfor query-focused multi-document summarization. The problem of previous\nsemi-supervised learning is that sentences are ranked without considering the\nhigher level information beyond sentence level. Researches on general\nsummarization illustrated that the addition of topic level can effectively\nimprove the summary quality. Inspired by previous researches, we propose a\ntwo-layer (i.e. sentence layer and topic layer) graph-based semi-supervised\nlearning approach. At the same time, we propose a novel topic model which makes\nfull use of the dependence between sentences and words. Experimental results on\nDUC and TAC data sets demonstrate the effectiveness of our proposed approach.", "authors": ["Jiwei Li", "Sujian Li"], "category": "cs.CL", "comment": "This paper has been withdrawn by the author due to a crucial sign\n  error in equation", "img": "/static/thumbs/1212.2036v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1212.2036v3", "num_discussion": 0, "originally_published_time": "12/10/2012", "pid": "1212.2036v3", "published_time": "12/31/2013", "rawpid": "1212.2036", "tags": ["cs.CL", "cs.IR"], "title": "Query-focused Multi-document Summarization: Combining a Novel Topic\n  Model with Graph-based Semi-supervised Learning"}, {"abstract": "Both supervised learning methods and LDA based topic model have been\nsuccessfully applied in the field of query focused multi-document\nsummarization. In this paper, we propose a novel supervised approach that can\nincorporate rich sentence features into Bayesian topic models in a principled\nway, thus taking advantages of both topic model and feature based supervised\nlearning methods. Experiments on TAC2008 and TAC2009 demonstrate the\neffectiveness of our approach.", "authors": ["Jiwei Li", "Sujian Li"], "category": "cs.CL", "comment": "This paper has been withdrawn by the author due to a crucial sign\n  error in equation", "img": "/static/thumbs/1212.2006v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1212.2006v2", "num_discussion": 0, "originally_published_time": "12/10/2012", "pid": "1212.2006v2", "published_time": "12/27/2013", "rawpid": "1212.2006", "tags": ["cs.CL", "cs.IR"], "title": "A Novel Feature-based Bayesian Model for Query Focused Multi-document\n  Summarization"}, {"abstract": "We present an approach for dictionary learning of action attributes via\ninformation maximization. We unify the class distribution and appearance\ninformation into an objective function for learning a sparse dictionary of\naction attributes. The objective function maximizes the mutual information\nbetween what has been learned and what remains to be learned in terms of\nappearance information and class distribution for each dictionary atom. We\npropose a Gaussian Process (GP) model for sparse representation to optimize the\ndictionary objective function. The sparse coding property allows a kernel with\ncompact support in GP to realize a very efficient dictionary learning process.\nHence we can describe an action video by a set of compact and discriminative\naction attributes. More importantly, we can recognize modeled action categories\nin a sparse feature space, which can be generalized to unseen and unmodeled\naction categories. Experimental results demonstrate the effectiveness of our\napproach in action recognition and summarization.", "authors": ["Qiang Qiu", "Zhuolin Jiang", "Rama Chellappa"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1308.0290v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1308.0290v1", "num_discussion": 0, "originally_published_time": "8/1/2013", "pid": "1308.0290v1", "published_time": "8/1/2013", "rawpid": "1308.0290", "tags": ["cs.CV"], "title": "Sparse Dictionary-based Attributes for Action Recognition and\n  Summarization"}, {"abstract": "We introduce a method to learn a mixture of submodular \"shells\" in a\nlarge-margin setting. A submodular shell is an abstract submodular function\nthat can be instantiated with a ground set and a set of parameters to produce a\nsubmodular function. A mixture of such shells can then also be so instantiated\nto produce a more complex submodular function. What our algorithm learns are\nthe mixture weights over such shells. We provide a risk bound guarantee when\nlearning in a large-margin structured-prediction setting using a projected\nsubgradient method when only approximate submodular optimization is possible\n(such as with submodular function maximization). We apply this method to the\nproblem of multi-document summarization and produce the best results reported\nso far on the widely used NIST DUC-05 through DUC-07 document summarization\ncorpora.", "authors": ["Hui Lin", "Jeff A. Bilmes"], "category": "cs.LG", "comment": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (...", "img": "/static/thumbs/1210.4871v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1210.4871v1", "num_discussion": 0, "originally_published_time": "10/16/2012", "pid": "1210.4871v1", "published_time": "10/16/2012", "rawpid": "1210.4871", "tags": ["cs.LG", "cs.CL", "cs.IR", "stat.ML"], "title": "Learning Mixtures of Submodular Shells with Application to Document\n  Summarization"}, {"abstract": "The Generative Adversarial Network (GAN) has achieved great success in\ngenerating realistic (real-valued) synthetic data. However, convergence issues\nand difficulties dealing with discrete data hinder the applicability of GAN to\ntext. We propose a framework for generating realistic text via adversarial\ntraining. We employ a long short-term memory network as generator, and a\nconvolutional network as discriminator. Instead of using the standard objective\nof GAN, we propose matching the high-dimensional latent feature distributions\nof real and synthetic sentences, via a kernelized discrepancy metric. This\neases adversarial training by alleviating the mode-collapsing problem. Our\nexperiments show superior performance in quantitative evaluation, and\ndemonstrate that our model can generate realistic-looking sentences.", "authors": ["Yizhe Zhang", "Zhe Gan", "Kai Fan", "Zhi Chen", "Ricardo Henao", "Dinghan Shen", "Lawrence Carin"], "category": "stat.ML", "comment": "Accepted by ICML 2017", "img": "/static/thumbs/1706.03850v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1706.03850v1", "num_discussion": 0, "originally_published_time": "6/12/2017", "pid": "1706.03850v1", "published_time": "6/12/2017", "rawpid": "1706.03850", "tags": ["stat.ML", "cs.CL", "cs.LG"], "title": "Adversarial Feature Matching for Text Generation"}, {"abstract": "Text extraction is an important problem in image processing with applications\nfrom optical character recognition to autonomous driving. Most of the\ntraditional text segmentation algorithms consider separating text from a simple\nbackground (which usually has a different color from texts). In this work we\nconsider separating texts from a textured background, that has similar color to\ntexts. We look at this problem from a signal decomposition perspective, and\nconsider a more realistic scenario where signal components are overlaid on top\nof each other (instead of adding together). When the signals are overlaid, to\nseparate signal components, we need to find a binary mask which shows the\nsupport of each component. Because directly solving the binary mask is\nintractable, we relax this problem to the approximated continuous problem, and\nsolve it by alternating optimization method. We show that the proposed\nalgorithm achieves significantly better results than other recent works on\nseveral challenging images.", "authors": ["Shervin Minaee", "Yao Wang"], "category": "cs.CV", "comment": "arXiv admin note: text overlap with arXiv:1704.07711", "img": "/static/thumbs/1706.04041v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1706.04041v1", "num_discussion": 0, "originally_published_time": "6/11/2017", "pid": "1706.04041v1", "published_time": "6/11/2017", "rawpid": "1706.04041", "tags": ["cs.CV"], "title": "Text Extraction From Texture Images Using Masked Signal Decomposition"}, {"abstract": "This work presents a fine-grained, text-chunking algorithm designed for the\ntask of multiword expressions (MWEs) segmentation. As a lexical class, MWEs\ninclude a wide variety of idioms, whose automatic identification are a\nnecessity for the handling of colloquial language. This algorithm\u0027s core\nnovelty is its use of non-word tokens, i.e., boundaries, in a bottom-up\nstrategy. Leveraging boundaries refines token-level information, forging\nhigh-level performance from relatively basic data. The generality of this\nmodel\u0027s feature space allows for its application across languages and domains.\nExperiments spanning 19 different languages exhibit a broadly-applicable,\nstate-of-the-art model. Evaluation against recent shared-task data places text\npartitioning as the overall, best performing MWE segmentation algorithm,\ncovering all MWE classes and multiple English domains (including user-generated\ntext). This performance, coupled with a non-combinatorial, fast-running design,\nproduces an ideal combination for implementations at scale, which are\nfacilitated through the release of open-source software.", "authors": ["Jake Ryland Williams"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1608.02025v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1608.02025v3", "num_discussion": 0, "originally_published_time": "8/5/2016", "pid": "1608.02025v3", "published_time": "6/9/2017", "rawpid": "1608.02025", "tags": ["cs.CL"], "title": "Boundary-based MWE segmentation with text partitioning"}, {"abstract": "We present a deterministic algorithm for Russian inflection. This algorithm\nis implemented in a publicly available web-service www.passare.ru which\nprovides functions for inflection of single words, word matching and synthesis\nof grammatically correct Russian text. The inflectional functions have been\ntested against the annotated corpus of Russian language OpenCorpora.", "authors": ["T. M. Sadykov", "T. A. Zhukov"], "category": "cs.CL", "comment": "9 pages, 1 figure", "img": "/static/thumbs/1706.02551v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1706.02551v1", "num_discussion": 0, "originally_published_time": "6/8/2017", "pid": "1706.02551v1", "published_time": "6/8/2017", "rawpid": "1706.02551", "tags": ["cs.CL", "68T35"], "title": "The Algorithmic Inflection of Russian and Generation of Grammatically\n  Correct Text"}, {"abstract": "In this paper we propose an approach to lexicon-free recognition of text in\nscene images. Our approach relies on a LSTM-based soft visual attention model\nlearned from convolutional features. A set of feature vectors are derived from\nan intermediate convolutional layer corresponding to different areas of the\nimage. This permits encoding of spatial information into the image\nrepresentation. In this way, the framework is able to learn how to selectively\nfocus on different parts of the image. At every time step the recognizer emits\none character using a weighted combination of the convolutional feature vectors\naccording to the learned attention model. Training can be done end-to-end using\nonly word level annotations. In addition, we show that modifying the beam\nsearch algorithm by integrating an explicit language model leads to\nsignificantly better recognition results. We validate the performance of our\napproach on standard SVT and ICDAR\u002703 scene text datasets, showing\nstate-of-the-art performance in unconstrained text recognition.", "authors": ["Suman K. Ghosh", "Ernest Valveny", "Andrew D. Bagdanov"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1706.01487v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1706.01487v1", "num_discussion": 0, "originally_published_time": "6/5/2017", "pid": "1706.01487v1", "published_time": "6/5/2017", "rawpid": "1706.01487", "tags": ["cs.CV"], "title": "Visual attention models for scene text recognition"}, {"abstract": "Recently deeplearning models have been shown to be capable of making\nremarkable performance in sentences and documents classification tasks. In this\nwork, we propose a novel framework called AC-BLSTM for modeling sentences and\ndocuments, which combines the asymmetric convolution neural network (ACNN) with\nthe Bidirectional Long Short-Term Memory network (BLSTM). Experiment results\ndemonstrate that our model achieves state-of-the-art results on five tasks,\nincluding sentiment analysis, question type classification, and subjectivity\nclassification. In order to further improve the performance of AC-BLSTM, we\npropose a semi-supervised learning framework called G-AC-BLSTM for text\nclassification by combining the generative model with AC-BLSTM.", "authors": ["Depeng Liang", "Yongdong Zhang"], "category": "cs.CL", "comment": "9 pages", "img": "/static/thumbs/1611.01884v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1611.01884v3", "num_discussion": 0, "originally_published_time": "11/7/2016", "pid": "1611.01884v3", "published_time": "6/5/2017", "rawpid": "1611.01884", "tags": ["cs.CL"], "title": "AC-BLSTM: Asymmetric Convolutional Bidirectional LSTM Networks for Text\n  Classification"}, {"abstract": "Autoencoders have been successful in learning meaningful representations from\nimage datasets. However, their performance on text datasets has not been widely\nstudied. Traditional autoencoders tend to learn possibly trivial\nrepresentations of text documents due to their confounding properties such as\nhigh-dimensionality, sparsity and power-law word distributions. In this paper,\nwe propose a novel k-competitive autoencoder, called KATE, for text documents.\nDue to the competition between the neurons in the hidden layer, each neuron\nbecomes specialized in recognizing specific data patterns, and overall the\nmodel can learn meaningful representations of textual data. A comprehensive set\nof experiments show that KATE can learn better representations than traditional\nautoencoders including denoising, contractive, variational, and k-sparse\nautoencoders. Our model also outperforms deep generative models, probabilistic\ntopic models, and even word representation models (e.g., Word2Vec) in terms of\nseveral downstream tasks such as document classification, regression, and\nretrieval.", "authors": ["Yu Chen", "Mohammed J. Zaki"], "category": "stat.ML", "comment": "10 pages, KDD\u002717", "img": "/static/thumbs/1705.02033v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1705.02033v2", "num_discussion": 0, "originally_published_time": "5/4/2017", "pid": "1705.02033v2", "published_time": "6/4/2017", "rawpid": "1705.02033", "tags": ["stat.ML", "cs.LG"], "title": "KATE: K-Competitive Autoencoder for Text"}, {"abstract": "Learning a good representation of text is key to many recommendation\napplications. Examples include news recommendation where texts to be\nrecommended are constantly published everyday. However, most existing\nrecommendation techniques, such as matrix factorization based methods, mainly\nrely on interaction histories to learn representations of items. While latent\nfactors of items can be learned effectively from user interaction data, in many\ncases, such data is not available, especially for newly emerged items.\n  In this work, we aim to address the problem of personalized recommendation\nfor completely new items with text information available. We cast the problem\nas a personalized text ranking problem and propose a general framework that\ncombines text embedding with personalized recommendation. Users and textual\ncontent are embedded into latent feature space. The text embedding function can\nbe learned end-to-end by predicting user interactions with items. To alleviate\nsparsity in interaction data, and leverage large amount of text data with\nlittle or no user interactions, we further propose a joint text embedding model\nthat incorporates unsupervised text embedding with a combination module.\nExperimental results show that our model can significantly improve the\neffectiveness of recommendation systems on real-world datasets.", "authors": ["Ting Chen", "Liangjie Hong", "Yue Shi", "Yizhou Sun"], "category": "cs.IR", "comment": "", "img": "/static/thumbs/1706.01084v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1706.01084v1", "num_discussion": 0, "originally_published_time": "6/4/2017", "pid": "1706.01084v1", "published_time": "6/4/2017", "rawpid": "1706.01084", "tags": ["cs.IR", "cs.LG"], "title": "Joint Text Embedding for Personalized Content-based Recommendation"}, {"abstract": "Translating information between text and image is a fundamental problem in\nartificial intelligence that connects natural language processing and computer\nvision. In the past few years, performance in image caption generation has seen\nsignificant improvement through the adoption of recurrent neural networks\n(RNN). Meanwhile, text-to-image generation begun to generate plausible images\nusing datasets of specific categories like birds and flowers. We\u0027ve even seen\nimage generation from multi-category datasets such as the Microsoft Common\nObjects in Context (MSCOCO) through the use of generative adversarial networks\n(GANs). Synthesizing objects with a complex shape, however, is still\nchallenging. For example, animals and humans have many degrees of freedom,\nwhich means that they can take on many complex shapes. We propose a new\ntraining method called Image-Text-Image (I2T2I) which integrates text-to-image\nand image-to-text (image captioning) synthesis to improve the performance of\ntext-to-image synthesis. We demonstrate that %the capability of our method to\nunderstand the sentence descriptions, so as to I2T2I can generate better\nmulti-categories images using MSCOCO than the state-of-the-art. We also\ndemonstrate that I2T2I can achieve transfer learning by using a pre-trained\nimage captioning module to generate human images on the MPII Human Pose", "authors": ["Hao Dong", "Jingqing Zhang", "Douglas McIlwraith", "Yike Guo"], "category": "cs.CV", "comment": "International Conference on Image Processing (ICIP) 2017", "img": "/static/thumbs/1703.06676v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1703.06676v3", "num_discussion": 0, "originally_published_time": "3/20/2017", "pid": "1703.06676v3", "published_time": "6/3/2017", "rawpid": "1703.06676", "tags": ["cs.CV", "cs.CL"], "title": "I2T2I: Learning Text to Image Synthesis with Textual Data Augmentation"}, {"abstract": "Motivated by concerns for user privacy, we design a steganographic system\n(\"stegosystem\") that enables two users to exchange encrypted messages without\nan adversary detecting that such an exchange is taking place. We propose a new\nlinguistic stegosystem based on a Long Short-Term Memory (LSTM) neural network.\nWe demonstrate our approach on the Twitter and Enron email datasets and show\nthat it yields high-quality steganographic text while significantly improving\ncapacity (encrypted bits per word) relative to the state-of-the-art.", "authors": ["Tina Fang", "Martin Jaggi", "Katerina Argyraki"], "category": "cs.AI", "comment": "ACL 2017 Student Research Workshop", "img": "/static/thumbs/1705.10742v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1705.10742v1", "num_discussion": 0, "originally_published_time": "5/30/2017", "pid": "1705.10742v1", "published_time": "5/30/2017", "rawpid": "1705.10742", "tags": ["cs.AI", "cs.CR", "cs.MM", "E.3; I.2.7"], "title": "Generating Steganographic Text with LSTMs"}, {"abstract": "Text in natural images contains rich semantics that are often highly relevant\nto objects or scene. In this paper, we focus on the problem of fully exploiting\nscene text for visual understanding. The main idea is combining word\nrepresentations and deep visual features into a globally trainable deep\nconvolutional neural network. First, the recognized words are obtained by a\nscene text reading system. Then, we combine the word embedding of the\nrecognized words and the deep visual features into a single representation,\nwhich is optimized by a convolutional neural network for fine-grained image\nclassification. In our framework, the attention mechanism is adopted to reveal\nthe relevance between each recognized word and the given image, which further\nenhances the recognition performance. We have performed experiments on two\ndatasets: Con-Text dataset and Drink Bottle dataset, that are proposed for\nfine-grained classification of business places and drink bottles, respectively.\nThe experimental results consistently demonstrate that the proposed method\ncombining textual and visual cues significantly outperforms classification with\nonly visual representations. Moreover, we have shown that the learned\nrepresentation improves the retrieval performance on the drink bottle images by\na large margin, making it potentially useful in product search.", "authors": ["Xiang Bai", "Mingkun Yang", "Pengyuan Lyu", "Yongchao Xu", "Jiebo Luo"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1704.04613v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.04613v2", "num_discussion": 0, "originally_published_time": "4/15/2017", "pid": "1704.04613v2", "published_time": "5/30/2017", "rawpid": "1704.04613", "tags": ["cs.CV"], "title": "Integrating Scene Text and Visual Appearance for Fine-Grained Image\n  Classification"}, {"abstract": "Despite the success of deep learning on many fronts especially image and\nspeech, its application in text classification often is still not as good as a\nsimple linear SVM on n-gram TF-IDF representation especially for smaller\ndatasets. Deep learning tends to emphasize on sentence level semantics when\nlearning a representation with models like recurrent neural network or\nrecursive neural network, however from the success of TF-IDF representation, it\nseems a bag-of-words type of representation has its strength. Taking advantage\nof both representions, we present a model known as TDSM (Top Down Semantic\nModel) for extracting a sentence representation that considers both the\nword-level semantics by linearly combining the words with attention weights and\nthe sentence-level semantics with BiLSTM and use it on text classification. We\napply the model on characters and our results show that our model is better\nthan all the other character-based and word-based convolutional neural network\nmodels by \\cite{zhang15} across seven different datasets with only 1\\% of their\nparameters. We also demonstrate that this model beats traditional linear models\non TF-IDF vectors on small and polished datasets like news article in which\ntypically deep learning models surrender.", "authors": ["Zhenzhou Wu", "Xin Zheng", "Daniel Dahlmeier"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1705.10586v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1705.10586v1", "num_discussion": 0, "originally_published_time": "5/29/2017", "pid": "1705.10586v1", "published_time": "5/29/2017", "rawpid": "1705.10586", "tags": ["cs.CL", "cs.LG"], "title": "Character-Based Text Classification using Top Down Semantic Model for\n  Sentence Representation"}, {"abstract": "Information extraction (IE) from text has largely focused on relations\nbetween individual entities, such as who has won which award. However, some\nfacts are never fully mentioned, and no IE method has perfect recall. Thus, it\nis beneficial to also tap contents about the cardinalities of these relations,\nfor example, how many awards someone has won. We introduce this novel problem\nof extracting cardinalities and discusses the specific challenges that set it\napart from standard IE. We present a distant supervision method using\nconditional random fields. A preliminary evaluation results in precision\nbetween 3% and 55%, depending on the difficulty of relations.", "authors": ["Paramita Mirza", "Simon Razniewski", "Fariz Darari", "Gerhard Weikum"], "category": "cs.CL", "comment": "5 pages, ACL 2017 (short paper)", "img": "/static/thumbs/1704.04455v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.04455v2", "num_discussion": 0, "originally_published_time": "4/14/2017", "pid": "1704.04455v2", "published_time": "5/27/2017", "rawpid": "1704.04455", "tags": ["cs.CL"], "title": "Cardinal Virtues: Extracting Relation Cardinalities from Text"}, {"abstract": "This paper focuses on style transfer on the basis of non-parallel text. This\nis an instance of a broader family of problems including machine translation,\ndecipherment, and sentiment modification. The key technical challenge is to\nseparate the content from desired text characteristics such as sentiment. We\nleverage refined alignment of latent representations across mono-lingual text\ncorpora with different characteristics. We deliberately modify encoded examples\naccording to their characteristics, requiring the reproduced instances to match\navailable examples with the altered characteristics as a population. We\ndemonstrate the effectiveness of this cross-alignment method on three tasks:\nsentiment modification, decipherment of word substitution ciphers, and recovery\nof word order.", "authors": ["Tianxiao Shen", "Tao Lei", "Regina Barzilay", "Tommi Jaakkola"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1705.09655v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1705.09655v1", "num_discussion": 0, "originally_published_time": "5/26/2017", "pid": "1705.09655v1", "published_time": "5/26/2017", "rawpid": "1705.09655", "tags": ["cs.CL", "cs.LG"], "title": "Style Transfer from Non-Parallel Text by Cross-Alignment"}, {"abstract": "Generic text embeddings are successfully used in a variety of tasks. However,\nthey are often learnt by capturing the co-occurrence structure from pure text\ncorpora, resulting in limitations of their ability to generalize. In this\npaper, we explore models that incorporate visual information into the text\nrepresentation. Based on comprehensive ablation studies, we propose a\nconceptually simple, yet well performing architecture. It outperforms previous\nmultimodal approaches on a set of well established benchmarks. We also improve\nthe state-of-the-art results for image-related text datasets, using orders of\nmagnitude less data.", "authors": ["Karol Kurach", "Sylvain Gelly", "Michal Jastrzebski", "Philip Haeusser", "Olivier Teytaud", "Damien Vincent", "Olivier Bousquet"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1705.08386v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1705.08386v2", "num_discussion": 0, "originally_published_time": "5/23/2017", "pid": "1705.08386v2", "published_time": "5/26/2017", "rawpid": "1705.08386", "tags": ["cs.CL", "cs.CV"], "title": "Better Text Understanding Through Image-To-Text Transfer"}, {"abstract": "We empirically characterize the performance of discriminative and generative\nLSTM models for text classification. We find that although RNN-based generative\nmodels are more powerful than their bag-of-words ancestors (e.g., they account\nfor conditional dependencies across words in a document), they have higher\nasymptotic error rates than discriminatively trained RNN models. However we\nalso find that generative models approach their asymptotic error rate more\nrapidly than their discriminative counterparts---the same pattern that Ng \u0026\nJordan (2001) proved holds for linear classification models that make more\nnaive conditional independence assumptions. Building on this finding, we\nhypothesize that RNN-based generative classification models will be more robust\nto shifts in the data distribution. This hypothesis is confirmed in a series of\nexperiments in zero-shot and continual learning settings that show that\ngenerative models substantially outperform discriminative models.", "authors": ["Dani Yogatama", "Chris Dyer", "Wang Ling", "Phil Blunsom"], "category": "stat.ML", "comment": "", "img": "/static/thumbs/1703.01898v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1703.01898v2", "num_discussion": 0, "originally_published_time": "3/6/2017", "pid": "1703.01898v2", "published_time": "5/26/2017", "rawpid": "1703.01898", "tags": ["stat.ML", "cs.CL", "cs.LG"], "title": "Generative and Discriminative Text Classification with Recurrent Neural\n  Networks"}, {"abstract": "Online handwritten Chinese text recognition (OHCTR) is a challenging problem\nas it involves a large-scale character set, ambiguous segmentation, and\nvariable-length input sequences. In this paper, we exploit the outstanding\ncapability of path signature to translate online pen-tip trajectories into\ninformative signature feature maps using a sliding window-based method,\nsuccessfully capturing the analytic and geometric properties of pen strokes\nwith strong local invariance and robustness. A multi-spatial-context fully\nconvolutional recurrent network (MCFCRN) is proposed to exploit the multiple\nspatial contexts from the signature feature maps and generate a prediction\nsequence while completely avoiding the difficult segmentation problem.\nFurthermore, an implicit language model is developed to make predictions based\non semantic context within a predicting feature sequence, providing a new\nperspective for incorporating lexicon constraints and prior knowledge about a\ncertain language in the recognition procedure. Experiments on two standard\nbenchmarks, Dataset-CASIA and Dataset-ICDAR, yielded outstanding results, with\ncorrect rates of 97.10% and 97.15%, respectively, which are significantly\nbetter than the best result reported thus far in the literature.", "authors": ["Zecheng Xie", "Zenghui Sun", "Lianwen Jin", "Hao Ni", "Terry Lyons"], "category": "cs.CV", "comment": "14 pages, 9 figures", "img": "/static/thumbs/1610.02616v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1610.02616v2", "num_discussion": 0, "originally_published_time": "10/9/2016", "pid": "1610.02616v2", "published_time": "5/25/2017", "rawpid": "1610.02616", "tags": ["cs.CV"], "title": "Learning Spatial-Semantic Context with Fully Convolutional Recurrent\n  Network for Online Handwritten Chinese Text Recognition"}, {"abstract": "End-to-end training from scratch of current deep architectures for new\ncomputer vision problems would require Imagenet-scale datasets, and this is not\nalways possible. In this paper we present a method that is able to take\nadvantage of freely available multi-modal content to train computer vision\nalgorithms without human supervision. We put forward the idea of performing\nself-supervised learning of visual features by mining a large scale corpus of\nmulti-modal (text and image) documents. We show that discriminative visual\nfeatures can be learnt efficiently by training a CNN to predict the semantic\ncontext in which a particular image is more probable to appear as an\nillustration. For this we leverage the hidden semantic structures discovered in\nthe text corpus with a well-known topic modeling technique. Our experiments\ndemonstrate state of the art performance in image classification, object\ndetection, and multi-modal retrieval compared to recent self-supervised or\nnatural-supervised approaches.", "authors": ["Lluis Gomez", "Yash Patel", "Mar\u00e7al Rusi\u00f1ol", "Dimosthenis Karatzas", "C. V. Jawahar"], "category": "cs.CV", "comment": "Accepted CVPR 2017 paper", "img": "/static/thumbs/1705.08631v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1705.08631v1", "num_discussion": 0, "originally_published_time": "5/24/2017", "pid": "1705.08631v1", "published_time": "5/24/2017", "rawpid": "1705.08631", "tags": ["cs.CV"], "title": "Self-supervised learning of visual features through embedding images\n  into text topic spaces"}, {"abstract": "Visual question answering is a recently proposed artificial intelligence task\nthat requires a deep understanding of both images and texts. In deep learning,\nimages are typically modeled through convolutional neural networks, and texts\nare typically modeled through recurrent neural networks. While the requirement\nfor modeling images is similar to traditional computer vision tasks, such as\nobject recognition and image classification, visual question answering raises a\ndifferent need for textual representation as compared to other natural language\nprocessing tasks. In this work, we perform a detailed analysis on natural\nlanguage questions in visual question answering. Based on the analysis, we\npropose to rely on convolutional neural networks for learning textual\nrepresentations. By exploring the various properties of convolutional neural\nnetworks specialized for text data, such as width and depth, we present our\n\"CNN Inception + Gate\" model. We show that our model improves question\nrepresentations and thus the overall accuracy of visual question answering\nmodels. We also show that the text representation requirement in visual\nquestion answering is more complicated and comprehensive than that in\nconventional natural language processing tasks, making it a better task to\nevaluate textual representation methods. Shallow models like fastText, which\ncan obtain comparable results with deep learning models in tasks like text\nclassification, are not suitable in visual question answering.", "authors": ["Zhengyang Wang", "Shuiwang Ji"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1705.06824v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1705.06824v1", "num_discussion": 0, "originally_published_time": "5/18/2017", "pid": "1705.06824v1", "published_time": "5/18/2017", "rawpid": "1705.06824", "tags": ["cs.LG", "cs.CL", "cs.NE", "stat.ML"], "title": "Learning Convolutional Text Representations for Visual Question\n  Answering"}, {"abstract": "In recent years, text recognition has achieved remarkable success in\nrecognizing scanned document text. However, word recognition in natural images\nis still an open problem, which generally requires time consuming\npost-processing steps. We present a novel architecture for individual word\ndetection in scene images based on semantic segmentation. Our contributions are\ntwofold: the concept of WordFence, which detects border areas surrounding each\nindividual word and a novel pixelwise weighted softmax loss function which\npenalizes background and emphasizes small text regions. WordFence ensures that\neach word is detected individually, and the new loss function provides a strong\ntraining signal to both text and word border localization. The proposed\ntechnique avoids intensive post-processing, producing an end-to-end word\ndetection system. We achieve superior localization recall on common benchmark\ndatasets - 92% recall on ICDAR11 and ICDAR13 and 63% recall on SVT.\nFurthermore, our end-to-end word recognition system achieves state-of-the-art\n86% F-Score on ICDAR13.", "authors": ["Andrei Polzounov", "Artsiom Ablavatski", "Sergio Escalera", "Shijian Lu", "Jianfei Cai"], "category": "cs.CV", "comment": "5 pages, 2 figures, ICIP 2017", "img": "/static/thumbs/1705.05483v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1705.05483v1", "num_discussion": 0, "originally_published_time": "5/15/2017", "pid": "1705.05483v1", "published_time": "5/15/2017", "rawpid": "1705.05483", "tags": ["cs.CV"], "title": "WordFence: Text Detection in Natural Images with Border Awareness"}, {"abstract": "The character information in natural scene images contains various personal\ninformation, such as telephone numbers, home addresses, etc. It is a high risk\nof leakage the information if they are published. In this paper, we proposed a\nscene text erasing method to properly hide the information via an inpainting\nconvolutional neural network (CNN) model. The input is a scene text image, and\nthe output is expected to be text erased image with all the character regions\nfilled up the colors of the surrounding background pixels. This work is\naccomplished by a CNN model through convolution to deconvolution with\ninterconnection process. The training samples and the corresponding inpainting\nimages are considered as teaching signals for training. To evaluate the text\nerasing performance, the output images are detected by a novel scene text\ndetection method. Subsequently, the same measurement on text detection is\nutilized for testing the images in benchmark dataset ICDAR2013. Compared with\ndirect text detection way, the scene text erasing process demonstrates a\ndrastically decrease on the precision, recall and f-score. That proves the\neffectiveness of proposed method for erasing the text in natural scene images.", "authors": ["Toshiki Nakamura", "Anna Zhu", "Keiji Yanai", "Seiichi Uchida"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1705.02772v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1705.02772v1", "num_discussion": 0, "originally_published_time": "5/8/2017", "pid": "1705.02772v1", "published_time": "5/8/2017", "rawpid": "1705.02772", "tags": ["cs.CV", "cs.AI"], "title": "Scene Text Eraser"}, {"abstract": "Adversarial training provides a means of regularizing supervised learning\nalgorithms while virtual adversarial training is able to extend supervised\nlearning algorithms to the semi-supervised setting. However, both methods\nrequire making small perturbations to numerous entries of the input vector,\nwhich is inappropriate for sparse high-dimensional inputs such as one-hot word\nrepresentations. We extend adversarial and virtual adversarial training to the\ntext domain by applying perturbations to the word embeddings in a recurrent\nneural network rather than to the original input itself. The proposed method\nachieves state of the art results on multiple benchmark semi-supervised and\npurely supervised tasks. We provide visualizations and analysis showing that\nthe learned word embeddings have improved in quality and that while training,\nthe model is less prone to overfitting.", "authors": ["Takeru Miyato", "Andrew M. Dai", "Ian Goodfellow"], "category": "stat.ML", "comment": "Published as a conference paper at ICLR 2017", "img": "/static/thumbs/1605.07725v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1605.07725v3", "num_discussion": 1, "originally_published_time": "5/25/2016", "pid": "1605.07725v3", "published_time": "5/6/2017", "rawpid": "1605.07725", "tags": ["stat.ML", "cs.LG"], "title": "Adversarial Training Methods for Semi-Supervised Text Classification"}, {"abstract": "We show that discourse structure, as defined by Rhetorical Structure Theory\nand provided by an existing discourse parser, benefits text categorization. Our\napproach uses a recursive neural network and a newly proposed attention\nmechanism to compute a representation of the text that focuses on salient\ncontent, from the perspective of both RST and the task. Experiments consider\nvariants of the approach and illustrate its strengths and weaknesses.", "authors": ["Yangfeng Ji", "Noah Smith"], "category": "cs.CL", "comment": "ACL 2017 camera ready version", "img": "/static/thumbs/1702.01829v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1702.01829v2", "num_discussion": 0, "originally_published_time": "2/7/2017", "pid": "1702.01829v2", "published_time": "5/6/2017", "rawpid": "1702.01829", "tags": ["cs.CL", "cs.LG"], "title": "Neural Discourse Structure for Text Categorization"}, {"abstract": "Cross-lingual text classification(CLTC) is the task of classifying documents\nwritten in different languages into the same taxonomy of categories. This paper\npresents a novel approach to CLTC that builds on model distillation, which\nadapts and extends a framework originally proposed for model compression. Using\nsoft probabilistic predictions for the documents in a label-rich language as\nthe (induced) supervisory labels in a parallel corpus of documents, we train\nclassifiers successfully for new languages in which labeled training data are\nnot available. An adversarial feature adaptation technique is also applied\nduring the model training to reduce distribution mismatch. We conducted\nexperiments on two benchmark CLTC datasets, treating English as the source\nlanguage and German, French, Japan and Chinese as the unlabeled target\nlanguages. The proposed approach had the advantageous or comparable performance\nof the other state-of-art methods.", "authors": ["Ruochen Xu", "Yiming Yang"], "category": "cs.CL", "comment": "Accepted at ACL 2017", "img": "/static/thumbs/1705.02073v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1705.02073v1", "num_discussion": 0, "originally_published_time": "5/5/2017", "pid": "1705.02073v1", "published_time": "5/5/2017", "rawpid": "1705.02073", "tags": ["cs.CL"], "title": "Cross-lingual Distillation for Text Classification"}, {"abstract": "Multi-label text classification is a popular machine learning task where each\ndocument is assigned with multiple relevant labels. This task is challenging\ndue to high dimensional features and correlated labels. Multi-label text\nclassifiers need to be carefully regularized to prevent the severe over-fitting\nin the high dimensional space, and also need to take into account label\ndependencies in order to make accurate predictions under uncertainty. We\ndemonstrate significant and practical improvement by carefully regularizing the\nmodel complexity during training phase, and also regularizing the label search\nspace during prediction phase. Specifically, we regularize the classifier\ntraining using Elastic-net (L1+L2) penalty for reducing model complexity/size,\nand employ early stopping to prevent overfitting. At prediction time, we apply\nsupport inference to restrict the search space to label sets encountered in the\ntraining set, and F-optimizer GFM to make optimal predictions for the F1\nmetric. We show that although support inference only provides density\nestimations on existing label combinations, when combined with GFM predictor,\nthe algorithm can output unseen label combinations. Taken collectively, our\nexperiments show state of the art results on many benchmark datasets. Beyond\nperformance and practical contributions, we make some interesting observations.\nContrary to the prior belief, which deems support inference as purely an\napproximate inference procedure, we show that support inference acts as a\nstrong regularizer on the label prediction structure. It allows the classifier\nto take into account label dependencies during prediction even if the\nclassifiers had not modeled any label dependencies during training.", "authors": ["Bingyu Wang", "Cheng Li", "Virgil Pavlu", "Javed Aslam"], "category": "stat.ML", "comment": "", "img": "/static/thumbs/1705.00740v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1705.00740v1", "num_discussion": 0, "originally_published_time": "5/1/2017", "pid": "1705.00740v1", "published_time": "5/1/2017", "rawpid": "1705.00740", "tags": ["stat.ML", "cs.LG"], "title": "Regularizing Model Complexity and Label Structure for Multi-Label Text\n  Classification"}, {"abstract": "We introduce the first generic text representation model that is completely\nnonsymbolic, i.e., it does not require the availability of a segmentation or\ntokenization method that attempts to identify words or other symbolic units in\ntext. This applies to training the parameters of the model on a training corpus\nas well as to applying it when computing the representation of a new text. We\nshow that our model performs better than prior work on an information\nextraction and a text denoising task.", "authors": ["Hinrich Schuetze", "Heike Adel", "Ehsaneddin Asgari"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1610.00479v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1610.00479v3", "num_discussion": 0, "originally_published_time": "10/3/2016", "pid": "1610.00479v3", "published_time": "5/1/2017", "rawpid": "1610.00479", "tags": ["cs.CL"], "title": "Nonsymbolic Text Representation"}, {"abstract": "Our goal is to combine the rich multistep inference of symbolic logical\nreasoning with the generalization capabilities of neural networks. We are\nparticularly interested in complex reasoning about entities and relations in\ntext and large-scale knowledge bases (KBs). Neelakantan et al. (2015) use RNNs\nto compose the distributed semantics of multi-hop paths in KBs; however for\nmultiple reasons, the approach lacks accuracy and practicality. This paper\nproposes three significant modeling advances: (1) we learn to jointly reason\nabout relations, entities, and entity-types; (2) we use neural attention\nmodeling to incorporate multiple paths; (3) we learn to share strength in a\nsingle RNN that represents logical composition across all relations. On a\nlargescale Freebase+ClueWeb prediction task, we achieve 25% error reduction,\nand a 53% error reduction on sparse relations due to shared strength. On chains\nof reasoning in WordNet we reduce error in mean quantile by 84% versus previous\nstate-of-the-art. The code and data are available at\nhttps://rajarshd.github.io/ChainsofReasoning", "authors": ["Rajarshi Das", "Arvind Neelakantan", "David Belanger", "Andrew McCallum"], "category": "cs.CL", "comment": "accepted to EACL 2017 (fixed latex formatting in previous version)", "img": "/static/thumbs/1607.01426v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1607.01426v3", "num_discussion": 0, "originally_published_time": "7/5/2016", "pid": "1607.01426v3", "published_time": "5/1/2017", "rawpid": "1607.01426", "tags": ["cs.CL"], "title": "Chains of Reasoning over Entities, Relations, and Text using Recurrent\n  Neural Networks"}, {"abstract": "Recurrent Neural Networks are showing much promise in many sub-areas of\nnatural language processing, ranging from document classification to machine\ntranslation to automatic question answering. Despite their promise, many\nrecurrent models have to read the whole text word by word, making it slow to\nhandle long documents. For example, it is difficult to use a recurrent network\nto read a book and answer questions about it. In this paper, we present an\napproach of reading text while skipping irrelevant information if needed. The\nunderlying model is a recurrent network that learns how far to jump after\nreading a few words of the input text. We employ a standard policy gradient\nmethod to train the model to make discrete jumping decisions. In our benchmarks\non four different tasks, including number prediction, sentiment analysis, news\narticle classification and automatic Q\\\u0026A, our proposed model, a modified LSTM\nwith jumping, is up to 6 times faster than the standard sequential LSTM, while\nmaintaining the same or even better accuracy.", "authors": ["Adams Wei Yu", "Hongrae Lee", "Quoc V. Le"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1704.06877v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.06877v2", "num_discussion": 0, "originally_published_time": "4/23/2017", "pid": "1704.06877v2", "published_time": "4/29/2017", "rawpid": "1704.06877", "tags": ["cs.CL", "cs.LG"], "title": "Learning to Skim Text"}, {"abstract": "Text line detection and localization is a crucial step for full page document\nanalysis, but still suffers from heterogeneity of real life documents. In this\npaper, we present a new approach for full page text recognition. Localization\nof the text lines is based on regressions with Fully Convolutional Neural\nNetworks and Multidimensional Long Short-Term Memory as contextual layers. In\norder to increase the efficiency of this localization method, only the position\nof the left side of the text lines are predicted. The text recognizer is then\nin charge of predicting the end of the text to recognize. This method has shown\ngood results for full page text recognition on the highly heterogeneous Maurdor\ndataset.", "authors": ["Bastien Moysset", "Christopher Kermorvant", "Christian Wolf"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1704.08628v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.08628v1", "num_discussion": 0, "originally_published_time": "4/27/2017", "pid": "1704.08628v1", "published_time": "4/27/2017", "rawpid": "1704.08628", "tags": ["cs.CV"], "title": "Full-Page Text Recognition: Learning Where to Start and When to Stop"}, {"abstract": "This paper aims to catalyze the discussions about text feature extraction\ntechniques using neural network architectures. The research questions discussed\nin the paper focus on the state-of-the-art neural network techniques that have\nproven to be useful tools for language processing, language generation, text\nclassification and other computational linguistics tasks.", "authors": ["Vineet John"], "category": "cs.CL", "comment": "9 pages, 2 figures", "img": "/static/thumbs/1704.08531v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.08531v1", "num_discussion": 0, "originally_published_time": "4/27/2017", "pid": "1704.08531v1", "published_time": "4/27/2017", "rawpid": "1704.08531", "tags": ["cs.CL", "68T50"], "title": "A Survey of Neural Network Techniques for Feature Extraction from Text"}, {"abstract": "Existing question answering methods infer answers either from a knowledge\nbase or from raw text. While knowledge base (KB) methods are good at answering\ncompositional questions, their performance is often affected by the\nincompleteness of the KB. Au contraire, web text contains millions of facts\nthat are absent in the KB, however in an unstructured form. {\\it Universal\nschema} can support reasoning on the union of both structured KBs and\nunstructured text by aligning them in a common embedded space. In this paper we\nextend universal schema to natural language question answering, employing\n\\emph{memory networks} to attend to the large body of facts in the combination\nof text and KB. Our models can be trained in an end-to-end fashion on\nquestion-answer pairs. Evaluation results on \\spades fill-in-the-blank question\nanswering dataset show that exploiting universal schema for question answering\nis better than using either a KB or text alone. This model also outperforms the\ncurrent state-of-the-art by 8.5 $F_1$ points.\\footnote{Code and data available\nin \\url{https://rajarshd.github.io/TextKBQA}}", "authors": ["Rajarshi Das", "Manzil Zaheer", "Siva Reddy", "Andrew McCallum"], "category": "cs.CL", "comment": "ACL 2017 (short)", "img": "/static/thumbs/1704.08384v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.08384v1", "num_discussion": 0, "originally_published_time": "4/27/2017", "pid": "1704.08384v1", "published_time": "4/27/2017", "rawpid": "1704.08384", "tags": ["cs.CL"], "title": "Question Answering on Knowledge Bases and Text using Universal Schema\n  and Memory Networks"}, {"abstract": "Deep neural networks (DNNs) play a key role in many applications. Current\nstudies focus on crafting adversarial samples against DNN-based image\nclassifiers by introducing some imperceptible perturbations to the input.\nHowever, DNNs for natural language processing have not got the attention they\ndeserve. In fact, the existing perturbation algorithms for images cannot be\ndirectly applied to text. This paper presents a simple but effective method to\nattack DNN-based text classifiers. Three perturbation strategies, namely\ninsertion, modification, and removal, are designed to generate an adversarial\nsample for a given text. By computing the cost gradients, what should be\ninserted, modified or removed, where to insert and how to modify are determined\neffectively. The experimental results show that the adversarial samples\ngenerated by our method can successfully fool a state-of-the-art model to\nmisclassify them as any desirable classes without compromising their utilities.\nAt the same time, the introduced perturbations are difficult to be perceived.\nOur study demonstrates that DNN-based text classifiers are also prone to the\nadversarial sample attack.", "authors": ["Bin Liang", "Hongcheng Li", "Miaoqiang Su", "Pan Bian", "Xirong Li", "Wenchang Shi"], "category": "cs.CR", "comment": "7 pages", "img": "/static/thumbs/1704.08006v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.08006v1", "num_discussion": 0, "originally_published_time": "4/26/2017", "pid": "1704.08006v1", "published_time": "4/26/2017", "rawpid": "1704.08006", "tags": ["cs.CR", "cs.LG"], "title": "Deep Text Classification Can be Fooled"}, {"abstract": "In conversational speech, the acoustic signal provides cues that help\nlisteners disambiguate difficult parses. For automatically parsing a spoken\nutterance, we introduce a model that integrates transcribed text and\nacoustic-prosodic features using a convolutional neural network over energy and\npitch trajectories coupled with an attention-based recurrent neural network\nthat accepts text and word-based prosodic features. We find that different\ntypes of acoustic-prosodic features are individually helpful, and together\nimprove parse F1 scores significantly over a strong text-only baseline. For\nthis study with known sentence boundaries, error analysis shows that the main\nbenefit of acoustic-prosodic features is in sentences with disfluencies and\nthat attachment errors are most improved.", "authors": ["Trang Tran", "Shubham Toshniwal", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu", "Mari Ostendorf"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1704.07287v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.07287v1", "num_discussion": 0, "originally_published_time": "4/24/2017", "pid": "1704.07287v1", "published_time": "4/24/2017", "rawpid": "1704.07287", "tags": ["cs.CL", "cs.LG", "cs.SD"], "title": "Joint Modeling of Text and Acoustic-Prosodic Cues for Neural Parsing"}, {"abstract": "Human verbal communication includes affective messages which are conveyed\nthrough use of emotionally colored words. There has been a lot of research in\nthis direction but the problem of integrating state-of-the-art neural language\nmodels with affective information remains an area ripe for exploration. In this\npaper, we propose an extension to an LSTM (Long Short-Term Memory) language\nmodel for generating conversational text, conditioned on affect categories. Our\nproposed model, Affect-LM enables us to customize the degree of emotional\ncontent in generated sentences through an additional design parameter.\nPerception studies conducted using Amazon Mechanical Turk show that Affect-LM\ngenerates naturally looking emotional sentences without sacrificing grammatical\ncorrectness. Affect-LM also learns affect-discriminative word representations,\nand perplexity experiments show that additional affective information in\nconversational text can improve language model prediction.", "authors": ["Sayan Ghosh", "Mathieu Chollet", "Eugene Laksana", "Louis-Philippe Morency", "Stefan Scherer"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1704.06851v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.06851v1", "num_discussion": 0, "originally_published_time": "4/22/2017", "pid": "1704.06851v1", "published_time": "4/22/2017", "rawpid": "1704.06851", "tags": ["cs.CL"], "title": "Affect-LM: A Neural Language Model for Customizable Affective Text\n  Generation"}, {"abstract": "We present an approach to automatically classify clinical text at a sentence\nlevel. We are using deep convolutional neural networks to represent complex\nfeatures. We train the network on a dataset providing a broad categorization of\nhealth information. Through a detailed evaluation, we demonstrate that our\nmethod outperforms several approaches widely used in natural language\nprocessing tasks by about 15%.", "authors": ["Mark Hughes", "Irene Li", "Spyros Kotoulas", "Toyotaro Suzumura"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1704.06841v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.06841v1", "num_discussion": 0, "originally_published_time": "4/22/2017", "pid": "1704.06841v1", "published_time": "4/22/2017", "rawpid": "1704.06841", "tags": ["cs.CL"], "title": "Medical Text Classification using Convolutional Neural Networks"}, {"abstract": "In this paper, we explicitly extract and model jointly multi-view information\nfrom short utterances of the individuals, such as speaker identity and text\ncontents. During the development stage, a deep neural network (DNN) that will\nbe used to extract j-vector, is initialized and trained with the speech frames\nas input and the actual side information of the utterance as flat output\nblock-wise one-hot labels. In the case of text dependent speaker verification,\nsince there is no one-one mapping between input frames and text content labels,\na syllable aware DNN is trained to provide compact lexical representation, the\ns-vector of the utterance. These two vectors (j-vector and s-vector) will be\ncombined together to become a multi-view vector representation of the utterance\nduring the enrollment and evaluation stages. In order to better describe such\nmulti-view vectors, we propose a multi-view probability linear discriminant\nanalysis (PLDA) model which incorporates both within-speaker/text and\nbetween-speaker/text variation. In verification we calculate the likelihood\nthat the two multi-view vectors belonging to the same speaker and text or not,\nand the likelihood will be used in decision-making. Large scale experiments for\nthe open-set condition showed that our approach leads to 0.26\\% EER, 2.7\\% EER,\nand 1.34\\% EER for impost wrong, impostor correct, and target wrong\nrespectively.", "authors": ["Ziqiang Shi", "Liu Liu", "Rujie Liu"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1704.06061v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.06061v2", "num_discussion": 0, "originally_published_time": "4/20/2017", "pid": "1704.06061v2", "published_time": "4/21/2017", "rawpid": "1704.06061", "tags": ["cs.LG"], "title": "Multi-view Probability Linear Discrimination Analysis for Multi-view\n  Vector Based Text Dependent Speaker Verification"}, {"abstract": "We propose a multi-view network for text classification. Our method\nautomatically creates various views of its input text, each taking the form of\nsoft attention weights that distribute the classifier\u0027s focus among a set of\nbase features. For a bag-of-words representation, each view focuses on a\ndifferent subset of the text\u0027s words. Aggregating many such views results in a\nmore discriminative and robust representation. Through a novel architecture\nthat both stacks and concatenates views, we produce a network that emphasizes\nboth depth and width, allowing training to converge quickly. Using our\nmulti-view architecture, we establish new state-of-the-art accuracies on two\nbenchmark tasks.", "authors": ["Hongyu Guo", "Colin Cherry", "Jiang Su"], "category": "cs.CL", "comment": "6 pages", "img": "/static/thumbs/1704.05907v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.05907v1", "num_discussion": 0, "originally_published_time": "4/19/2017", "pid": "1704.05907v1", "published_time": "4/19/2017", "rawpid": "1704.05907", "tags": ["cs.CL", "cs.LG", "cs.NE"], "title": "End-to-End Multi-View Networks for Text Classification"}, {"abstract": "Neural network models have shown their promising opportunities for multi-task\nlearning, which focus on learning the shared layers to extract the common and\ntask-invariant features. However, in most existing approaches, the extracted\nshared features are prone to be contaminated by task-specific features or the\nnoise brought by other tasks. In this paper, we propose an adversarial\nmulti-task learning framework, alleviating the shared and private latent\nfeature spaces from interfering with each other. We conduct extensive\nexperiments on 16 different text classification tasks, which demonstrates the\nbenefits of our approach. Besides, we show that the shared knowledge learned by\nour proposed model can be regarded as off-the-shelf knowledge and easily\ntransferred to new tasks. The datasets of all 16 tasks are publicly available\nat \\url{http://nlp.fudan.edu.cn/data/}", "authors": ["Pengfei Liu", "Xipeng Qiu", "Xuanjing Huang"], "category": "cs.CL", "comment": "Accepted by ACL2017", "img": "/static/thumbs/1704.05742v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.05742v1", "num_discussion": 0, "originally_published_time": "4/19/2017", "pid": "1704.05742v1", "published_time": "4/19/2017", "rawpid": "1704.05742", "tags": ["cs.CL"], "title": "Adversarial Multi-task Learning for Text Classification"}, {"abstract": "Automatic question generation aims to generate questions from a text passage\nwhere the generated questions can be answered by certain sub-spans of the given\npassage. Traditional methods mainly use rigid heuristic rules to transform a\nsentence into related questions. In this work, we propose to apply the neural\nencoder-decoder model to generate meaningful and diverse questions from natural\nlanguage sentences. The encoder reads the input text and the answer position,\nto produce an answer-aware input representation, which is fed to the decoder to\ngenerate an answer focused question. We conduct a preliminary study on neural\nquestion generation from text with the SQuAD dataset, and the experiment\nresults show that our method can produce fluent and diverse questions.", "authors": ["Qingyu Zhou", "Nan Yang", "Furu Wei", "Chuanqi Tan", "Hangbo Bao", "Ming Zhou"], "category": "cs.CL", "comment": "Submitted to EMNLP 2017", "img": "/static/thumbs/1704.01792v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.01792v3", "num_discussion": 0, "originally_published_time": "4/6/2017", "pid": "1704.01792v3", "published_time": "4/18/2017", "rawpid": "1704.01792", "tags": ["cs.CL"], "title": "Neural Question Generation from Text: A Preliminary Study"}, {"abstract": "We test whether distributional models can do one-shot learning of\ndefinitional properties from text only. Using Bayesian models, we find that\nfirst learning overarching structure in the known data, regularities in textual\ncontexts and in properties, helps one-shot learning, and that individual\ncontext items can be highly informative.", "authors": ["Su Wang", "Stephen Roller", "Katrin Erk"], "category": "cs.CL", "comment": "Keywords: Distributional semantics; Lexical semantics; Bayesian\n  models", "img": "/static/thumbs/1704.04550v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.04550v1", "num_discussion": 0, "originally_published_time": "4/14/2017", "pid": "1704.04550v1", "published_time": "4/14/2017", "rawpid": "1704.04550", "tags": ["cs.CL"], "title": "Distributional model on a diet: One-shot word learning from text only"}, {"abstract": "Most state-of-the-art text detection methods are specific to horizontal Latin\ntext and are not fast enough for real-time applications. We introduce Segment\nLinking (SegLink), an oriented text detection method. The main idea is to\ndecompose text into two locally detectable elements, namely segments and links.\nA segment is an oriented box covering a part of a word or text line; A link\nconnects two adjacent segments, indicating that they belong to the same word or\ntext line. Both elements are detected densely at multiple scales by an\nend-to-end trained, fully-convolutional neural network. Final detections are\nproduced by combining segments connected by links. Compared with previous\nmethods, SegLink improves along the dimensions of accuracy, speed, and ease of\ntraining. It achieves an f-measure of 75.0% on the standard ICDAR 2015\nIncidental (Challenge 4) benchmark, outperforming the previous best by a large\nmargin. It runs at over 20 FPS on 512x512 images. Moreover, without\nmodification, SegLink is able to detect long lines of non-Latin text, such as\nChinese.", "authors": ["Baoguang Shi", "Xiang Bai", "Serge Belongie"], "category": "cs.CV", "comment": "To Appear in CVPR 2017", "img": "/static/thumbs/1703.06520v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1703.06520v3", "num_discussion": 0, "originally_published_time": "3/19/2017", "pid": "1703.06520v3", "published_time": "4/13/2017", "rawpid": "1703.06520", "tags": ["cs.CV"], "title": "Detecting Oriented Text in Natural Images by Linking Segments"}, {"abstract": "Although neural networks are well suited for sequential transfer learning\ntasks, the catastrophic forgetting problem hinders proper integration of prior\nknowledge. In this work, we propose a solution to this problem by using a\nmulti-task objective based on the idea of distillation and a mechanism that\ndirectly penalizes forgetting at the shared representation layer during the\nknowledge integration phase of training. We demonstrate our approach on a\nTwitter domain sentiment analysis task with sequential knowledge transfer from\nfour related tasks. We show that our technique outperforms networks fine-tuned\nto the target task. Additionally, we show both through empirical evidence and\nexamples that it does not forget useful knowledge from the source task that is\nforgotten during standard fine-tuning. Surprisingly, we find that first\ndistilling a human made rule based sentiment engine into a recurrent neural\nnetwork and then integrating the knowledge with the target task data leads to a\nsubstantial gain in generalization performance. Our experiments demonstrate the\npower of multi-source transfer techniques in practical text analytics problems\nwhen paired with distillation. In particular, for the SemEval 2016 Task 4\nSubtask A (Nakov et al., 2016) dataset we surpass the state of the art\nestablished during the competition with a comparatively simple model\narchitecture that is not even competitive when trained on only the labeled task\nspecific data.", "authors": ["Matthew Riemer", "Elham Khabiri", "Richard Goodwin"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1704.03617v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.03617v1", "num_discussion": 0, "originally_published_time": "4/12/2017", "pid": "1704.03617v1", "published_time": "4/12/2017", "rawpid": "1704.03617", "tags": ["cs.CL", "cs.LG"], "title": "Representation Stability as a Regularizer for Improved Text Analytics\n  Transfer Learning"}, {"abstract": "Previous approaches for scene text detection have already achieved promising\nperformances across various benchmarks. However, they usually fall short when\ndealing with challenging scenarios, even when equipped with deep neural network\nmodels, because the overall performance is determined by the interplay of\nmultiple stages and components in the pipelines. In this work, we propose a\nsimple yet powerful pipeline that yields fast and accurate text detection in\nnatural scenes. The pipeline directly predicts words or text lines of arbitrary\norientations and quadrilateral shapes in full images, eliminating unnecessary\nintermediate steps (e.g., candidate aggregation and word partitioning), with a\nsingle neural network. The simplicity of our pipeline allows concentrating\nefforts on designing loss functions and neural network architecture.\nExperiments on standard datasets including ICDAR 2015, COCO-Text and MSRA-TD500\ndemonstrate that the proposed algorithm significantly outperforms\nstate-of-the-art methods in terms of both accuracy and efficiency. On the ICDAR\n2015 dataset, the proposed algorithm achieves an F-score of 0.7820 at 13.2fps\nat 720p resolution.", "authors": ["Xinyu Zhou", "Cong Yao", "He Wen", "Yuzhi Wang", "Shuchang Zhou", "Weiran He", "Jiajun Liang"], "category": "cs.CV", "comment": "Accepted to CVPR 2017", "img": "/static/thumbs/1704.03155v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.03155v1", "num_discussion": 0, "originally_published_time": "4/11/2017", "pid": "1704.03155v1", "published_time": "4/11/2017", "rawpid": "1704.03155", "tags": ["cs.CV"], "title": "EAST: An Efficient and Accurate Scene Text Detector"}, {"abstract": "The amount of textual data generated in environments such as social media,\nblogs, online newspapers, and so on, have attracted the attention of the\nscientific community in order to automatize and improve several tasks that were\nmanually performed such as sentiment analysis, user profiling, or text\ncategorization, just to mention a few. Fortunately, several of these activities\ncan be posed as a classification problem, i.e., a problem where one is\ninterested in developing a function, from a set of texts with associated\nlabels, capable of predicting a label given an unseen text. In this\ncontribution, we propose a text classifier, named $\\mu$TC. $\\mu$TC is composed\nof a number of easy to implement text transformation, text representation and a\nmachine learning algorithm that produce a competitive classifier even over\ninformal written text when these parts are correctly configured. We provide a\ndetailed description of $\\mu$TC along with an extensive experimental comparison\nwith the relevant state-of-the-art methods. $\\mu$TC was compared on 30\ndifferent datasets obtaining the best performance (regarding accuracy) in 18 of\nthem. The different datasets include several problems like topic and polarity\nclassification, spam detection, user profiling and authorship attribution.\nFurthermore, it is important to comment that our approach allows the usage of\nthe technology even for users without knowledge of machine learning and natural\nlanguage processing.", "authors": ["Eric S. Tellez", "Daniela Moctezuma", "Sabino Miranda-J\u00edmenez", "Mario Graff"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1704.01975v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.01975v1", "num_discussion": 0, "originally_published_time": "4/6/2017", "pid": "1704.01975v1", "published_time": "4/6/2017", "rawpid": "1704.01975", "tags": ["cs.CL", "cs.AI", "stat.ML"], "title": "An Automated Text Categorization Framework based on Hyperparameter\n  Optimization"}, {"abstract": "As the type and the number of such venues increase, automated analysis of\nsentiment on textual resources has become an essential data mining task. In\nthis paper, we investigate the problem of mining opinions on the collection of\ninformal short texts. Both positive and negative sentiment strength of texts\nare detected. We focus on a non-English language that has few resources for\ntext mining. This approach would help enhance the sentiment analysis in\nlanguages where a list of opinionated words does not exist. We propose a new\nmethod projects the text into dense and low dimensional feature vectors\naccording to the sentiment strength of the words. We detect the mixture of\npositive and negative sentiments on a multi-variant scale. Empirical evaluation\nof the proposed framework on Turkish tweets shows that our approach gets good\nresults for opinion mining.", "authors": ["Esra Akbas"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1704.00016v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.00016v2", "num_discussion": 0, "originally_published_time": "3/31/2017", "pid": "1704.00016v2", "published_time": "4/4/2017", "rawpid": "1704.00016", "tags": ["cs.CL", "cs.IR"], "title": "Opinion Mining on Non-English Short Text"}, {"abstract": "We introduce an algorithm for word-level text spotting that is able to\naccurately and reliably determine the bounding regions of individual words of\ntext \"in the wild\". Our system is formed by the cascade of two convolutional\nneural networks. The first network is fully convolutional and is in charge of\ndetecting areas containing text. This results in a very reliable but possibly\ninaccurate segmentation of the input image. The second network (inspired by the\npopular YOLO architecture) analyzes each segment produced in the first stage,\nand predicts oriented rectangular regions containing individual words. No\npost-processing (e.g. text line grouping) is necessary. With execution time of\n450 ms for a 1000-by-560 image on a Titan X GPU, our system achieves the\nhighest score to date among published algorithms on the ICDAR 2015 Incidental\nScene Text dataset benchmark.", "authors": ["Siyang Qin", "Roberto Manduchi"], "category": "cs.CV", "comment": "7 pages, 8 figures", "img": "/static/thumbs/1704.00834v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.00834v1", "num_discussion": 0, "originally_published_time": "4/3/2017", "pid": "1704.00834v1", "published_time": "4/3/2017", "rawpid": "1704.00834", "tags": ["cs.CV"], "title": "Cascaded Segmentation-Detection Networks for Word-Level Text Spotting"}, {"abstract": "Open domain Question Answering (QA) systems must interact with external\nknowledge sources, such as web pages, to find relevant information. Information\nsources like Wikipedia, however, are not well structured and difficult to\nutilize in comparison with Knowledge Bases (KBs). In this work we present a\ntwo-step approach to question answering from unstructured text, consisting of a\nretrieval step and a comprehension step. For comprehension, we present an RNN\nbased attention model with a novel mixture mechanism for selecting answers from\neither retrieved articles or a fixed vocabulary. For retrieval we introduce a\nhand-crafted model and a neural model for ranking relevant articles. We achieve\nstate-of-the-art performance on W IKI M OVIES dataset, reducing the error by\n40%. Our experimental results further demonstrate the importance of each of the\nintroduced components.", "authors": ["Yusuke Watanabe", "Bhuwan Dhingra", "Ruslan Salakhutdinov"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1703.08885v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1703.08885v1", "num_discussion": 0, "originally_published_time": "3/26/2017", "pid": "1703.08885v1", "published_time": "3/26/2017", "rawpid": "1703.08885", "tags": ["cs.CL"], "title": "Question Answering from Unstructured Text by Retrieval and Comprehension"}, {"abstract": "In this work, we present the Text Conditioned Auxiliary Classifier Generative\nAdversarial Network, (TAC-GAN) a text to image Generative Adversarial Network\n(GAN) for synthesizing images from their text descriptions. Former approaches\nhave tried to condition the generative process on the textual data; but allying\nit to the usage of class information, known to diversify the generated samples\nand improve their structural coherence, has not been explored. We trained the\npresented TAC-GAN model on the Oxford-102 dataset of flowers, and evaluated the\ndiscriminability of the generated images with Inception-Score, as well as their\ndiversity using the Multi-Scale Structural Similarity Index (MS-SSIM). Our\napproach outperforms the state-of-the-art models, i.e., its inception score is\n3.45, corresponding to a relative increase of 7.8% compared to the recently\nintroduced StackGan. A comparison of the mean MS-SSIM scores of the training\nand generated samples per class shows that our approach is able to generate\nhighly diverse images with an average MS-SSIM of 0.14 over all generated\nclasses.", "authors": ["Ayushman Dash", "John Cristian Borges Gamboa", "Sheraz Ahmed", "Marcus Liwicki", "Muhammad Zeshan Afzal"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1703.06412v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1703.06412v2", "num_discussion": 0, "originally_published_time": "3/19/2017", "pid": "1703.06412v2", "published_time": "3/26/2017", "rawpid": "1703.06412", "tags": ["cs.CV"], "title": "TAC-GAN - Text Conditioned Auxiliary Classifier Generative Adversarial\n  Network"}, {"abstract": "This paper introduces a novel rotation-based framework for arbitrary-oriented\ntext detection in natural scene images. We present the Rotation Region Proposal\nNetworks (RRPN), which is designed to generate inclined proposals with text\norientation angle information. The angle information is then adapted for\nbounding box regression to make the proposals more accurately fit into the text\nregion in orientation. The Rotation Region-of-Interest (RRoI) pooling layer is\nproposed to project arbitrary-oriented proposals to the feature map for a text\nregion classifier. The whole framework is built upon region proposal based\narchitecture, which ensures the computational efficiency of the\narbitrary-oriented text detection comparing with previous text detection\nsystems. We conduct experiments using the rotation-based framework on three\nreal-world scene text detection datasets, and demonstrate its superiority in\nterms of effectiveness and efficiency over previous approaches.", "authors": ["Jianqi Ma", "Weiyuan Shao", "Hao Ye", "Li Wang", "Hong Wang", "Yingbin Zheng", "Xiangyang Xue"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1703.01086v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1703.01086v2", "num_discussion": 0, "originally_published_time": "3/3/2017", "pid": "1703.01086v2", "published_time": "3/25/2017", "rawpid": "1703.01086", "tags": ["cs.CV"], "title": "Arbitrary-Oriented Scene Text Detection via Rotation Proposals"}, {"abstract": "Text content can have different visual presentation ways with roughly similar\ncharacters. While conventional text image retrieval depends on complex model of\nOCR-based text recognition and text similarity detection, this paper proposes a\nnew learning-based approach to text image retrieval with the purpose of finding\nout the original or similar text through a query text image. Firstly, features\nof text images are extracted by the CNN network to obtain the deep visual\nrepresentations. Then, the dimension of CNN features is reduced by PCA method\nto improve the efficiency of similarity detection. Based on that, an improved\nsimilarity metrics with article theme relevance filtering is proposed to\nimprove the retrieval accuracy. In experimental procedure, we collect a group\nof academic papers both including English and Chinese as the text database, and\ncut them into pieces of text image. A text image with changed text content is\nused as the query image, experimental results show that the proposed approach\nhas good ability to retrieve the original text content.", "authors": ["Mao Tan", "Si-Ping Yuan", "Yong-Xin Su"], "category": "cs.CV", "comment": "There are some details to be corrected in this article, and they are\n  not suitable for open now", "img": "/static/thumbs/1703.08013v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1703.08013v2", "num_discussion": 0, "originally_published_time": "3/23/2017", "pid": "1703.08013v2", "published_time": "3/24/2017", "rawpid": "1703.08013", "tags": ["cs.CV", "cs.IR", "cs.LG"], "title": "A learning-based approach to text image retrieval: using CNN features\n  and improved similarity metrics"}, {"abstract": "In this paper, we first provide a new perspective to divide existing high\nperformance object detection methods into direct and indirect regressions.\nDirect regression performs boundary regression by predicting the offsets from a\ngiven point, while indirect regression predicts the offsets from some bounding\nbox proposals. Then we analyze the drawbacks of the indirect regression, which\nthe recent state-of-the-art detection structures like Faster-RCNN and SSD\nfollows, for multi-oriented scene text detection, and point out the potential\nsuperiority of direct regression. To verify this point of view, we propose a\ndeep direct regression based method for multi-oriented scene text detection.\nOur detection framework is simple and effective with a fully convolutional\nnetwork and one-step post processing. The fully convolutional network is\noptimized in an end-to-end way and has bi-task outputs where one is pixel-wise\nclassification between text and non-text, and the other is direct regression to\ndetermine the vertex coordinates of quadrilateral text boundaries. The proposed\nmethod is particularly beneficial for localizing incidental scene texts. On the\nICDAR2015 Incidental Scene Text benchmark, our method achieves the F1-measure\nof 81%, which is a new state-of-the-art and significantly outperforms previous\napproaches. On other standard datasets with focused scene texts, our method\nalso reaches the state-of-the-art performance.", "authors": ["Wenhao He", "Xu-Yao Zhang", "Fei Yin", "Cheng-Lin Liu"], "category": "cs.CV", "comment": "9 pages, 9 figures", "img": "/static/thumbs/1703.08289v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1703.08289v1", "num_discussion": 0, "originally_published_time": "3/24/2017", "pid": "1703.08289v1", "published_time": "3/24/2017", "rawpid": "1703.08289", "tags": ["cs.CV"], "title": "Deep Direct Regression for Multi-Oriented Scene Text Detection"}, {"abstract": "Mining textual patterns in news, tweets, papers, and many other kinds of text\ncorpora has been an active theme in text mining and NLP research. Previous\nstudies adopt a dependency parsing-based pattern discovery approach. However,\nthe parsing results lose rich context around entities in the patterns, and the\nprocess is costly for a corpus of large scale. In this study, we propose a\nnovel typed textual pattern structure, called meta pattern, which is extended\nto a frequent, informative, and precise subsequence pattern in certain context.\nWe propose an efficient framework, called MetaPAD, which discovers meta\npatterns from massive corpora with three techniques: (1) it develops a\ncontext-aware segmentation method to carefully determine the boundaries of\npatterns with a learnt pattern quality assessment function, which avoids costly\ndependency parsing and generates high-quality patterns; (2) it identifies and\ngroups synonymous meta patterns from multiple facets---their types, contexts,\nand extractions; and (3) it examines type distributions of entities in the\ninstances extracted by each group of patterns, and looks for appropriate type\nlevels to make discovered patterns precise. Experiments demonstrate that our\nproposed framework discovers high-quality typed textual patterns efficiently\nfrom different genres of massive corpora and facilitates information\nextraction.", "authors": ["Meng Jiang", "Jingbo Shang", "Taylor Cassidy", "Xiang Ren", "Lance M. Kaplan", "Timothy P. Hanratty", "Jiawei Han"], "category": "cs.CL", "comment": "9 pages", "img": "/static/thumbs/1703.04213v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1703.04213v2", "num_discussion": 0, "originally_published_time": "3/13/2017", "pid": "1703.04213v2", "published_time": "3/14/2017", "rawpid": "1703.04213", "tags": ["cs.CL"], "title": "MetaPAD: Meta Pattern Discovery from Massive Text Corpora"}, {"abstract": "As one of the fundamental tasks in text analysis, phrase mining aims at\nextracting quality phrases from a text corpus. Phrase mining is important in\nvarious tasks such as information extraction/retrieval, taxonomy construction,\nand topic modeling. Most existing methods rely on complex, trained linguistic\nanalyzers, and thus likely have unsatisfactory performance on text corpora of\nnew domains and genres without extra but expensive adaption. Recently, a few\ndata-driven methods have been developed successfully for extraction of phrases\nfrom massive domain-specific text. However, none of the state-of-the-art models\nis fully automated because they require human experts for designing rules or\nlabeling phrases.\n  Since one can easily obtain many quality phrases from public knowledge bases\nto a scale that is much larger than that produced by human experts, in this\npaper, we propose a novel framework for automated phrase mining, AutoPhrase,\nwhich leverages this large amount of high-quality phrases in an effective way\nand achieves better performance compared to limited human labeled phrases. In\naddition, we develop a POS-guided phrasal segmentation model, which\nincorporates the shallow syntactic information in part-of-speech (POS) tags to\nfurther enhance the performance, when a POS tagger is available. Note that,\nAutoPhrase can support any language as long as a general knowledge base (e.g.,\nWikipedia) in that language is available, while benefiting from, but not\nrequiring, a POS tagger. Compared to the state-of-the-art methods, the new\nmethod has shown significant improvements in effectiveness on five real-world\ndatasets across different domains and languages.", "authors": ["Jingbo Shang", "Jialu Liu", "Meng Jiang", "Xiang Ren", "Clare R Voss", "Jiawei Han"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1702.04457v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1702.04457v2", "num_discussion": 0, "originally_published_time": "2/15/2017", "pid": "1702.04457v2", "published_time": "3/11/2017", "rawpid": "1702.04457", "tags": ["cs.CL"], "title": "Automated Phrase Mining from Massive Text Corpora"}, {"abstract": "Text similarity detection aims at measuring the degree of similarity between\na pair of texts. Corpora available for text similarity detection are designed\nto evaluate the algorithms to assess the paraphrase level among documents. In\nthis paper we present a textual German corpus for similarity detection. The\npurpose of this corpus is to automatically assess the similarity between a pair\nof texts and to evaluate different similarity measures, both for whole\ndocuments or for individual sentences. Therefore we have calculated several\nsimple measures on our corpus based on a library of similarity functions.", "authors": ["Juan-Manuel Torres-Moreno", "Gerardo Sierra", "Peter Peinl"], "category": "cs.IR", "comment": "1 figure; 13 pages", "img": "/static/thumbs/1703.03923v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1703.03923v1", "num_discussion": 0, "originally_published_time": "3/11/2017", "pid": "1703.03923v1", "published_time": "3/11/2017", "rawpid": "1703.03923", "tags": ["cs.IR", "cs.CL"], "title": "A German Corpus for Text Similarity Detection Tasks"}, {"abstract": "Detecting incidental scene text is a challenging task because of\nmulti-orientation, perspective distortion, and variation of text size, color\nand scale. Retrospective research has only focused on using rectangular\nbounding box or horizontal sliding window to localize text, which may result in\nredundant background noise, unnecessary overlap or even information loss. To\naddress these issues, we propose a new Convolutional Neural Networks (CNNs)\nbased method, named Deep Matching Prior Network (DMPNet), to detect text with\ntighter quadrangle. First, we use quadrilateral sliding windows in several\nspecific intermediate convolutional layers to roughly recall the text with\nhigher overlapping area and then a shared Monte-Carlo method is proposed for\nfast and accurate computing of the polygonal areas. After that, we designed a\nsequential protocol for relative regression which can exactly predict text with\ncompact quadrangle. Moreover, a auxiliary smooth Ln loss is also proposed for\nfurther regressing the position of text, which has better overall performance\nthan L2 loss and smooth L1 loss in terms of robustness and stability. The\neffectiveness of our approach is evaluated on a public word-level,\nmulti-oriented scene text database, ICDAR 2015 Robust Reading Competition\nChallenge 4 \"Incidental scene text localization\". The performance of our method\nis evaluated by using F-measure and found to be 70.64%, outperforming the\nexisting state-of-the-art method with F-measure 63.76%.", "authors": ["Yuliang Liu", "Lianwen Jin"], "category": "cs.CV", "comment": "8 Pages, 7 figures. Accepted to appear in CVPR 2017", "img": "/static/thumbs/1703.01425v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1703.01425v1", "num_discussion": 0, "originally_published_time": "3/4/2017", "pid": "1703.01425v1", "published_time": "3/4/2017", "rawpid": "1703.01425", "tags": ["cs.CV"], "title": "Deep Matching Prior Network: Toward Tighter Multi-oriented Text\n  Detection"}, {"abstract": "Generic generation and manipulation of text is challenging and has limited\nsuccess compared to recent deep generative modeling in visual domain. This\npaper aims at generating plausible natural language sentences, whose attributes\nare dynamically controlled by learning disentangled latent representations with\ndesignated semantics. We propose a new neural generative model which combines\nvariational auto-encoders and holistic attribute discriminators for effective\nimposition of semantic structures. With differentiable approximation to\ndiscrete text samples, explicit constraints on independent attribute controls,\nand efficient collaborative learning of generator and discriminators, our model\nlearns highly interpretable representations from even only word annotations,\nand produces realistic sentences with desired attributes. Quantitative\nevaluation validates the accuracy of sentence and attribute generation.", "authors": ["Zhiting Hu", "Zichao Yang", "Xiaodan Liang", "Ruslan Salakhutdinov", "Eric P. Xing"], "category": "cs.LG", "comment": "updated discussions and references", "img": "/static/thumbs/1703.00955v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1703.00955v1", "num_discussion": 0, "originally_published_time": "3/2/2017", "pid": "1703.00955v1", "published_time": "3/2/2017", "rawpid": "1703.00955", "tags": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "title": "Controllable Text Generation"}, {"abstract": "Recurrent neural networks (RNNs) process input text sequentially and model\nthe conditional transition between word tokens. In contrast, the advantages of\nrecursive networks include that they explicitly model the compositionality and\nthe recursive structure of natural language. However, the current recursive\narchitecture is limited by its dependence on syntactic tree. In this paper, we\nintroduce a robust syntactic parsing-independent tree structured model, Neural\nTree Indexers (NTI) that provides a middle ground between the sequential RNNs\nand the syntactic treebased recursive models. NTI constructs a full n-ary tree\nby processing the input text with its node function in a bottom-up fashion.\nAttention mechanism can then be applied to both structure and node function. We\nimplemented and evaluated a binarytree model of NTI, showing the model achieved\nthe state-of-the-art performance on three different NLP tasks: natural language\ninference, answer sentence selection, and sentence classification,\noutperforming state-of-the-art recurrent and recursive neural networks.", "authors": ["Tsendsuren Munkhdalai", "Hong Yu"], "category": "cs.CL", "comment": "Accepted at EACL 2017", "img": "/static/thumbs/1607.04492v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1607.04492v2", "num_discussion": 0, "originally_published_time": "7/15/2016", "pid": "1607.04492v2", "published_time": "2/28/2017", "rawpid": "1607.04492", "tags": ["cs.CL", "cs.LG", "stat.ML"], "title": "Neural Tree Indexers for Text Understanding"}, {"abstract": "Recent work on generative modeling of text has found that variational\nauto-encoders (VAE) incorporating LSTM decoders perform worse than simpler LSTM\nlanguage models (Bowman et al., 2015). This negative result is so far poorly\nunderstood, but has been attributed to the propensity of LSTM decoders to\nignore conditioning information from the encoder. In this paper, we experiment\nwith a new type of decoder for VAE: a dilated CNN. By changing the decoder\u0027s\ndilation architecture, we control the effective context from previously\ngenerated words. In experiments, we find that there is a trade off between the\ncontextual capacity of the decoder and the amount of encoding information used.\nWe show that with the right decoder, VAE can outperform LSTM language models.\nWe demonstrate perplexity gains on two datasets, representing the first\npositive experimental result on the use VAE for generative modeling of text.\nFurther, we conduct an in-depth investigation of the use of VAE (with our new\ndecoding architecture) for semi-supervised and unsupervised labeling tasks,\ndemonstrating gains over several strong baselines.", "authors": ["Zichao Yang", "Zhiting Hu", "Ruslan Salakhutdinov", "Taylor Berg-Kirkpatrick"], "category": "cs.NE", "comment": "12 pages", "img": "/static/thumbs/1702.08139v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1702.08139v1", "num_discussion": 0, "originally_published_time": "2/27/2017", "pid": "1702.08139v1", "published_time": "2/27/2017", "rawpid": "1702.08139", "tags": ["cs.NE", "cs.CL", "cs.LG"], "title": "Improved Variational Autoencoders for Text Modeling using Dilated\n  Convolutions"}, {"abstract": "The paper [1] shows that simple linear classifier can compete with complex\ndeep learning algorithms in text classification applications. Combining bag of\nwords (BoW) and linear classification techniques, fastText [1] attains same or\nonly slightly lower accuracy than deep learning algorithms [2-9] that are\norders of magnitude slower. We proved formally that fastText can be transformed\ninto a simpler equivalent classifier, which unlike fastText does not have any\nhidden layer. We also proved that the necessary and sufficient dimensionality\nof the word vector embedding space is exactly the number of document classes.\nThese results help constructing more optimal linear text classifiers with\nguaranteed maximum classification capabilities. The results are proven exactly\nby pure formal algebraic methods without attracting any empirical data.", "authors": ["Vladimir Zolotov", "David Kung"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1702.05531v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1702.05531v1", "num_discussion": 0, "originally_published_time": "2/17/2017", "pid": "1702.05531v1", "published_time": "2/17/2017", "rawpid": "1702.05531", "tags": ["cs.CL"], "title": "Analysis and Optimization of fastText Linear Text Classifier"}, {"abstract": "Text Proposals have emerged as a class-dependent version of object proposals\n- efficient approaches to reduce the search space of possible text object\nlocations in an image. Combined with strong word classifiers, text proposals\ncurrently yield top state of the art results in end-to-end scene text\nrecognition. In this paper we propose an improvement over the original Text\nProposals algorithm of Gomez and Karatzas (2016), combining it with Fully\nConvolutional Networks to improve the ranking of proposals. Results on the\nICDAR RRC and the COCO-text datasets show superior performance over current\nstate-of-the-art.", "authors": ["Dena Bazazian", "Raul Gomez", "Anguelos Nicolaou", "Lluis Gomez", "Dimosthenis Karatzas", "Andrew D. Bagdanov"], "category": "cs.CV", "comment": "6 pages, 8 figures, International Conference on Pattern Recognition\n  (ICPR) - DLPR (Deep Learning f...", "img": "/static/thumbs/1702.05089v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1702.05089v1", "num_discussion": 0, "originally_published_time": "2/16/2017", "pid": "1702.05089v1", "published_time": "2/16/2017", "rawpid": "1702.05089", "tags": ["cs.CV"], "title": "Improving Text Proposals for Scene Images with Fully Convolutional\n  Networks"}, {"abstract": "Language students are most engaged while reading texts at an appropriate\ndifficulty level. However, existing methods of evaluating text difficulty focus\nmainly on vocabulary and do not prioritize grammatical features, hence they do\nnot work well for language learners with limited knowledge of grammar. In this\npaper, we introduce grammatical templates, the expert-identified units of\ngrammar that students learn from class, as an important feature of text\ndifficulty evaluation. Experimental classification results show that\ngrammatical template features significantly improve text difficulty prediction\naccuracy over baseline readability features by 7.4%. Moreover, we build a\nsimple and human-understandable text difficulty evaluation approach with 87.7%\naccuracy, using only 5 grammatical template features.", "authors": ["Shuhan Wang", "Erik Andersen"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1609.05180v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1609.05180v2", "num_discussion": 0, "originally_published_time": "9/16/2016", "pid": "1609.05180v2", "published_time": "2/15/2017", "rawpid": "1609.05180", "tags": ["cs.CL", "cs.AI"], "title": "Grammatical Templates: Improving Text Difficulty Evaluation for Language\n  Learners"}, {"abstract": "In this paper we describe approaches for discovering acoustic concepts and\nrelations in text. The first major goal is to be able to identify text phrases\nwhich contain a notion of audibility and can be termed as a sound or an\nacoustic concept. We also propose a method to define an acoustic scene through\na set of sound concepts. We use pattern matching and parts of speech tags to\ngenerate sound concepts from large scale text corpora. We use dependency\nparsing and LSTM recurrent neural network to predict a set of sound concepts\nfor a given acoustic scene. These methods are not only helpful in creating an\nacoustic knowledge base but in the future can also directly help acoustic event\nand scene detection research.", "authors": ["Anurag Kumar", "Bhiksha Raj", "Ndapandula Nakashole"], "category": "cs.SD", "comment": "ICASSP 2017", "img": "/static/thumbs/1609.07384v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1609.07384v2", "num_discussion": 0, "originally_published_time": "9/23/2016", "pid": "1609.07384v2", "published_time": "2/13/2017", "rawpid": "1609.07384", "tags": ["cs.SD", "cs.AI", "cs.LG"], "title": "Discovering Sound Concepts and Acoustic Relations In Text"}, {"abstract": "Turkish Wikipedia Named-Entity Recognition and Text Categorization (TWNERTC)\ndataset is a collection of automatically categorized and annotated sentences\nobtained from Wikipedia. We constructed large-scale gazetteers by using a graph\ncrawler algorithm to extract relevant entity and domain information from a\nsemantic knowledge base, Freebase. The constructed gazetteers contains\napproximately 300K entities with thousands of fine-grained entity types under\n77 different domains. Since automated processes are prone to ambiguity, we also\nintroduce two new content specific noise reduction methodologies. Moreover, we\nmap fine-grained entity types to the equivalent four coarse-grained types:\nperson, loc, org, misc. Eventually, we construct six different dataset versions\nand evaluate the quality of annotations by comparing ground truths from human\nannotators. We make these datasets publicly available to support studies on\nTurkish named-entity recognition (NER) and text categorization (TC).", "authors": ["H. Bahadir Sahin", "Caglar Tirkaz", "Eray Yildiz", "Mustafa Tolga Eren", "Ozan Sonmez"], "category": "cs.CL", "comment": "10 page, 1 figure, white paper, update: added correct download link\n  for dataset", "img": "/static/thumbs/1702.02363v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1702.02363v2", "num_discussion": 0, "originally_published_time": "2/8/2017", "pid": "1702.02363v2", "published_time": "2/9/2017", "rawpid": "1702.02363", "tags": ["cs.CL"], "title": "Automatically Annotated Turkish Corpus for Named Entity Recognition and\n  Text Categorization using Large-Scale Gazetteers"}, {"abstract": "In this paper we explore the effect of architectural choices on learning a\nVariational Autoencoder (VAE) for text generation. In contrast to the\npreviously introduced VAE model for text where both the encoder and decoder are\nRNNs, we propose a novel hybrid architecture that blends fully feed-forward\nconvolutional and deconvolutional components with a recurrent language model.\nOur architecture exhibits several attractive properties such as faster run time\nand convergence, ability to better handle long sequences and, more importantly,\nit helps to avoid some of the major difficulties posed by training VAE models\non textual data.", "authors": ["Stanislau Semeniuta", "Aliaksei Severyn", "Erhardt Barth"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1702.02390v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1702.02390v1", "num_discussion": 0, "originally_published_time": "2/8/2017", "pid": "1702.02390v1", "published_time": "2/8/2017", "rawpid": "1702.02390", "tags": ["cs.CL"], "title": "A Hybrid Convolutional Variational Autoencoder for Text Generation"}, {"abstract": "Automatic speech recognition (ASR) and Text to speech (TTS) are two prominent\narea of research in human computer interaction nowadays. A set of phonetically\nrich sentences is in a matter of importance in order to develop these two\ninteractive modules of HCI. Essentially, the set of phonetically rich sentences\nhas to cover all possible phone units distributed uniformly. Selecting such a\nset from a big corpus with maintaining phonetic characteristic based similarity\nis still a challenging problem. The major objective of this paper is to devise\na criteria in order to select a set of sentences encompassing all phonetic\naspects of a corpus with size as minimum as possible. First, this paper\npresents a statistical analysis of Hindi phonetics by observing the structural\ncharacteristics. Further a two stage algorithm is proposed to extract\nphonetically rich sentences with a high variety of triphones from the EMILLE\nHindi corpus. The algorithm consists of a distance measuring criteria to select\na sentence in order to improve the triphone distribution. Moreover, a special\npreprocessing method is proposed to score each triphone in terms of inverse\nprobability in order to fasten the algorithm. The results show that the\napproach efficiently build uniformly distributed phonetically-rich corpus with\noptimum number of sentences.", "authors": ["Shrikant Malviya", "Rohit Mishra", "Uma Shanker Tiwary"], "category": "cs.CL", "comment": "19th Coordination and Standardization of Speech Databases and\n  Assessment Technique (O-COCOSDA) at ...", "img": "/static/thumbs/1701.08655v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1701.08655v2", "num_discussion": 0, "originally_published_time": "1/30/2017", "pid": "1701.08655v2", "published_time": "2/7/2017", "rawpid": "1701.08655", "tags": ["cs.CL"], "title": "Structural Analysis of Hindi Phonetics and A Method for Extraction of\n  Phonetically Rich Sentences from a Very Large Hindi Text Corpus"}, {"abstract": "Arabic language is one of the most popular languages in the world. Hundreds\nof millions of people in many countries around the world speak Arabic as their\nnative speaking. However, due to complexity of Arabic language, recognition of\nprinted and handwritten Arabic text remained untouched for a very long time\ncompared with English and Chinese. Although, in the last few years, significant\nnumber of researches has been done in recognizing printed and handwritten\nArabic text, it stills an open research field due to cursive nature of Arabic\nscript. This paper proposes automatic printed Arabic text recognition technique\nbased on linear and ellipse regression techniques. After collecting all\npossible forms of each character, unique code is generated to represent each\ncharacter form. Each code contains a sequence of lines and ellipses. To\nrecognize fonts, a unique list of codes is identified to be used as a\nfingerprint of font. The proposed technique has been evaluated using over 14000\ndifferent Arabic words with different fonts and experimental results show that\naverage recognition rate of the proposed technique is 86%.", "authors": ["Ashraf A. Shahin"], "category": "cs.CV", "comment": "http://thesai.org/Downloads/Volume8No1/Paper_29-Printed_Arabic_Text_Recognition_using_Linear.pdf", "img": "/static/thumbs/1702.01444v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1702.01444v1", "num_discussion": 0, "originally_published_time": "2/5/2017", "pid": "1702.01444v1", "published_time": "2/5/2017", "rawpid": "1702.01444", "tags": ["cs.CV"], "title": "Printed Arabic Text Recognition using Linear and Nonlinear Regression"}, {"abstract": "Use of social media has grown dramatically during the last few years. Users\nfollow informal languages in communicating through social media. The language\nof communication is often mixed in nature, where people transcribe their\nregional language with English and this technique is found to be extremely\npopular. Natural language processing (NLP) aims to infer the information from\nthese text where Part-of-Speech (PoS) tagging plays an important role in\ngetting the prosody of the written text. For the task of PoS tagging on\nCode-Mixed Indian Social Media Text, we develop a supervised system based on\nConditional Random Field classifier. In order to tackle the problem\neffectively, we have focused on extracting rich linguistic features. We\nparticipate in three different language pairs, ie. English-Hindi,\nEnglish-Bengali and English-Telugu on three different social media platforms,\nTwitter, Facebook \u0026 WhatsApp. The proposed system is able to successfully\nassign coarse as well as fine-grained PoS tag labels for a given a code-mixed\nsentence. Experiments show that our system is quite generic that shows\nencouraging performance levels on all the three language pairs in all the\ndomains.", "authors": ["Deepak Gupta", "Shubham Tripathi", "Asif Ekbal", "Pushpak Bhattacharyya"], "category": "cs.CL", "comment": "5 pages, ICON 2016", "img": "/static/thumbs/1702.00167v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1702.00167v2", "num_discussion": 0, "originally_published_time": "2/1/2017", "pid": "1702.00167v2", "published_time": "2/2/2017", "rawpid": "1702.00167", "tags": ["cs.CL"], "title": "SMPOST: Parts of Speech Tagger for Code-Mixed Indic Social Media Text"}, {"abstract": "This paper focuses on the problem of script identification in scene text\nimages. Facing this problem with state of the art CNN classifiers is not\nstraightforward, as they fail to address a key characteristic of scene text\ninstances: their extremely variable aspect ratio. Instead of resizing input\nimages to a fixed aspect ratio as in the typical use of holistic CNN\nclassifiers, we propose here a patch-based classification framework in order to\npreserve discriminative parts of the image that are characteristic of its\nclass. We describe a novel method based on the use of ensembles of conjoined\nnetworks to jointly learn discriminative stroke-parts representations and their\nrelative importance in a patch-based classification scheme. Our experiments\nwith this learning procedure demonstrate state-of-the-art results in two public\nscript identification datasets. In addition, we propose a new public benchmark\ndataset for the evaluation of multi-lingual scene text end-to-end reading\nsystems. Experiments done in this dataset demonstrate the key role of script\nidentification in a complete end-to-end system that combines our script\nidentification method with a previously published text detector and an\noff-the-shelf OCR engine.", "authors": ["Lluis Gomez", "Anguelos Nicolaou", "Dimosthenis Karatzas"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1602.07480v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1602.07480v2", "num_discussion": 0, "originally_published_time": "2/24/2016", "pid": "1602.07480v2", "published_time": "2/1/2017", "rawpid": "1602.07480", "tags": ["cs.CV"], "title": "Improving patch-based scene text script identification with ensembles of\n  conjoined networks"}, {"abstract": "A drug can affect the activity of other drugs, when administered together, in\nboth synergistic or antagonistic ways. In one hand synergistic effects lead to\nimproved therapeutic outcomes, antagonistic consequences can be\nlife-threatening, leading to increased healthcare cost, or may even cause\ndeath. Thus, identification of unknown drug-drug interaction (DDI) is an\nimportant concern for efficient and effective healthcare. Although there exist\nmultiple resources for DDI, they often unable to keep pace with rich amount of\ninformation available in fast growing biomedical texts including literature.\nMost existing methods model DDI extraction from text as classification problem\nand mainly rely on handcrafted features. Some of these features further depends\non domain specific tools. Recently neural network models using latent features\nhas shown to be perform similar or better than the other existing models using\nhandcrafted features. In this paper, we present three models namely, B-LSTM,\nAB-LSTM and Joint AB-LSTM based on long short-term memory (LSTM) network. All\nthree models utilize word and position embedding as latent features and thus do\nnot rely on feature engineering. Further use of bidirectional long short-term\nmemory (Bi-LSTM) networks allow to extract optimal features from the whole\nsentence. The two models, AB-LSTM and Joint AB-LSTM also use attentive pooling\nin the output of Bi-LSTM layer to assign weights to features. Our experimental\nresults on the SemEval-2013 DDI extraction dataset shows that the Joint AB-LSTM\nmodel outperforms all the existing methods, including those relying on\nhandcrafted features. The other two proposed models also perform competitively\nwith state-of-the-art methods.", "authors": ["Sunil Kumar Sahu", "Ashish Anand"], "category": "cs.CL", "comment": "10 pages, 3 figures", "img": "/static/thumbs/1701.08303v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1701.08303v1", "num_discussion": 0, "originally_published_time": "1/28/2017", "pid": "1701.08303v1", "published_time": "1/28/2017", "rawpid": "1701.08303", "tags": ["cs.CL"], "title": "Drug-Drug Interaction Extraction from Biomedical Text Using Long Short\n  Term Memory Network"}, {"abstract": "The dominant approach for many NLP tasks are recurrent neural networks, in\nparticular LSTMs, and convolutional neural networks. However, these\narchitectures are rather shallow in comparison to the deep convolutional\nnetworks which have pushed the state-of-the-art in computer vision. We present\na new architecture (VDCNN) for text processing which operates directly at the\ncharacter level and uses only small convolutions and pooling operations. We are\nable to show that the performance of this model increases with depth: using up\nto 29 convolutional layers, we report improvements over the state-of-the-art on\nseveral public text classification tasks. To the best of our knowledge, this is\nthe first time that very deep convolutional nets have been applied to text\nprocessing.", "authors": ["Alexis Conneau", "Holger Schwenk", "Lo\u00efc Barrault", "Yann Lecun"], "category": "cs.CL", "comment": "10 pages, EACL 2017, camera-ready", "img": "/static/thumbs/1606.01781v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1606.01781v2", "num_discussion": 0, "originally_published_time": "6/6/2016", "pid": "1606.01781v2", "published_time": "1/27/2017", "rawpid": "1606.01781", "tags": ["cs.CL", "cs.LG", "cs.NE"], "title": "Very Deep Convolutional Networks for Text Classification"}, {"abstract": "This paper presents a challenge to the community: given a large corpus of\nwritten text aligned to its normalized spoken form, train an RNN to learn the\ncorrect normalization function. We present a data set of general text where the\nnormalizations were generated using an existing text normalization component of\na text-to-speech system. This data set will be released open-source in the near\nfuture.\n  We also present our own experiments with this data set with a variety of\ndifferent RNN architectures. While some of the architectures do in fact produce\nvery good results when measured in terms of overall accuracy, the errors that\nare produced are problematic, since they would convey completely the wrong\nmessage if such a system were deployed in a speech application. On the other\nhand, we show that a simple FST-based filter can mitigate those errors, and\nachieve a level of accuracy not achievable by the RNN alone.\n  Though our conclusions are largely negative on this point, we are actually\nnot arguing that the text normalization problem is intractable using an pure\nRNN approach, merely that it is not going to be something that can be solved\nmerely by having huge amounts of annotated text data and feeding that to a\ngeneral RNN model. And when we open-source our data, we will be providing a\nnovel data set for sequence-to-sequence modeling in the hopes that the the\ncommunity can find better solutions.\n  The data used in this work have been released and are available at:\nhttps://github.com/rwsproat/text-normalization-data", "authors": ["Richard Sproat", "Navdeep Jaitly"], "category": "cs.CL", "comment": "17 pages, 13 tables, 3 figures", "img": "/static/thumbs/1611.00068v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1611.00068v2", "num_discussion": 0, "originally_published_time": "10/31/2016", "pid": "1611.00068v2", "published_time": "1/24/2017", "rawpid": "1611.00068", "tags": ["cs.CL"], "title": "RNN Approaches to Text Normalization: A Challenge"}, {"abstract": "We address the problem of multiclass classification in the case where the\nnumber of classes is very large. We propose a multiclass to binary reduction\nstrategy, in which we transform the original problem into a binary\nclassification one over pairs of examples. We derive generalization bounds for\nthe error of the classifier of pairs using local Rademacher complexity, and a\ndouble sampling strategy (in the terms of examples and classes) that speeds up\nthe training phase while maintaining a very low memory usage. Experiments are\ncarried for text classification on DMOZ and Wikipedia collections with up to\n20,000 classes in order to show the efficiency of the proposed method.", "authors": ["Bikash Joshi", "Massih-Reza Amini", "Ioannis Partalas", "Franck Iutzeler", "Yury Maximov"], "category": "stat.ML", "comment": "18 pages, 4 figures", "img": "/static/thumbs/1701.06511v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1701.06511v1", "num_discussion": 0, "originally_published_time": "1/23/2017", "pid": "1701.06511v1", "published_time": "1/23/2017", "rawpid": "1701.06511", "tags": ["stat.ML", "cs.LG"], "title": "Aggressive Sampling for Multi-class to Binary Reduction with\n  Applications to Text Classification"}, {"abstract": "We study how collective memories are formed online. We do so by tracking\nentities that emerge in public discourse, that is, in online text streams such\nas social media and news streams, before they are incorporated into Wikipedia,\nwhich, we argue, can be viewed as an online place for collective memory. By\ntracking how entities emerge in public discourse, i.e., the temporal patterns\nbetween their first mention in online text streams and subsequent incorporation\ninto collective memory, we gain insights into how the collective remembrance\nprocess happens online. Specifically, we analyze nearly 80,000 entities as they\nemerge in online text streams before they are incorporated into Wikipedia. The\nonline text streams we use for our analysis comprise of social media and news\nstreams, and span over 579 million documents in a timespan of 18 months. We\ndiscover two main emergence patterns: entities that emerge in a \"bursty\"\nfashion, i.e., that appear in public discourse without a precedent, blast into\nactivity and transition into collective memory. Other entities display a\n\"delayed\" pattern, where they appear in public discourse, experience a period\nof inactivity, and then resurface before transitioning into our cultural\ncollective memory.", "authors": ["David Graus", "Daan Odijk", "Maarten de Rijke"], "category": "cs.IR", "comment": "37 pages, 10 figures", "img": "/static/thumbs/1701.04039v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1701.04039v1", "num_discussion": 0, "originally_published_time": "1/15/2017", "pid": "1701.04039v1", "published_time": "1/15/2017", "rawpid": "1701.04039", "tags": ["cs.IR", "cs.CL"], "title": "The Birth of Collective Memories: Analyzing Emerging Entities in Text\n  Streams"}, {"abstract": "The problem of outlier detection is extremely challenging in many domains\nsuch as text, in which the attribute values are typically non-negative, and\nmost values are zero. In such cases, it often becomes difficult to separate the\noutliers from the natural variations in the patterns in the underlying data. In\nthis paper, we present a matrix factorization method, which is naturally able\nto distinguish the anomalies with the use of low rank approximations of the\nunderlying data. Our iterative algorithm TONMF is based on block coordinate\ndescent (BCD) framework. We define blocks over the term-document matrix such\nthat the function becomes solvable. Given most recently updated values of other\nmatrix blocks, we always update one block at a time to its optimal. Our\napproach has significant advantages over traditional methods for text outlier\ndetection. Finally, we present experimental results illustrating the\neffectiveness of our method over competing methods.", "authors": ["Ramakrishnan Kannan", "Hyenkyun Woo", "Charu C. Aggarwal", "Haesun Park"], "category": "cs.IR", "comment": "Accepted at 2017 SIAM Data Mining Conference", "img": "/static/thumbs/1701.01325v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1701.01325v1", "num_discussion": 0, "originally_published_time": "1/5/2017", "pid": "1701.01325v1", "published_time": "1/5/2017", "rawpid": "1701.01325", "tags": ["cs.IR", "cs.LG", "stat.ML"], "title": "Outlier Detection for Text Data : An Extended Version"}, {"abstract": "Short text clustering is a challenging problem due to its sparseness of text\nrepresentation. Here we propose a flexible Self-Taught Convolutional neural\nnetwork framework for Short Text Clustering (dubbed STC^2), which can flexibly\nand successfully incorporate more useful semantic features and learn non-biased\ndeep text representation in an unsupervised manner. In our framework, the\noriginal raw text features are firstly embedded into compact binary codes by\nusing one existing unsupervised dimensionality reduction methods. Then, word\nembeddings are explored and fed into convolutional neural networks to learn\ndeep feature representations, meanwhile the output units are used to fit the\npre-trained binary codes in the training process. Finally, we get the optimal\nclusters by employing K-means to cluster the learned representations. Extensive\nexperimental results demonstrate that the proposed framework is effective,\nflexible and outperform several popular clustering methods when tested on three\npublic short text datasets.", "authors": ["Jiaming Xu", "Bo Xu", "Peng Wang", "Suncong Zheng", "Guanhua Tian", "Jun Zhao", "Bo Xu"], "category": "cs.IR", "comment": "33 pages, accepted for publication in Neural Networks", "img": "/static/thumbs/1701.00185v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1701.00185v1", "num_discussion": 0, "originally_published_time": "1/1/2017", "pid": "1701.00185v1", "published_time": "1/1/2017", "rawpid": "1701.00185", "tags": ["cs.IR", "cs.CL"], "title": "Self-Taught Convolutional Neural Networks for Short Text Clustering"}, {"abstract": "Building Part-of-Speech (POS) taggers for code-mixed Indian languages is a\nparticularly challenging problem in computational linguistics due to a dearth\nof accurately annotated training corpora. ICON, as part of its NLP tools\ncontest has organized this challenge as a shared task for the second\nconsecutive year to improve the state-of-the-art. This paper describes the POS\ntagger built at Surukam to predict the coarse-grained and fine-grained POS tags\nfor three language pairs - Bengali-English, Telugu-English and Hindi-English,\nwith the text spanning three popular social media platforms - Facebook,\nWhatsApp and Twitter. We employed Conditional Random Fields as the sequence\ntagging algorithm and used a library called sklearn-crfsuite - a thin wrapper\naround CRFsuite for training our model. Among the features we used include -\ncharacter n-grams, language information and patterns for emoji, number,\npunctuation and web-address. Our submissions in the constrained\nenvironment,i.e., without making any use of monolingual POS taggers or the\nlike, obtained an overall average F1-score of 76.45%, which is comparable to\nthe 2015 winning score of 76.79%.", "authors": ["Sree Harsha Ramesh", "Raveena R Kumar"], "category": "cs.CL", "comment": "4 Pages, 13th International Conference on Natural Language\n  Processing, Varanasi, India", "img": "/static/thumbs/1701.00066v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1701.00066v1", "num_discussion": 0, "originally_published_time": "12/31/2016", "pid": "1701.00066v1", "published_time": "12/31/2016", "rawpid": "1701.00066", "tags": ["cs.CL"], "title": "A POS Tagger for Code Mixed Indian Social Media Text - ICON-2016 NLP\n  Tools Contest Entry from Surukam"}, {"abstract": "People typically learn through exposure to visual concepts associated with\nlinguistic descriptions. For instance, teaching visual object categories to\nchildren is often accompanied by descriptions in text or speech. In a machine\nlearning context, these observations motivates us to ask whether this learning\nprocess could be computationally modeled to learn visual classifiers. More\nspecifically, the main question of this work is how to utilize purely textual\ndescription of visual classes with no training images, to learn explicit visual\nclassifiers for them. We propose and investigate two baseline formulations,\nbased on regression and domain transfer, that predict a linear classifier.\nThen, we propose a new constrained optimization formulation that combines a\nregression function and a knowledge transfer function with additional\nconstraints to predict the parameters of a linear classifier. We also propose a\ngeneric kernelized models where a kernel classifier is predicted in the form\ndefined by the representer theorem. The kernelized models allow defining and\nutilizing any two RKHS (Reproducing Kernel Hilbert Space) kernel functions in\nthe visual space and text space, respectively. We finally propose a kernel\nfunction between unstructured text descriptions that builds on distributional\nsemantics, which shows an advantage in our setting and could be useful for\nother applications. We applied all the studied models to predict visual\nclassifiers on two fine-grained and challenging categorization datasets (CU\nBirds and Flower Datasets), and the results indicate successful predictions of\nour final model over several baselines that we designed.", "authors": ["Mohamed Elhoseiny", "Ahmed Elgammal", "Babak Saleh"], "category": "cs.CV", "comment": "(TPAMI) Transactions on Pattern Analysis and Machine Intelligence\n  2017", "img": "/static/thumbs/1601.00025v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1601.00025v2", "num_discussion": 0, "originally_published_time": "12/31/2015", "pid": "1601.00025v2", "published_time": "12/28/2016", "rawpid": "1601.00025", "tags": ["cs.CV", "cs.CL", "cs.LG"], "title": "Write a Classifier: Predicting Visual Classifiers from Unstructured Text"}, {"abstract": "In this work, we describe a conditional random fields (CRF) based system for\nPart-Of- Speech (POS) tagging of code-mixed Indian social media text as part of\nour participation in the tool contest on POS tagging for codemixed Indian\nsocial media text, held in conjunction with the 2016 International Conference\non Natural Language Processing, IIT(BHU), India. We participated only in\nconstrained mode contest for all three language pairs, Bengali-English,\nHindi-English and Telegu-English. Our system achieves the overall average F1\nscore of 79.99, which is the highest overall average F1 score among all 16\nsystems participated in constrained mode contest.", "authors": ["Kamal Sarkar"], "category": "cs.CL", "comment": "This work is awarded the first prize in the NLP tool contest on \"POS\n  Tagging for Code-Mixed Indian...", "img": "/static/thumbs/1612.07956v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1612.07956v1", "num_discussion": 0, "originally_published_time": "12/23/2016", "pid": "1612.07956v1", "published_time": "12/23/2016", "rawpid": "1612.07956", "tags": ["cs.CL"], "title": "A CRF Based POS Tagger for Code-mixed Indian Social Media Text"}, {"abstract": "Text documents can be described by a number of abstract concepts such as\nsemantic category, writing style, or sentiment. Machine learning (ML) models\nhave been trained to automatically map documents to these abstract concepts,\nallowing to annotate very large text collections, more than could be processed\nby a human in a lifetime. Besides predicting the text\u0027s category very\naccurately, it is also highly desirable to understand how and why the\ncategorization process takes place. In this paper, we demonstrate that such\nunderstanding can be achieved by tracing the classification decision back to\nindividual words using layer-wise relevance propagation (LRP), a recently\ndeveloped technique for explaining predictions of complex non-linear\nclassifiers. We train two word-based ML models, a convolutional neural network\n(CNN) and a bag-of-words SVM classifier, on a topic categorization task and\nadapt the LRP method to decompose the predictions of these models onto words.\nResulting scores indicate how much individual words contribute to the overall\nclassification decision. This enables one to distill relevant information from\ntext documents without an explicit semantic information extraction step. We\nfurther use the word-wise relevance scores for generating novel vector-based\ndocument representations which capture semantic information. Based on these\ndocument vectors, we introduce a measure of model explanatory power and show\nthat, although the SVM and CNN models perform similarly in terms of\nclassification accuracy, the latter exhibits a higher level of explainability\nwhich makes it more comprehensible for humans and potentially more useful for\nother applications.", "authors": ["Leila Arras", "Franziska Horn", "Gr\u00e9goire Montavon", "Klaus-Robert M\u00fcller", "Wojciech Samek"], "category": "cs.CL", "comment": "19 pages, 7 figures", "img": "/static/thumbs/1612.07843v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1612.07843v1", "num_discussion": 0, "originally_published_time": "12/23/2016", "pid": "1612.07843v1", "published_time": "12/23/2016", "rawpid": "1612.07843", "tags": ["cs.CL", "cs.IR", "cs.LG", "stat.ML"], "title": "\"What is Relevant in a Text Document?\": An Interpretable Machine\n  Learning Approach"}, {"abstract": "We introduce a new multi-modal task for computer systems, posed as a combined\nvision-language comprehension challenge: identifying the most suitable text\ndescribing a scene, given several similar options. Accomplishing the task\nentails demonstrating comprehension beyond just recognizing \"keywords\" (or\nkey-phrases) and their corresponding visual concepts. Instead, it requires an\nalignment between the representations of the two modalities that achieves a\nvisually-grounded \"understanding\" of various linguistic elements and their\ndependencies. This new task also admits an easy-to-compute and well-studied\nmetric: the accuracy in detecting the true target among the decoys.\n  The paper makes several contributions: an effective and extensible mechanism\nfor generating decoys from (human-created) image captions; an instance of\napplying this mechanism, yielding a large-scale machine comprehension dataset\n(based on the COCO images and captions) that we make publicly available; human\nevaluation results on this dataset, informing a performance upper-bound; and\nseveral baseline and competitive learning approaches that illustrate the\nutility of the proposed task and dataset in advancing both image and language\ncomprehension. We also show that, in a multi-task learning setting, the\nperformance on the proposed task is positively correlated with the end-to-end\ntask of image captioning.", "authors": ["Nan Ding", "Sebastian Goodman", "Fei Sha", "Radu Soricut"], "category": "cs.CL", "comment": "11 pages", "img": "/static/thumbs/1612.07833v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1612.07833v1", "num_discussion": 0, "originally_published_time": "12/22/2016", "pid": "1612.07833v1", "published_time": "12/22/2016", "rawpid": "1612.07833", "tags": ["cs.CL", "cs.CV"], "title": "Understanding Image and Text Simultaneously: a Dual Vision-Language\n  Machine Comprehension Task"}, {"abstract": "We investigate what distinguishes reported dreams from other personal\nnarratives. The continuity hypothesis, stemming from psychological dream\nanalysis work, states that most dreams refer to a person\u0027s daily life and\npersonal concerns, similar to other personal narratives such as diary entries.\nDifferences between the two texts may reveal the linguistic markers of dream\ntext, which could be the basis for new dream analysis work and for the\nautomatic detection of dream descriptions. We used three text analytics\nmethods: text classification, topic modeling, and text coherence analysis, and\napplied these methods to a balanced set of texts representing dreams, diary\nentries, and other personal stories. We observed that dream texts could be\ndistinguished from other personal narratives nearly perfectly, mostly based on\nthe presence of uncertainty markers and descriptions of scenes. Important\nmarkers for non-dream narratives are specific time expressions and\nconversational expressions. Dream texts also exhibit a lower discourse\ncoherence than other personal narratives.", "authors": ["Iris Hendrickx", "Louis Onrust", "Florian Kunneman", "Ali H\u00fcrriyeto\u011flu", "Antal van den Bosch", "Wessel Stoop"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1612.03659v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1612.03659v1", "num_discussion": 0, "originally_published_time": "12/12/2016", "pid": "1612.03659v1", "published_time": "12/12/2016", "rawpid": "1612.03659", "tags": ["cs.CL"], "title": "Unraveling reported dreams with text analytics"}, {"abstract": "We consider the problem of producing compact architectures for text\nclassification, such that the full model fits in a limited amount of memory.\nAfter considering different solutions inspired by the hashing literature, we\npropose a method built upon product quantization to store word embeddings.\nWhile the original technique leads to a loss in accuracy, we adapt this method\nto circumvent quantization artefacts. Our experiments carried out on several\nbenchmarks show that our approach typically requires two orders of magnitude\nless memory than fastText while being only slightly inferior with respect to\naccuracy. As a result, it outperforms the state of the art by a good margin in\nterms of the compromise between memory usage and accuracy.", "authors": ["Armand Joulin", "Edouard Grave", "Piotr Bojanowski", "Matthijs Douze", "H\u00e9rve J\u00e9gou", "Tomas Mikolov"], "category": "cs.CL", "comment": "Submitted to ICLR 2017", "img": "/static/thumbs/1612.03651v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1612.03651v1", "num_discussion": 0, "originally_published_time": "12/12/2016", "pid": "1612.03651v1", "published_time": "12/12/2016", "rawpid": "1612.03651", "tags": ["cs.CL"], "title": "FastText.zip: Compressing text classification models"}, {"abstract": "In this paper, we develop a binary convolutional encoder-decoder network\n(B-CEDNet) for natural scene text processing (NSTP). It converts a text image\nto a class-distinguished salience map that reveals the categorical, spatial and\nmorphological information of characters. The existing solutions are either\nmemory consuming or run-time consuming that cannot be applied to real-time\napplications on resource-constrained devices such as advanced driver assistance\nsystems. The developed network can process multiple regions containing\ncharacters by one-off forward operation, and is trained to have binary weights\nand binary feature maps, which lead to both remarkable inference run-time\nspeedup and memory usage reduction. By training with over 200, 000 synthesis\nscene text images (size of $32\\times128$), it can achieve $90\\%$ and $91\\%$\npixel-wise accuracy on ICDAR-03 and ICDAR-13 datasets. It only consumes $4.59\\\nms$ inference run-time realized on GPU with a small network size of 2.14 MB,\nwhich is up to $8\\times$ faster and $96\\%$ smaller than it full-precision\nversion.", "authors": ["Zichuan Liu", "Yixing Li", "Fengbo Ren", "Hao Yu"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1612.03630v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1612.03630v1", "num_discussion": 0, "originally_published_time": "12/12/2016", "pid": "1612.03630v1", "published_time": "12/12/2016", "rawpid": "1612.03630", "tags": ["cs.CV"], "title": "A Binary Convolutional Encoder-decoder Network for Real-time Natural\n  Scene Text Processing"}, {"abstract": "Synthesizing photo-realistic images from text descriptions is a challenging\nproblem in computer vision and has many practical applications. Samples\ngenerated by existing text-to-image approaches can roughly reflect the meaning\nof the given descriptions, but they fail to contain necessary details and vivid\nobject parts. In this paper, we propose stacked Generative Adversarial Networks\n(StackGAN) to generate photo-realistic images conditioned on text descriptions.\nThe Stage-I GAN sketches the primitive shape and basic colors of the object\nbased on the given text description, yielding Stage-I low resolution images.\nThe Stage-II GAN takes Stage-I results and text descriptions as inputs, and\ngenerates high resolution images with photo-realistic details. The Stage-II GAN\nis able to rectify defects and add compelling details with the refinement\nprocess. Samples generated by StackGAN are more plausible than those generated\nby existing approaches. Importantly, our StackGAN for the first time generates\nrealistic 256 x 256 images conditioned on only text descriptions, while\nstate-of-the-art methods can generate at most 128 x 128 images. To demonstrate\nthe effectiveness of the proposed StackGAN, extensive experiments are conducted\non CUB and Oxford-102 datasets, which contain enough object appearance\nvariations and are widely-used for text-to-image generation analysis.", "authors": ["Han Zhang", "Tao Xu", "Hongsheng Li", "Shaoting Zhang", "Xiaolei Huang", "Xiaogang Wang", "Dimitris Metaxas"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1612.03242v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1612.03242v1", "num_discussion": 0, "originally_published_time": "12/10/2016", "pid": "1612.03242v1", "published_time": "12/10/2016", "rawpid": "1612.03242", "tags": ["cs.CV", "cs.AI", "stat.ML"], "title": "StackGAN: Text to Photo-realistic Image Synthesis with Stacked\n  Generative Adversarial Networks"}, {"abstract": "In this work, we explore the problem of generating fantastic special-effects\nfor the typography. It is quite challenging due to the model diversities to\nillustrate varied text effects for different characters. To address this issue,\nour key idea is to exploit the analytics on the high regularity of the spatial\ndistribution for text effects to guide the synthesis process. Specifically, we\ncharacterize the stylized patches by their normalized positions and the optimal\nscales to depict their style elements. Our method first estimates these two\nfeatures and derives their correlation statistically. They are then converted\ninto soft constraints for texture transfer to accomplish adaptive multi-scale\ntexture synthesis and to make style element distribution uniform. It allows our\nalgorithm to produce artistic typography that fits for both local texture\npatterns and the global spatial distribution in the example. Experimental\nresults demonstrate the superiority of our method for various text effects over\nconventional style transfer methods. In addition, we validate the effectiveness\nof our algorithm with extensive artistic typography library generation.", "authors": ["Shuai Yang", "Jiaying Liu", "Zhouhui Lian", "Zongming Guo"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1611.09026v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1611.09026v2", "num_discussion": 0, "originally_published_time": "11/28/2016", "pid": "1611.09026v2", "published_time": "12/6/2016", "rawpid": "1611.09026", "tags": ["cs.CV"], "title": "Awesome Typography: Statistics-Based Text Effects Transfer"}, {"abstract": "The biggest challenge in the field of image processing is to recognize\ndocuments both in printed and handwritten format. Optical Character Recognition\nOCR is a type of document image analysis where scanned digital image that\ncontains either machine printed or handwritten script input into an OCR\nsoftware engine and translating it into an editable machine readable digital\ntext format. A Neural network is designed to model the way in which the brain\nperforms a particular task or function of interest: The neural network is\nsimulated in software on a digital computer. Character Recognition refers to\nthe process of converting printed Text documents into translated Unicode Text.\nThe printed documents available in the form of books, papers, magazines, etc.\nare scanned using standard scanners which produce an image of the scanned\ndocument. Lines are identifying by an algorithm where we identify top and\nbottom of line. Then in each line character boundaries are calculated by an\nalgorithm then using these calculation, characters is isolated from the image\nand then we classify each character by basic back propagation. Each image\ncharacter is comprised of 30*20 pixels. We have used the Back propagation\nNeural Network for efficient recognition where the errors were corrected\nthrough back propagation and rectified neuron values were transmitted by\nfeed-forward method in the neural network of multiple layers.", "authors": ["Singh Vijendra", "Nisha Vasudeva", "Hem Jyotsana Parashar"], "category": "cs.CV", "comment": "2011 IEEE 3rd International Conference on Machine Learning and\n  Computing (ICMLC 2011, Singapore, P...", "img": "/static/thumbs/1612.00625v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1612.00625v1", "num_discussion": 0, "originally_published_time": "12/2/2016", "pid": "1612.00625v1", "published_time": "12/2/2016", "rawpid": "1612.00625", "tags": ["cs.CV"], "title": "Recognition of Text Image Using Multilayer Perceptron"}, {"abstract": "We propose a new active learning (AL) method for text classification with\nconvolutional neural networks (CNNs). In AL, one selects the instances to be\nmanually labeled with the aim of maximizing model performance with minimal\neffort. Neural models capitalize on word embeddings as representations\n(features), tuning these to the task at hand. We argue that AL strategies for\nmulti-layered neural models should focus on selecting instances that most\naffect the embedding space (i.e., induce discriminative word representations).\nThis is in contrast to traditional AL approaches (e.g., entropy-based\nuncertainty sampling), which specify higher level objectives. We propose a\nsimple approach for sentence classification that selects instances containing\nwords whose embeddings are likely to be updated with the greatest magnitude,\nthereby rapidly learning discriminative, task-specific embeddings. We extend\nthis approach to document classification by jointly considering: (1) the\nexpected changes to the constituent word representations; and (2) the model\u0027s\ncurrent overall uncertainty regarding the instance. The relative emphasis\nplaced on these criteria is governed by a stochastic process that favors\nselecting instances likely to improve representations at the outset of\nlearning, and then shifts toward general uncertainty sampling as AL progresses.\nEmpirical results show that our method outperforms baseline AL approaches on\nboth sentence and document classification tasks. We also show that, as\nexpected, the method quickly learns discriminative word embeddings. To the best\nof our knowledge, this is the first work on AL addressing neural models for\ntext classification.", "authors": ["Ye Zhang", "Matthew Lease", "Byron C. Wallace"], "category": "cs.CL", "comment": "This paper got accepted by AAAI 2017", "img": "/static/thumbs/1606.04212v4.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1606.04212v4", "num_discussion": 0, "originally_published_time": "6/14/2016", "pid": "1606.04212v4", "published_time": "12/1/2016", "rawpid": "1606.04212", "tags": ["cs.CL"], "title": "Active Discriminative Text Representation Learning"}, {"abstract": "Understanding human actions is a key problem in computer vision. However,\nrecognizing actions is only the first step of understanding what a person is\ndoing. In this paper, we introduce the problem of predicting why a person has\nperformed an action in images. This problem has many applications in human\nactivity understanding, such as anticipating or explaining an action. To study\nthis problem, we introduce a new dataset of people performing actions annotated\nwith likely motivations. However, the information in an image alone may not be\nsufficient to automatically solve this task. Since humans can rely on their\nlifetime of experiences to infer motivation, we propose to give computer vision\nsystems access to some of these experiences by using recently developed natural\nlanguage models to mine knowledge stored in massive amounts of text. While we\nare still far away from fully understanding motivation, our results suggest\nthat transferring knowledge from language into vision can help machines\nunderstand why people in images might be performing an action.", "authors": ["Carl Vondrick", "Deniz Oktay", "Hamed Pirsiavash", "Antonio Torralba"], "category": "cs.CV", "comment": "CVPR 2016", "img": "/static/thumbs/1406.5472v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1406.5472v2", "num_discussion": 0, "originally_published_time": "6/20/2014", "pid": "1406.5472v2", "published_time": "11/30/2016", "rawpid": "1406.5472", "tags": ["cs.CV"], "title": "Predicting Motivations of Actions by Leveraging Text"}, {"abstract": "This paper investigates how linguistic knowledge mined from large text\ncorpora can aid the generation of natural language descriptions of videos.\nSpecifically, we integrate both a neural language model and distributional\nsemantics trained on large text corpora into a recent LSTM-based architecture\nfor video description. We evaluate our approach on a collection of Youtube\nvideos as well as two large movie description datasets showing significant\nimprovements in grammaticality while modestly improving descriptive quality.", "authors": ["Subhashini Venugopalan", "Lisa Anne Hendricks", "Raymond Mooney", "Kate Saenko"], "category": "cs.CL", "comment": "Accepted at EMNLP 2016. Project page:\n  http://vsubhashini.github.io/language_fusion.html", "img": "/static/thumbs/1604.01729v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1604.01729v2", "num_discussion": 0, "originally_published_time": "4/6/2016", "pid": "1604.01729v2", "published_time": "11/29/2016", "rawpid": "1604.01729", "tags": ["cs.CL", "cs.CV"], "title": "Improving LSTM-based Video Description with Linguistic Knowledge Mined\n  from Text"}, {"abstract": "Although semi-supervised variational autoencoder (SemiVAE) works in image\nclassification task, it fails in text classification task if using vanilla LSTM\nas its decoder. From a perspective of reinforcement learning, it is verified\nthat the decoder\u0027s capability to distinguish between different categorical\nlabels is essential. Therefore, Semi-supervised Sequential Variational\nAutoencoder (SSVAE) is proposed, which increases the capability by feeding\nlabel into its decoder RNN at each time-step. Two specific decoder structures\nare investigated and both of them are verified to be effective. Besides, in\norder to reduce the computational complexity in training, a novel optimization\nmethod is proposed, which estimates the gradient of the unlabeled objective\nfunction by sampling, along with two variance reduction techniques.\nExperimental results on Large Movie Review Dataset (IMDB) and AG\u0027s News corpus\nshow that the proposed approach significantly improves the classification\naccuracy compared with pure-supervised classifiers, and achieves competitive\nperformance against previous advanced methods. State-of-the-art results can be\nobtained by integrating other pretraining-based methods.", "authors": ["Weidi Xu", "Haoze Sun", "Chao Deng", "Ying Tan"], "category": "cs.CL", "comment": "8 pages, 4 figure", "img": "/static/thumbs/1603.02514v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1603.02514v3", "num_discussion": 0, "originally_published_time": "3/8/2016", "pid": "1603.02514v3", "published_time": "11/24/2016", "rawpid": "1603.02514", "tags": ["cs.CL", "cs.LG"], "title": "Variational Autoencoders for Semi-supervised Text Classification"}, {"abstract": "Physical library collections are valuable and long standing resources for\nknowledge and learning. However, managing books in a large bookshelf and\nfinding books on it often leads to tedious manual work, especially for large\nbook collections where books might be missing or misplaced. Recently, deep\nneural models, such as Convolutional Neural Networks (CNN) and Recurrent Neural\nNetworks (RNN) have achieved great success for scene text detection and\nrecognition. Motivated by these recent successes, we aim to investigate their\nviability in facilitating book management, a task that introduces further\nchallenges including large amounts of cluttered scene text, distortion, and\nvaried lighting conditions. In this paper, we present a library inventory\nbuilding and retrieval system based on scene text reading methods. We\nspecifically design our scene text recognition model using rich supervision to\naccelerate training and achieve state-of-the-art performance on several\nbenchmark datasets. Our proposed system has the potential to greatly reduce the\namount of human labor required in managing book inventories as well as the\nspace needed to store book information.", "authors": ["Xiao Yang", "Dafang He", "Wenyi Huang", "Zihan Zhou", "Alex Ororbia", "Dan Kifer", "C. Lee Giles"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1611.07385v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1611.07385v1", "num_discussion": 0, "originally_published_time": "11/22/2016", "pid": "1611.07385v1", "published_time": "11/22/2016", "rawpid": "1611.07385", "tags": ["cs.CV"], "title": "Smart Library: Identifying Books in a Library using Richly Supervised\n  Deep Scene Text Reading"}, {"abstract": "The accuracy of Optical Character Recognition (OCR) is crucial to the success\nof subsequent applications used in text analyzing pipeline. Recent models of\nOCR post-processing significantly improve the quality of OCR-generated text,\nbut are still prone to suggest correction candidates from limited observations\nwhile insufficiently accounting for the characteristics of OCR errors. In this\npaper, we show how to enlarge candidate suggestion space by using external\ncorpus and integrating OCR-specific features in a regression approach to\ncorrect OCR-generated errors. The evaluation results show that our model can\ncorrect 61.5% of the OCR-errors (considering the top 1 suggestion) and 71.5% of\nthe OCR-errors (considering the top 3 suggestions), for cases where the\ntheoretical correction upper-bound is 78%.", "authors": ["Jie Mei", "Aminul Islam", "Yajing Wu", "Abidalrahman Moh\u0027d", "Evangelos E. Milios"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1611.06950v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1611.06950v1", "num_discussion": 0, "originally_published_time": "11/21/2016", "pid": "1611.06950v1", "published_time": "11/21/2016", "rawpid": "1611.06950", "tags": ["cs.CV", "cs.LG"], "title": "Statistical Learning for OCR Text Correction"}, {"abstract": "This paper presents an end-to-end trainable fast scene text detector, named\nTextBoxes, which detects scene text with both high accuracy and efficiency in a\nsingle network forward pass, involving no post-process except for a standard\nnon-maximum suppression. TextBoxes outperforms competing methods in terms of\ntext localization accuracy and is much faster, taking only 0.09s per image in a\nfast implementation. Furthermore, combined with a text recognizer, TextBoxes\nsignificantly outperforms state-of-the-art approaches on word spotting and\nend-to-end text recognition tasks.", "authors": ["Minghui Liao", "Baoguang Shi", "Xiang Bai", "Xinggang Wang", "Wenyu Liu"], "category": "cs.CV", "comment": "Accepted by AAAI2017", "img": "/static/thumbs/1611.06779v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1611.06779v1", "num_discussion": 0, "originally_published_time": "11/21/2016", "pid": "1611.06779v1", "published_time": "11/21/2016", "rawpid": "1611.06779", "tags": ["cs.CV"], "title": "TextBoxes: A Fast Text Detector with a Single Deep Neural Network"}, {"abstract": "Recurrent Neural Network (RNN) is one of the most popular architectures used\nin Natural Language Processsing (NLP) tasks because its recurrent structure is\nvery suitable to process variable-length text. RNN can utilize distributed\nrepresentations of words by first converting the tokens comprising each text\ninto vectors, which form a matrix. And this matrix includes two dimensions: the\ntime-step dimension and the feature vector dimension. Then most existing models\nusually utilize one-dimensional (1D) max pooling operation or attention-based\noperation only on the time-step dimension to obtain a fixed-length vector.\nHowever, the features on the feature vector dimension are not mutually\nindependent, and simply applying 1D pooling operation over the time-step\ndimension independently may destroy the structure of the feature\nrepresentation. On the other hand, applying two-dimensional (2D) pooling\noperation over the two dimensions may sample more meaningful features for\nsequence modeling tasks. To integrate the features on both dimensions of the\nmatrix, this paper explores applying 2D max pooling operation to obtain a\nfixed-length representation of the text. This paper also utilizes 2D\nconvolution to sample more meaningful information of the matrix. Experiments\nare conducted on six text classification tasks, including sentiment analysis,\nquestion classification, subjectivity classification and newsgroup\nclassification. Compared with the state-of-the-art models, the proposed models\nachieve excellent performance on 4 out of 6 tasks. Specifically, one of the\nproposed models achieves highest accuracy on Stanford Sentiment Treebank binary\nclassification and fine-grained classification tasks.", "authors": ["Peng Zhou", "Zhenyu Qi", "Suncong Zheng", "Jiaming Xu", "Hongyun Bao", "Bo Xu"], "category": "cs.CL", "comment": "11 pages", "img": "/static/thumbs/1611.06639v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1611.06639v1", "num_discussion": 0, "originally_published_time": "11/21/2016", "pid": "1611.06639v1", "published_time": "11/21/2016", "rawpid": "1611.06639", "tags": ["cs.CL"], "title": "Text Classification Improved by Integrating Bidirectional LSTM with\n  Two-dimensional Max Pooling"}, {"abstract": "This paper describes Centre for Development of Advanced Computing\u0027s (CDACM)\nsubmission to the shared task-\u0027Tool Contest on POS tagging for Code-Mixed\nIndian Social Media (Facebook, Twitter, and Whatsapp) Text\u0027, collocated with\nICON-2016. The shared task was to predict Part of Speech (POS) tag at word\nlevel for a given text. The code-mixed text is generated mostly on social media\nby multilingual users. The presence of the multilingual words,\ntransliterations, and spelling variations make such content linguistically\ncomplex. In this paper, we propose an approach to POS tag code-mixed social\nmedia text using Recurrent Neural Network Language Model (RNN-LM) architecture.\nWe submitted the results for Hindi-English (hi-en), Bengali-English (bn-en),\nand Telugu-English (te-en) code-mixed data.", "authors": ["Raj Nath Patel", "Prakash B. Pimpale", "M Sasikumar"], "category": "cs.CL", "comment": "7 pages, Published at the Tool Contest on POS tagging for Indian\n  Social Media Text, ICON 2016", "img": "/static/thumbs/1611.04989v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1611.04989v2", "num_discussion": 0, "originally_published_time": "11/15/2016", "pid": "1611.04989v2", "published_time": "11/16/2016", "rawpid": "1611.04989", "tags": ["cs.CL"], "title": "Recurrent Neural Network based Part-of-Speech Tagger for Code-Mixed\n  Social Media Text"}, {"abstract": "This article provides an interesting exploration of character-level\nconvolutional neural network solving Chinese corpus text classification\nproblem. We constructed a large-scale Chinese language dataset, and the result\nshows that character-level convolutional neural network works better on Chinese\ncorpus than its corresponding pinyin format dataset. This is the first time\nthat character-level convolutional neural network applied to text\nclassification problem.", "authors": ["Weijie Huang", "Jun Wang"], "category": "cs.CL", "comment": "MSc Thesis, 44 pages", "img": "/static/thumbs/1611.04358v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1611.04358v2", "num_discussion": 0, "originally_published_time": "11/14/2016", "pid": "1611.04358v2", "published_time": "11/15/2016", "rawpid": "1611.04358", "tags": ["cs.CL"], "title": "Character-level Convolutional Network for Text Classification Applied to\n  Chinese Corpus"}, {"abstract": "Long text brings a big challenge to semantic matching due to their\ncomplicated semantic and syntactic structures. To tackle the challenge, we\nconsider using prior knowledge to help identify useful information and filter\nout noise to matching in long text. To this end, we propose a knowledge\nenhanced hybrid neural network (KEHNN). The model fuses prior knowledge into\nword representations by knowledge gates and establishes three matching channels\nwith words, sequential structures of sentences given by Gated Recurrent Units\n(GRU), and knowledge enhanced representations. The three channels are processed\nby a convolutional neural network to generate high level features for matching,\nand the features are synthesized as a matching score by a multilayer\nperceptron. The model extends the existing methods by conducting matching on\nwords, local structures of sentences, and global context of sentences.\nEvaluation results from extensive experiments on public data sets for question\nanswering and conversation show that KEHNN can significantly outperform\nthe-state-of-the-art matching models and particularly improve the performance\non pairs with long text.", "authors": ["Yu Wu", "Wei Wu", "Zhoujun Li", "Ming Zhou"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1611.04684v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1611.04684v1", "num_discussion": 0, "originally_published_time": "11/15/2016", "pid": "1611.04684v1", "published_time": "11/15/2016", "rawpid": "1611.04684", "tags": ["cs.CL"], "title": "Knowledge Enhanced Hybrid Neural Network for Text Matching"}, {"abstract": "In this paper, a novel neural network architecture is proposed attempting to\nrectify text images with mild assumptions. A new dataset of text images is\ncollected to verify our model and open to public. We explored the capability of\ndeep neural network in learning geometric transformation and found the model\ncould segment the text image without explicit supervised segmentation\ninformation. Experiments show the architecture proposed can restore planar\ntransformations with wonderful robustness and effectiveness.", "authors": ["Chengzhe Yan", "Jie Hu", "Changshui Zhang"], "category": "cs.CV", "comment": "9 pages, 10 figures", "img": "/static/thumbs/1611.04298v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1611.04298v1", "num_discussion": 0, "originally_published_time": "11/14/2016", "pid": "1611.04298v1", "published_time": "11/14/2016", "rawpid": "1611.04298", "tags": ["cs.CV"], "title": "A DNN Framework For Text Image Rectification From Planar Transformations"}]